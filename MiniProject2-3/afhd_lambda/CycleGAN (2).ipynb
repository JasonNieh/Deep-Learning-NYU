{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bkkaggle/pytorch-CycleGAN-and-pix2pix/blob/master/CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5VIGyIus8Vr7"
   },
   "source": [
    "Take a look at the [repository](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) for more information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7wNjDKdQy35h"
   },
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TRm-USlsHgEV"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pt3igws3eiVp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CycleGAN.ipynb\tdata\t\t imgs\t\trequirements.txt  util\r\n",
      "LICENSE\t\tdatasets\t models\t\tscripts\r\n",
      "README.md\tdocs\t\t options\ttest.py\r\n",
      "checkpoints\tenvironment.yml  pix2pix.ipynb\ttrain.py\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!ls .\n",
    "# cd ./proj2/pytorch-CycleGAN-and-pix2pix\n",
    "# os.chdir('pytorch-CycleGAN-and-pix2pix/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z1EySlOXwwoa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/jz4364/.local/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.10.2)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /home/jz4364/.local/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (0.11.3)\n",
      "Requirement already satisfied: dominate>=2.4.0 in /home/jz4364/.local/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (2.6.0)\n",
      "Requirement already satisfied: visdom>=0.1.8.8 in /home/jz4364/.local/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (0.1.8.9)\n",
      "Requirement already satisfied: wandb in /home/jz4364/.local/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (0.12.11)\n",
      "Requirement already satisfied: typing-extensions in /home/jz4364/.local/lib/python3.8/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.1.1)\n",
      "Requirement already satisfied: numpy in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages/numpy-1.19.2-py3.8-linux-x86_64.egg (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.19.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (8.0.1)\n",
      "Requirement already satisfied: six in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.15.0)\n",
      "Requirement already satisfied: websocket-client in /home/jz4364/.local/lib/python3.8/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: scipy in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages/scipy-1.5.2-py3.8-linux-x86_64.egg (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.5.2)\n",
      "Requirement already satisfied: torchfile in /home/jz4364/.local/lib/python3.8/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (0.1.0)\n",
      "Requirement already satisfied: requests in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.24.0)\n",
      "Requirement already satisfied: pyzmq in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (19.0.2)\n",
      "Requirement already satisfied: tornado in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.1)\n",
      "Requirement already satisfied: jsonpatch in /home/jz4364/.local/lib/python3.8/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.32)\n",
      "Requirement already satisfied: yaspin>=1.0.0 in /home/jz4364/.local/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 5)) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 5)) (2.8.1)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/jz4364/.local/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 5)) (1.5.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/jz4364/.local/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 5)) (0.4.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /home/jz4364/.local/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 5)) (3.20.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/jz4364/.local/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 5)) (8.1.2)\n",
      "Requirement already satisfied: setproctitle in /home/jz4364/.local/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 5)) (1.2.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /home/jz4364/.local/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 5)) (3.1.27)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 5)) (5.8.0)\n",
      "Requirement already satisfied: PyYAML in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 5)) (5.3.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /home/jz4364/.local/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 5)) (2.3)\n",
      "Requirement already satisfied: pathtools in /home/jz4364/.local/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 5)) (0.1.2)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /home/jz4364/.local/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 5)) (1.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.25.10)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/jz4364/.local/lib/python3.8/site-packages (from jsonpatch->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.2)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /home/jz4364/.local/lib/python3.8/site-packages (from yaspin>=1.0.0->wandb->-r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/jz4364/.local/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb->-r requirements.txt (line 5)) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/jz4364/.local/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb->-r requirements.txt (line 5)) (5.0.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8daqlgVhw29P"
   },
   "source": [
    "# Datasets\n",
    "\n",
    "Download one of the official datasets with:\n",
    "\n",
    "-   `bash ./datasets/download_cyclegan_dataset.sh [apple2orange, summer2winter_yosemite, horse2zebra, monet2photo, cezanne2photo, ukiyoe2photo, vangogh2photo, maps, cityscapes, facades, iphone2dslr_flower, ae_photos]`\n",
    "\n",
    "Or use your own dataset by creating the appropriate folders and adding in the images.\n",
    "\n",
    "-   Create a dataset folder under `/dataset` for your dataset.\n",
    "-   Create subfolders `testA`, `testB`, `trainA`, and `trainB` under your dataset's folder. Place any images you want to transform from a to b (cat2dog) in the `testA` folder, images you want to transform from b to a (dog2cat) in the `testB` folder, and do the same for the `trainA` and `trainB` folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrdOettJxaCc"
   },
   "outputs": [],
   "source": [
    "!bash ./datasets/download_cyclegan_dataset.sh horse2zebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip dataset\n",
    "import zipfile\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "path = r'/scratch/jz4364/dog2cat_afhq'\n",
    "dog = r'/scratch/jz4364/dog2cat_afhq/testB.zip'\n",
    "with zipfile.ZipFile(dog,'r') as zipf:\n",
    "    zipf.extractall(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdUz4116xhpm"
   },
   "source": [
    "# Pretrained models\n",
    "\n",
    "Download one of the official pretrained models with:\n",
    "\n",
    "-   `bash ./scripts/download_cyclegan_model.sh [apple2orange, orange2apple, summer2winter_yosemite, winter2summer_yosemite, horse2zebra, zebra2horse, monet2photo, style_monet, style_cezanne, style_ukiyoe, style_vangogh, sat2map, map2sat, cityscapes_photo2label, cityscapes_label2photo, facades_photo2label, facades_label2photo, iphone2dslr_flower]`\n",
    "\n",
    "Or add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B75UqtKhxznS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: available models are apple2orange, orange2apple, summer2winter_yosemite, winter2summer_yosemite, horse2zebra, zebra2horse, monet2photo, style_monet, style_cezanne, style_ukiyoe, style_vangogh, sat2map, map2sat, cityscapes_photo2label, cityscapes_label2photo, facades_photo2label, facades_label2photo, iphone2dslr_flower\n",
      "Specified [apple2orange]\n",
      "WARNING: timestamping does nothing in combination with -O. See the manual\n",
      "for details.\n",
      "\n",
      "--2022-04-20 12:29:40--  http://efrosgans.eecs.berkeley.edu/cyclegan/pretrained_models/apple2orange.pth\n",
      "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.244.190\n",
      "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.244.190|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 45575747 (43M)\n",
      "Saving to: ‘./checkpoints/apple2orange_pretrained/latest_net_G.pth’\n",
      "\n",
      "./checkpoints/apple 100%[===================>]  43.46M  29.2MB/s    in 1.5s    \n",
      "\n",
      "2022-04-20 12:29:42 (29.2 MB/s) - ‘./checkpoints/apple2orange_pretrained/latest_net_G.pth’ saved [45575747/45575747]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bash ./scripts/download_cyclegan_model.sh apple2orange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yFw1kDQBx3LN"
   },
   "source": [
    "# Training\n",
    "\n",
    "-   `python train.py --dataroot ./datasets/horse2zebra --name horse2zebra --model cycle_gan`\n",
    "\n",
    "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. I've found that a batch size of 16 fits onto 4 V100s and can finish training an epoch in ~90s.\n",
    "\n",
    "Once your model has trained, copy over the last checkpoint to a format that the testing model can automatically detect:\n",
    "\n",
    "Use `cp ./checkpoints/horse2zebra/latest_net_G_A.pth ./checkpoints/horse2zebra/latest_net_G.pth` if you want to transform images from class A to class B and `cp ./checkpoints/horse2zebra/latest_net_G_B.pth ./checkpoints/horse2zebra/latest_net_G.pth` if you want to transform images from class B to class A.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CycleGAN.ipynb\tdata\t\t imgs\t\trequirements.txt  train.py\n",
      "LICENSE\t\tdatasets\t models\t\tresults\t\t  util\n",
      "README.md\tdocs\t\t options\tscripts\t\t  wandb\n",
      "checkpoints\tenvironment.yml  pix2pix.ipynb\ttest.py\n",
      "11352\n",
      "7913\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!ls\n",
    "file_list = os.listdir(r\"./datasets/dog2cat/trainA\")\n",
    "print(len(file_list))\n",
    "file_list = os.listdir(r\"./datasets/dog2cat/trainB\")\n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0sp7TCT2x9dB"
   },
   "outputs": [],
   "source": [
    "!python train.py --dataroot /scratch/jz4364/dog2cat --name dog2cat --model cycle_gan --use_wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using afhq dataset\n",
    "!python train.py --dataroot /scratch/jz4364/dog2cat_afhq --name dog2cat_afhq --model cycle_gan --use_wandb --lambda_A\n",
    " 5 --lambda_B 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9UkcaFZiyASl"
   },
   "source": [
    "# Testing\n",
    "\n",
    "-   `python test.py --dataroot datasets/horse2zebra/testA --name horse2zebra_pretrained --model test --no_dropout`\n",
    "\n",
    "Change the `--dataroot` and `--name` to be consistent with your trained model's configuration.\n",
    "\n",
    "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
    "> The option --model test is used for generating results of CycleGAN only for one side. This option will automatically set --dataset_mode single, which only loads the images from one set. On the contrary, using --model cycle_gan requires loading and generating results in both directions, which is sometimes unnecessary. The results will be saved at ./results/. Use --results_dir {directory_path_to_save_result} to specify the results directory.\n",
    "\n",
    "> For your own experiments, you might want to specify --netG, --norm, --no_dropout to match the generator architecture of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCsKkEq0yGh0"
   },
   "outputs": [],
   "source": [
    "!python test.py --dataroot datasets/apple2orange/testA --name apple2orange_pretrained --model test --no_dropout --use_wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot /scratch/jz4364/dog2cat_afhq --name dog2cat_afhq --model cycle_gan --no_dropout --use_wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzSKIPUByfiN"
   },
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Mgg8raPyizq"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = plt.imread('./results/horse2zebra_pretrained/test_latest/images/n02381460_1010_fake.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0G3oVH9DyqLQ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = plt.imread('./results/horse2zebra_pretrained/test_latest/images/n02381460_1010_real.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     _step                                             real_A  \\\n",
      "0        3  {'_type': 'image-file', 'format': 'png', 'heig...   \n",
      "1       10                                                NaN   \n",
      "2       20  {'_type': 'image-file', 'format': 'png', 'heig...   \n",
      "3       21                                                NaN   \n",
      "4       25  {'height': 256, 'path': 'media/images/real_A_2...   \n",
      "..     ...                                                ...   \n",
      "479   2655  {'width': 256, '_type': 'image-file', 'format'...   \n",
      "480   2672                                                NaN   \n",
      "481   2674                                                NaN   \n",
      "482   2685                                                NaN   \n",
      "483   2691                                                NaN   \n",
      "\n",
      "                                                real_B  \\\n",
      "0    {'_type': 'image-file', 'format': 'png', 'heig...   \n",
      "1                                                  NaN   \n",
      "2    {'size': 129796, 'width': 256, '_type': 'image...   \n",
      "3                                                  NaN   \n",
      "4    {'width': 256, '_type': 'image-file', 'format'...   \n",
      "..                                                 ...   \n",
      "479  {'_type': 'image-file', 'format': 'png', 'heig...   \n",
      "480                                                NaN   \n",
      "481                                                NaN   \n",
      "482                                                NaN   \n",
      "483                                                NaN   \n",
      "\n",
      "                                                fake_B  \\\n",
      "0    {'height': 256, 'path': 'media/images/fake_B_3...   \n",
      "1                                                  NaN   \n",
      "2    {'format': 'png', 'height': 256, 'path': 'medi...   \n",
      "3                                                  NaN   \n",
      "4    {'sha256': 'e82336af46e2cf313160909c22f40f2998...   \n",
      "..                                                 ...   \n",
      "479  {'path': 'media/images/fake_B_2655_73066a71f30...   \n",
      "480                                                NaN   \n",
      "481                                                NaN   \n",
      "482                                                NaN   \n",
      "483                                                NaN   \n",
      "\n",
      "                                                fake_A  \\\n",
      "0    {'sha256': '43db8cac1ad7f86523536cc8f72566880d...   \n",
      "1                                                  NaN   \n",
      "2    {'path': 'media/images/fake_A_20_fa43f152af87e...   \n",
      "3                                                  NaN   \n",
      "4    {'_type': 'image-file', 'format': 'png', 'heig...   \n",
      "..                                                 ...   \n",
      "479  {'path': 'media/images/fake_A_2655_b2bb46dd25e...   \n",
      "480                                                NaN   \n",
      "481                                                NaN   \n",
      "482                                                NaN   \n",
      "483                                                NaN   \n",
      "\n",
      "                                                 idt_B  \\\n",
      "0    {'format': 'png', 'height': 256, 'path': 'medi...   \n",
      "1                                             0.434897   \n",
      "2    {'_type': 'image-file', 'format': 'png', 'heig...   \n",
      "3                                             0.389527   \n",
      "4    {'_type': 'image-file', 'format': 'png', 'heig...   \n",
      "..                                                 ...   \n",
      "479  {'_type': 'image-file', 'format': 'png', 'heig...   \n",
      "480                                          0.0627393   \n",
      "481                                          0.0785341   \n",
      "482                                          0.0944722   \n",
      "483                                           0.125597   \n",
      "\n",
      "                                                 idt_A  \\\n",
      "0    {'width': 256, '_type': 'image-file', 'format'...   \n",
      "1                                             0.760775   \n",
      "2    {'format': 'png', 'height': 256, 'path': 'medi...   \n",
      "3                                             0.467911   \n",
      "4    {'_type': 'image-file', 'format': 'png', 'heig...   \n",
      "..                                                 ...   \n",
      "479  {'size': 104863, 'width': 256, '_type': 'image...   \n",
      "480                                          0.0918168   \n",
      "481                                          0.0843654   \n",
      "482                                           0.126351   \n",
      "483                                            0.11494   \n",
      "\n",
      "                                                 rec_A  \\\n",
      "0    {'format': 'png', 'height': 256, 'path': 'medi...   \n",
      "1                                                  NaN   \n",
      "2    {'size': 119123, 'width': 256, '_type': 'image...   \n",
      "3                                                  NaN   \n",
      "4    {'_type': 'image-file', 'format': 'png', 'heig...   \n",
      "..                                                 ...   \n",
      "479  {'_type': 'image-file', 'format': 'png', 'heig...   \n",
      "480                                                NaN   \n",
      "481                                                NaN   \n",
      "482                                                NaN   \n",
      "483                                                NaN   \n",
      "\n",
      "                                                 rec_B  _runtime  _timestamp  \\\n",
      "0    {'width': 256, '_type': 'image-file', 'format'...        94  1650512175   \n",
      "1                                                  NaN       183  1650512264   \n",
      "2    {'format': 'png', 'height': 256, 'path': 'medi...       362  1650512443   \n",
      "3                                                  NaN       362  1650512443   \n",
      "4    {'_type': 'image-file', 'format': 'png', 'heig...       452  1650512533   \n",
      "..                                                 ...       ...         ...   \n",
      "479  {'format': 'png', 'height': 256, 'path': 'medi...     44476  1650556557   \n",
      "480                                                NaN     44746  1650556827   \n",
      "481                                                NaN     44791  1650556872   \n",
      "482                                                NaN     44971  1650557052   \n",
      "483                                                NaN     45062  1650557143   \n",
      "\n",
      "          G_A       D_A       D_B       G_B   cycle_A   cycle_B Result  \n",
      "0         NaN       NaN       NaN       NaN       NaN       NaN    NaN  \n",
      "1    0.665957  0.150818  0.214869  0.257034  0.756556  1.557465    NaN  \n",
      "2         NaN       NaN       NaN       NaN       NaN       NaN    NaN  \n",
      "3    0.458875  0.270310  0.299813  0.288896  0.920434  1.071594    NaN  \n",
      "4         NaN       NaN       NaN       NaN       NaN       NaN    NaN  \n",
      "..        ...       ...       ...       ...       ...       ...    ...  \n",
      "479       NaN       NaN       NaN       NaN       NaN       NaN    NaN  \n",
      "480  0.402263  0.152404  0.242563  0.318017  0.216676  0.272285    NaN  \n",
      "481  0.483234  0.198762  0.227683  0.398622  0.258654  0.287097    NaN  \n",
      "482  0.547835  0.145970  0.168308  0.495754  0.340647  0.361752    NaN  \n",
      "483  0.475794  0.198485  0.231667  0.408886  0.257711  0.268922    NaN  \n",
      "\n",
      "[484 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "api = wandb.Api()\n",
    "run = api.run(\"/klchg/CycleGAN-and-pix2pix/runs/1u6afnzt\")\n",
    "print(run.history())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mklchg\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.15 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jz4364/proj2/pytorch-CycleGAN-and-pix2pix/wandb/run-20220423_170853-2h3su6g4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dl_proj2/CycleGAN-and-pix2pix/runs/2h3su6g4\" target=\"_blank\">bumbling-feather-1</a></strong> to <a href=\"https://wandb.ai/dl_proj2/CycleGAN-and-pix2pix\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/dl_proj2/CycleGAN-and-pix2pix/runs/2h3su6g4?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x15264a1e7bb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"CycleGAN-and-pix2pix\", entity=\"dl_proj2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sha256': 'ed65c922e9b173a2c53c8dda8cbbb42ce83936056607a2f7382d0b96fa564b7b', 'artifact_path': 'wandb-client-artifact://15vhjoy06m14enrkzhuql1q75xv898sfit887lfrfbg6r26zsfc0p32ox0kgrflse9z64kf0kahd5ye44r9r6puvbjcgvwk5r96r9wedobch1j37uc4lxxb0j512bjwn:latest/Result.table.json', '_latest_artifact_path': 'wandb-client-artifact://15vhjoy06m14enrkzhuql1q75xv898sfit887lfrfbg6r26zsfc0p32ox0kgrflse9z64kf0kahd5ye44r9r6puvbjcgvwk5r96r9wedobch1j37uc4lxxb0j512bjwn:latest/Result.table.json', 'path': 'media/table/Result_2688_ed65c922e9b173a2c53c.table.json', 'size': 187, '_type': 'table-file', 'ncols': 9, 'nrows': 1}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "api = wandb.Api()\n",
    "run = api.run(\"/klchg/CycleGAN-and-pix2pix/runs/1u6afnzt\")\n",
    "run.summary['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CycleGAN",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
