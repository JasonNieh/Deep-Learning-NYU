{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "azOQDGfMLFN8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import math\n",
    "import torchvision\n",
    "from torchvision import transforms as transforms\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from math import cos,pi\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nnaef49GOhPH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Vb_Gr3w9vzx8"
   },
   "outputs": [],
   "source": [
    "# torch.manual_seed(17)\n",
    "\n",
    "# class HaS(object): \n",
    "# #     def __init__(self):\n",
    "        \n",
    "#     def __call__(self, img):\n",
    "#         # get width and height of the image\n",
    "#         img_= np.array(img).copy()\n",
    "#         s = img_.shape\n",
    "#         wd = s[0]\n",
    "#         ht = s[1]\n",
    "\n",
    "#         # possible grid size, 0 means no hiding\n",
    "#         grid_size=3\n",
    "\n",
    "#         # hiding probability\n",
    "#         hide_prob = 0.1\n",
    " \n",
    "#         # randomly choose one grid size\n",
    "# #         grid_size= grid_sizes[random.randint(0,len(grid_sizes)-1)]\n",
    "\n",
    "#         # hide the patches\n",
    "#         if(grid_size>0):\n",
    "#              for x in range(0,wd,grid_size):\n",
    "#                  for y in range(0,ht,grid_size):\n",
    "#                      x_end = min(wd, x+grid_size)  \n",
    "#                      y_end = min(ht, y+grid_size)\n",
    "#                      if(random.random() <=  hide_prob):\n",
    "#                            img_[x:x_end,y:y_end,:]=0\n",
    "\n",
    "#         return img_\n",
    "    \n",
    "# torch.manual_seed(17)\n",
    "\n",
    "        \n",
    "# class HideEdge(object): \n",
    "#     def __init__(self,hide_size):\n",
    "#         self.hide_size=hide_size\n",
    "        \n",
    "#     def __call__(self, img):\n",
    "#         # get width and height of the image\n",
    "#         img_= np.array(img).copy()\n",
    "#         s = img_.shape\n",
    "#         wd = s[0]\n",
    "#         ht = s[1]\n",
    "\n",
    "#         hide_size=self.hide_size\n",
    "        \n",
    "# #         img_[:,:,:] = img()\n",
    "   \n",
    "#         x_end = wd - hide_size \n",
    "#         y_end = ht - hide_size\n",
    "\n",
    "#         img_[x_end:,y_end:,:]=0\n",
    "# #         img_[x_end:,:hide_size,:]=0\n",
    "# #         img_[:hide_size,y_end:,:]=0\n",
    "#         img_[:hide_size,:hide_size,:]=0\n",
    "# #         img_[x_end:,:,:]=0\n",
    "# #         img_[:,y_end:,:]=0\n",
    "# #         img_[:hide_size,:,:]=0\n",
    "# #         img_[:,:hide_size,:]=0\n",
    "# #         print(img_[x_end,y_end,:])\n",
    "# #         print(img_[hide_size,hide_size,:])\n",
    "# #         print(x_end,y_end,hide_size)\n",
    "        \n",
    "# #         mean = img_[hide_size:x_end-1,hide_size:y_end,:].mean()\n",
    "# #         std = img_[hide_size:x_end-1,hide_size:y_end,:].std()\n",
    "# #         print(mean, std)\n",
    "# #         img_[hide_size:x_end-1,hide_size:y_end,:] = (img_[hide_size:x_end-1,hide_size:y_end,:] - mean) / std\n",
    "# #         print(img_[hide_size:x_end-1,hide_size:y_end,:])\n",
    "        \n",
    "#         return img_\n",
    "\n",
    "   \n",
    "# class Hide_after_Norm(object): \n",
    "#     def __init__(self,hide_size):\n",
    "#         self.hide_size=hide_size\n",
    "        \n",
    "#     def __call__(self, img_):\n",
    "#         # get width and height of the image\n",
    "# #         img_= np.array(img).copy()\n",
    "#         s = img_.shape\n",
    "#         wd = s[1]\n",
    "#         ht = s[2]\n",
    "\n",
    "#         hide_size=self.hide_size\n",
    "        \n",
    "# #         img_[:,:,:] = img()\n",
    "   \n",
    "#         x_end = wd - hide_size \n",
    "#         y_end = ht - hide_size\n",
    "        \n",
    "#         x_end = wd - hide_size \n",
    "#         y_end = ht - hide_size\n",
    "\n",
    "#         img_[:,x_end:,y_end:]=0\n",
    "# #         img_[x_end:,:hide_size,:]=0\n",
    "# #         img_[:hide_size,y_end:,:]=0\n",
    "#         img_[:,:hide_size,:hide_size]=0\n",
    "# #         print(img_[x_end,y_end,:])\n",
    "# #         print(img_[hide_size,hide_size,:])\n",
    "# #         print(x_end,y_end,hide_size)\n",
    "        \n",
    "# #         mean = img_[hide_size:x_end-1,hide_size:y_end,:].mean()\n",
    "# #         std = img_[hide_size:x_end-1,hide_size:y_end,:].std()\n",
    "# #         print(mean, std)\n",
    "# #         img_[hide_size:x_end-1,hide_size:y_end,:] = (img_[hide_size:x_end-1,hide_size:y_end,:] - mean) / std\n",
    "# #         print(img_[hide_size:x_end-1,hide_size:y_end,:])\n",
    "        \n",
    "#         return img_\n",
    "    \n",
    "    \n",
    "\n",
    "# # torch.cuda.manual_seed(17) # for GPU\n",
    "# aug_train = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(), # 水平翻转\n",
    "# #     torchvision.transforms.CenterCrop(26),\n",
    "# #     HideEdge(),\n",
    "#     torchvision.transforms.RandomRotation(15),\n",
    "# #     torchvision.transforms.CenterCrop(28),\n",
    "#     # transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5), # color aug\n",
    "# #     transforms.RandomCrop(32, padding=4), # 裁剪\n",
    "#     # transforms.RandomResizedCrop((32,32),scale=(0.1,1),ratio=(0.5,2))\n",
    "# #     hide_patch(),\n",
    "# #     HaS(),\n",
    "# #     HideEdge(2),\n",
    "#     transforms.ToTensor(),\n",
    "# #     Norm(2),\n",
    "#     transforms.Normalize((0.4649, 0.4553, 0.4214), (0.2271, 0.2234, 0.2208)),# normalization\n",
    "#     Hide_after_Norm(2)\n",
    "#     ])\n",
    "\n",
    "# aug_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4649, 0.4553, 0.4214), (0.2271, 0.2234, 0.2208)), # normalization\n",
    "#     Hide_after_Norm(2)\n",
    "#     ])\n",
    "\n",
    "# trainingdata = torchvision.datasets.CIFAR10('./CIFAR10',train=True,download=True,transform=aug_train)\n",
    "# # testdata = torchvision.datasets.CIFAR10('./CIFAR10',train=False,download=True,transform=transforms.ToTensor())\n",
    "# # print(len(trainingdata),len(testdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(17)\n",
    "torch.cuda.manual_seed_all(17)\n",
    "\n",
    "aug_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32,padding=4,padding_mode='reflect'),\n",
    "    transforms.RandomHorizontalFlip(), # 水平翻转\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4244, 0.4146, 0.3836), (0.2539, 0.2491, 0.2420)) # normalization\n",
    "    ])\n",
    "\n",
    "aug_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4244, 0.4146, 0.3836), (0.2539, 0.2491, 0.2420)) # normalization\n",
    "    ])\n",
    "\n",
    "trainingdata = torchvision.datasets.CIFAR10('./CIFAR10',train=True,download=True,transform=aug_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "3983cfe844f847899487b2745a203a9b",
      "1121692d91114d58b3db79e41b0a24c9",
      "8148f05b38d94ec19351ac920b70acba",
      "af7b660f147d4d1d8796d3419673c9b7",
      "0130588af6254c76a2c8c382288cfcea",
      "fb3e769eb8324af3b77041879c9b54cf",
      "accf52fe298b4716af9d9c351e7326dc",
      "1d40f4bf0c0e48709cdec5f80069ed2f",
      "321ea7fa0b4d4c9dab9ed5231954e54c",
      "a66b114e4595419f84ac44a676a1ca61",
      "4aa5668c8eaa49f88148d499240b6ea5"
     ]
    },
    "id": "1lqsbqYCMja7",
    "outputId": "3b4aa629-06a0-480a-afec-dcdb971e4bf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def get_mean_and_std(dataset):\n",
    "  '''Compute the mean and std value of dataset.'''\n",
    "  dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "  mean = torch.zeros(3)\n",
    "  std = torch.zeros(3)\n",
    "  print('==> Computing mean and std..')\n",
    "  for inputs, targets in dataloader:\n",
    "      for i in range(3):\n",
    "          mean[i] += inputs[:,i,:,:].mean()\n",
    "          std[i] += inputs[:,i,:,:].std()\n",
    "  mean.div_(len(dataset))\n",
    "  std.div_(len(dataset))\n",
    "  return mean, std\n",
    "\n",
    "def load_data(is_train,aug,batch_size):\n",
    "  dataset = torchvision.datasets.CIFAR10('./CIFAR10',train=is_train,download=True,transform=aug)\n",
    "#   mean, std = get_mean_and_std(dataset)\n",
    "#   print(mean, std)\n",
    "  dataloader = torch.utils.data.DataLoader(dataset,batch_size=batch_size,shuffle=is_train)\n",
    "  return dataloader\n",
    "\n",
    "batch_size = 256 # param\n",
    "trainDataLoader = load_data(is_train=True,aug=aug_train,batch_size=batch_size)\n",
    "testDataLoader = load_data(is_train=False,aug=aug_test,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-TD4UKtgzXbh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32]) 6\n",
      "[[[-0.9147032  -0.38956204  0.0274618  ...  0.01201648  0.18191507\n",
      "    0.15102442]\n",
      "  [-0.32778072 -0.03431951  0.10468844 ... -0.21966343  0.1973604\n",
      "    0.2591417 ]\n",
      "  [-0.09610081  0.29003236  0.24369638 ... -0.6366873  -0.51312464\n",
      "   -0.32778072]\n",
      "  ...\n",
      "  [ 1.0931895   1.2321974   1.448432   ...  0.22825105  0.66072035\n",
      "    1.6646665 ]\n",
      "  [ 1.2013068   1.3248694   1.3866507  ... -0.38956204 -0.17332745\n",
      "    1.1704161 ]\n",
      "  [ 1.3866507   1.2785335   1.1549708  ... -0.8529219  -0.8065859\n",
      "    0.7997283 ]]\n",
      "\n",
      " [[-1.2393323  -0.8772444  -0.53089947 ... -0.5151565  -0.3419841\n",
      "   -0.3419841 ]\n",
      "  [-0.8142726  -0.6725861  -0.5623854  ... -0.68832904 -0.32624117\n",
      "   -0.29475525]\n",
      "  [-0.6411001  -0.42069885 -0.45218474 ... -1.003188   -0.9244732\n",
      "   -0.76704377]\n",
      "  ...\n",
      "  [ 0.57110703  0.6813077   0.9804237  ... -0.21604052  0.19327614\n",
      "    1.2323109 ]\n",
      "  [ 0.6025929   0.74427944  0.8229942  ... -0.83001554 -0.68832904\n",
      "    0.6655647 ]\n",
      "  [ 0.87022305  0.8072512   0.6340788  ... -1.1291317  -1.1763605\n",
      "    0.42942047]]\n",
      "\n",
      " [[-1.4554853  -1.212413   -0.92072594 ... -0.9045211  -0.7748825\n",
      "   -0.7748825 ]\n",
      "  [-1.1800033  -1.1313888  -1.0503646  ... -1.017955   -0.80729216\n",
      "   -0.7748825 ]\n",
      "  [-1.0341598  -0.9531356  -1.0017501  ... -1.1800033  -1.212413\n",
      "   -1.1475936 ]\n",
      "  ...\n",
      "  [-0.17530379 -0.49940035 -0.4831955  ... -0.4183762  -0.22391827\n",
      "    0.6835522 ]\n",
      "  [-1.0989791  -1.1800033  -1.0341598  ... -1.0341598  -1.0341598\n",
      "   -0.06186999]\n",
      "  [-1.1637985  -1.1475936  -1.0341598  ... -1.2610275  -1.4716902\n",
      "   -0.45078588]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "image,label = trainingdata[0]\n",
    "image_= np.array(image).copy()\n",
    "print(image.shape, label)\n",
    "print(image_)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.imshow(image.numpy().transpose(1,2,0))\n",
    "plt.title(str(classes[label]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jo4vcA1BwajW"
   },
   "outputs": [],
   "source": [
    "# trainDataLoader = torch.utils.data.DataLoader(trainingdata,batch_size=batch_size,shuffle=True)\n",
    "# testDataLoader = torch.utils.data.DataLoader(testdata,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "# images, labels = iter(trainDataLoader).next()\n",
    "# plt.figure(figsize=(17,8))\n",
    "# for index in np.arange(0,5):\n",
    "#   plt.subplot(1,5,index+1)\n",
    "#   plt.imshow(images[index].numpy().transpose(1,2,0))\n",
    "#   plt.title(str(classes[labels[index]]))\n",
    "\n",
    "def get_mean_and_std(dataset):\n",
    "  '''Compute the mean and std value of dataset.'''\n",
    "  dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "  mean = torch.zeros(3)\n",
    "  std = torch.zeros(3)\n",
    "  print('==> Computing mean and std..')\n",
    "  for inputs, targets in dataloader:\n",
    "      for i in range(3):\n",
    "          mean[i] += inputs[:,i,:,:].mean()\n",
    "          std[i] += inputs[:,i,:,:].std()\n",
    "  mean.div_(len(dataset))\n",
    "  std.div_(len(dataset))\n",
    "  return mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YDBTjSf2jDNm"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_planes, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = in_planes\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_planes)\n",
    "        self.layer1 = self._make_layer(block, in_planes, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, in_planes*2, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, in_planes*4, num_blocks[2], stride=2)\n",
    "#         self.layer4 = self._make_layer(block, in_planes*8, num_blocks[3], stride=2)\n",
    "#         self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "#         self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "#         self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "#         self.layer4 = self._make_layer(block, self.in_planes*8, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(x.shape)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "#         print(out.shape)\n",
    "        out = self.layer1(out)\n",
    "#         print(out.shape)\n",
    "        out = self.layer2(out)\n",
    "#         print(out.shape)\n",
    "        out = self.layer3(out)\n",
    "#         print(out.shape)\n",
    "#         out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "#         print(out.shape)\n",
    "        out = out.view(out.size(0), -1)\n",
    "#         print(out.shape)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu') # weight initialization\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)\n",
    "            elif isinstance(m,nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "            elif isinstance(m,nn.Linear):\n",
    "                nn.init.normal_(m.weight,std=1e-3)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)    \n",
    "\n",
    "def project1_model():\n",
    "#     return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "#     return ResNet(BasicBlock, [2, 2, 2])\n",
    "    return ResNet(80, BasicBlock, [3, 3, 2])\n",
    "\n",
    "# model1 = nn.Sequential(project1_model(), nn.AdaptiveAvgPool2d((1,1)), nn.Flatten(), nn.Linear(512, 10)).cuda()\n",
    "model1 = project1_model().cuda()\n",
    "model1.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FDnI9zbyLK6B",
    "outputId": "4a1b7b4e-5d52-42d6-8563-500023c3acae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4923930\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    # torch.numel() returns number of elements in a tensor\n",
    "\n",
    "print(count_parameters(model1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, current_epoch,max_epoch,lr_min=0,lr_max=0.1,warmup=True):\n",
    "    warmup_epoch = 10 if warmup else 0\n",
    "    if current_epoch < warmup_epoch:\n",
    "        lr = lr_max * current_epoch / warmup_epoch\n",
    "    else:\n",
    "        lr = lr_min + (lr_max-lr_min)*(1 + cos(pi * (current_epoch - warmup_epoch) / (max_epoch - warmup_epoch))) / 2\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbLtFYydjoIx",
    "outputId": "0321ff7b-c60c-4099-f5fb-4a9536f10244"
   },
   "outputs": [],
   "source": [
    "# X = torch.rand(size=(1, 3, 32, 32)).cuda()\n",
    "# for layer in model1:\n",
    "#   X = layer(X)\n",
    "#   print(layer.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "j5xklXYe6gRe",
    "outputId": "b846ff14-cc67-4bdc-d6bb-f727fa580bcc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read model from checkpoint\n",
      "Restart from epoch 3595\n",
      "Epoch 3596, Train loss 0.00027077447840402244, Test loss 0.15326829310506582, Train accuracy 100.0, Test accuracy 95.498046875, Cost 66.14358425140381 s\n",
      "Epoch 3597, Train loss 0.0002619336730128211, Test loss 0.15251947790384293, Train accuracy 100.0, Test accuracy 95.458984375, Cost 64.45724964141846 s\n",
      "Epoch 3598, Train loss 0.0002632034263987574, Test loss 0.1514471709728241, Train accuracy 100.0, Test accuracy 95.478515625, Cost 64.48179578781128 s\n",
      "Epoch 3599, Train loss 0.0002646682839941623, Test loss 0.15156962554901837, Train accuracy 100.0, Test accuracy 95.44921875, Cost 64.54869246482849 s\n",
      "Epoch 3600, Train loss 0.00026569943344968906, Test loss 0.15015771072357892, Train accuracy 100.0, Test accuracy 95.46875, Cost 64.53459310531616 s\n",
      "Model saved in epoch 3600\n",
      "Epoch 3601, Train loss 0.0002723244642580465, Test loss 0.15095309894531966, Train accuracy 100.0, Test accuracy 95.48828125, Cost 64.51774430274963 s\n",
      "Epoch 3602, Train loss 0.00027482941613368673, Test loss 0.1503688022494316, Train accuracy 100.0, Test accuracy 95.498046875, Cost 64.56410908699036 s\n",
      "Epoch 3603, Train loss 0.00028563533227757683, Test loss 0.15200730711221694, Train accuracy 100.0, Test accuracy 95.478515625, Cost 64.66988229751587 s\n",
      "Epoch 3604, Train loss 0.0002888305730730466, Test loss 0.1504845006391406, Train accuracy 100.0, Test accuracy 95.419921875, Cost 64.62175559997559 s\n",
      "Epoch 3605, Train loss 0.0002787001742072622, Test loss 0.15231589823961258, Train accuracy 100.0, Test accuracy 95.419921875, Cost 64.56831502914429 s\n",
      "Model saved in epoch 3605\n",
      "Epoch 3606, Train loss 0.00028293026057048227, Test loss 0.15219679698348046, Train accuracy 100.0, Test accuracy 95.37109375, Cost 64.62179851531982 s\n",
      "Epoch 3607, Train loss 0.0002803647449229397, Test loss 0.15322815142571927, Train accuracy 100.0, Test accuracy 95.41015625, Cost 64.59656190872192 s\n",
      "Epoch 3608, Train loss 0.0002876185344761399, Test loss 0.15247626677155496, Train accuracy 100.0, Test accuracy 95.46875, Cost 64.59700107574463 s\n",
      "Epoch 3609, Train loss 0.0002837147487521086, Test loss 0.15239399932324887, Train accuracy 100.0, Test accuracy 95.419921875, Cost 64.59221839904785 s\n",
      "Epoch 3610, Train loss 0.0003027773974671228, Test loss 0.1531502788886428, Train accuracy 100.0, Test accuracy 95.517578125, Cost 64.6028380393982 s\n",
      "Model saved in epoch 3610\n",
      "Epoch 3611, Train loss 0.0002870789601506751, Test loss 0.1526038372889161, Train accuracy 100.0, Test accuracy 95.46875, Cost 64.61339259147644 s\n",
      "Epoch 3612, Train loss 0.00031031741339259555, Test loss 0.15288057439029218, Train accuracy 100.0, Test accuracy 95.390625, Cost 64.59347081184387 s\n",
      "Epoch 3613, Train loss 0.0002899543794729671, Test loss 0.15465041771531104, Train accuracy 100.0, Test accuracy 95.4296875, Cost 64.59286975860596 s\n",
      "Epoch 3614, Train loss 0.00028362692244961494, Test loss 0.1530654115602374, Train accuracy 100.0, Test accuracy 95.419921875, Cost 64.62993335723877 s\n",
      "Epoch 3615, Train loss 0.00030953634082760226, Test loss 0.1536814048886299, Train accuracy 100.0, Test accuracy 95.439453125, Cost 64.6649272441864 s\n",
      "Model saved in epoch 3615\n",
      "Epoch 3616, Train loss 0.00028227480340449674, Test loss 0.15244081933051348, Train accuracy 100.0, Test accuracy 95.478515625, Cost 64.70146179199219 s\n",
      "Epoch 3617, Train loss 0.0003171150814040982, Test loss 0.15473570302128792, Train accuracy 100.0, Test accuracy 95.46875, Cost 64.68175029754639 s\n",
      "Epoch 3620, Train loss 0.0003376704155424686, Test loss 0.15049560610204935, Train accuracy 100.0, Test accuracy 95.537109375, Cost 65.13078689575195 s\n",
      "Model saved in epoch 3620\n",
      "Epoch 3621, Train loss 0.00031416232444343576, Test loss 0.14944204669445754, Train accuracy 100.0, Test accuracy 95.52734375, Cost 65.12629270553589 s\n",
      "Epoch 3622, Train loss 0.00028911474554642693, Test loss 0.14966917932033538, Train accuracy 100.0, Test accuracy 95.546875, Cost 65.1167631149292 s\n",
      "Epoch 3623, Train loss 0.0003132525034372372, Test loss 0.15139217544347047, Train accuracy 100.0, Test accuracy 95.439453125, Cost 65.11954069137573 s\n",
      "Epoch 3624, Train loss 0.00031014395567674036, Test loss 0.15024443250149488, Train accuracy 100.0, Test accuracy 95.5078125, Cost 65.11373972892761 s\n",
      "Epoch 3625, Train loss 0.00030414480656594495, Test loss 0.15136282350867986, Train accuracy 100.0, Test accuracy 95.546875, Cost 65.13004446029663 s\n",
      "Model saved in epoch 3625\n",
      "Epoch 3626, Train loss 0.00029103354512587934, Test loss 0.15080937873572112, Train accuracy 100.0, Test accuracy 95.498046875, Cost 65.14996671676636 s\n",
      "Epoch 3627, Train loss 0.0002869582223903141, Test loss 0.14973849505186082, Train accuracy 100.0, Test accuracy 95.498046875, Cost 65.00772070884705 s\n",
      "Epoch 3628, Train loss 0.00029642455685498876, Test loss 0.15004186574369668, Train accuracy 100.0, Test accuracy 95.52734375, Cost 64.591068983078 s\n",
      "Epoch 3629, Train loss 0.00029775392984596026, Test loss 0.15029339361935853, Train accuracy 100.0, Test accuracy 95.46875, Cost 64.58580875396729 s\n",
      "Epoch 3630, Train loss 0.00029770954650451374, Test loss 0.15100226793438196, Train accuracy 100.0, Test accuracy 95.5078125, Cost 64.61167407035828 s\n",
      "Model saved in epoch 3630\n",
      "Epoch 3631, Train loss 0.0002979918707361711, Test loss 0.15144493542611598, Train accuracy 100.0, Test accuracy 95.46875, Cost 64.62477087974548 s\n",
      "Epoch 3632, Train loss 0.0002902780391622753, Test loss 0.15038355235010387, Train accuracy 100.0, Test accuracy 95.52734375, Cost 64.70629715919495 s\n",
      "Epoch 3633, Train loss 0.0002799161389257464, Test loss 0.148709955252707, Train accuracy 100.0, Test accuracy 95.60546875, Cost 64.69473052024841 s\n",
      "Epoch 3634, Train loss 0.00029136695496961287, Test loss 0.15162286572158337, Train accuracy 100.0, Test accuracy 95.595703125, Cost 64.7048990726471 s\n",
      "Epoch 3635, Train loss 0.0002799397931381946, Test loss 0.15084112621843815, Train accuracy 100.0, Test accuracy 95.60546875, Cost 64.67203092575073 s\n",
      "Model saved in epoch 3635\n",
      "Epoch 3636, Train loss 0.00029504757311565763, Test loss 0.14996302239596843, Train accuracy 100.0, Test accuracy 95.576171875, Cost 64.70268273353577 s\n",
      "Epoch 3637, Train loss 0.0002853421407350225, Test loss 0.1487872838973999, Train accuracy 100.0, Test accuracy 95.72265625, Cost 64.69579982757568 s\n",
      "Epoch 3638, Train loss 0.0003020641000760833, Test loss 0.14908993802964687, Train accuracy 100.0, Test accuracy 95.625, Cost 64.70140314102173 s\n",
      "Epoch 3639, Train loss 0.0002920286741365479, Test loss 0.14863339420408012, Train accuracy 100.0, Test accuracy 95.64453125, Cost 64.68644952774048 s\n",
      "Epoch 3640, Train loss 0.00029259757599104383, Test loss 0.14821806978434324, Train accuracy 100.0, Test accuracy 95.60546875, Cost 64.67371273040771 s\n",
      "Model saved in epoch 3640\n",
      "Epoch 3641, Train loss 0.0003073996456211661, Test loss 0.14841178636997937, Train accuracy 100.0, Test accuracy 95.576171875, Cost 64.67548060417175 s\n",
      "Epoch 3642, Train loss 0.00029226071630397867, Test loss 0.14923493135720492, Train accuracy 100.0, Test accuracy 95.576171875, Cost 64.67545223236084 s\n",
      "Epoch 3643, Train loss 0.0002812368809233648, Test loss 0.14991186149418353, Train accuracy 100.0, Test accuracy 95.634765625, Cost 64.66689944267273 s\n",
      "Epoch 3644, Train loss 0.0003099372592334141, Test loss 0.15105415396392347, Train accuracy 100.0, Test accuracy 95.5859375, Cost 64.70119833946228 s\n",
      "Epoch 3645, Train loss 0.0002979502646574437, Test loss 0.149262036383152, Train accuracy 100.0, Test accuracy 95.693359375, Cost 64.71000719070435 s\n",
      "Model saved in epoch 3645\n",
      "Epoch 3646, Train loss 0.00031149498540706155, Test loss 0.14808192905038595, Train accuracy 100.0, Test accuracy 95.634765625, Cost 64.71709084510803 s\n",
      "Epoch 3647, Train loss 0.00029210435768247257, Test loss 0.14924611914902924, Train accuracy 100.0, Test accuracy 95.625, Cost 64.69309735298157 s\n",
      "Epoch 3648, Train loss 0.0002765302277260403, Test loss 0.1494749817997217, Train accuracy 100.0, Test accuracy 95.6640625, Cost 64.68791127204895 s\n",
      "Epoch 3649, Train loss 0.000284933951568709, Test loss 0.1487364374101162, Train accuracy 100.0, Test accuracy 95.634765625, Cost 64.69889211654663 s\n",
      "Epoch 3650, Train loss 0.0002816547598091087, Test loss 0.14849185030907391, Train accuracy 100.0, Test accuracy 95.595703125, Cost 64.69410586357117 s\n",
      "Model saved in epoch 3650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3651, Train loss 0.0002843339604382612, Test loss 0.14987601153552532, Train accuracy 100.0, Test accuracy 95.615234375, Cost 64.69223070144653 s\n",
      "Epoch 3652, Train loss 0.0002779103158492053, Test loss 0.1497041504830122, Train accuracy 100.0, Test accuracy 95.56640625, Cost 64.6731550693512 s\n",
      "Epoch 3653, Train loss 0.0002820747179853521, Test loss 0.14982595723122358, Train accuracy 100.0, Test accuracy 95.634765625, Cost 64.65177273750305 s\n",
      "Epoch 3654, Train loss 0.0002788094719349198, Test loss 0.15014639049768447, Train accuracy 100.0, Test accuracy 95.595703125, Cost 64.66091465950012 s\n",
      "Epoch 3655, Train loss 0.00029069865625814954, Test loss 0.14881091061979532, Train accuracy 100.0, Test accuracy 95.712890625, Cost 64.61807513237 s\n",
      "Model saved in epoch 3655\n",
      "Epoch 3656, Train loss 0.0003037920339883552, Test loss 0.1486571289598942, Train accuracy 100.0, Test accuracy 95.556640625, Cost 64.65524291992188 s\n",
      "Epoch 3657, Train loss 0.00029243728983731544, Test loss 0.15038003232330083, Train accuracy 100.0, Test accuracy 95.72265625, Cost 64.67263841629028 s\n",
      "Epoch 3658, Train loss 0.00032237149237201323, Test loss 0.15168629288673402, Train accuracy 100.0, Test accuracy 95.56640625, Cost 64.67248058319092 s\n",
      "Epoch 3659, Train loss 0.0003087724385574004, Test loss 0.14989839475601913, Train accuracy 100.0, Test accuracy 95.654296875, Cost 64.70157265663147 s\n",
      "Epoch 3660, Train loss 0.0002876495151324388, Test loss 0.15055579636245967, Train accuracy 100.0, Test accuracy 95.5859375, Cost 64.69754767417908 s\n",
      "Model saved in epoch 3660\n",
      "Epoch 3661, Train loss 0.00027643277993477997, Test loss 0.14998255744576455, Train accuracy 100.0, Test accuracy 95.595703125, Cost 64.61602067947388 s\n",
      "Epoch 3662, Train loss 0.00028917297971261456, Test loss 0.15007443856447936, Train accuracy 100.0, Test accuracy 95.56640625, Cost 64.57099413871765 s\n",
      "Epoch 3663, Train loss 0.00029059026022952485, Test loss 0.15010475404560567, Train accuracy 100.0, Test accuracy 95.673828125, Cost 64.57065296173096 s\n",
      "Epoch 3664, Train loss 0.0002854784517917231, Test loss 0.14865486025810243, Train accuracy 100.0, Test accuracy 95.625, Cost 64.67196035385132 s\n",
      "Epoch 3665, Train loss 0.0002820281812574296, Test loss 0.14950607102364302, Train accuracy 100.0, Test accuracy 95.56640625, Cost 64.63591575622559 s\n",
      "Model saved in epoch 3665\n",
      "Epoch 3666, Train loss 0.00028509664435678503, Test loss 0.14947438575327396, Train accuracy 100.0, Test accuracy 95.5859375, Cost 64.5706787109375 s\n",
      "Epoch 3667, Train loss 0.0002868814165650496, Test loss 0.14817780833691357, Train accuracy 100.0, Test accuracy 95.712890625, Cost 64.51601958274841 s\n",
      "Epoch 3668, Train loss 0.0002852856266646104, Test loss 0.14937560949474574, Train accuracy 100.0, Test accuracy 95.5859375, Cost 64.5012435913086 s\n",
      "Epoch 3669, Train loss 0.0002867293642710286, Test loss 0.15038384087383747, Train accuracy 100.0, Test accuracy 95.498046875, Cost 64.47200608253479 s\n",
      "Epoch 3670, Train loss 0.00028964380529645015, Test loss 0.14992388673126697, Train accuracy 100.0, Test accuracy 95.537109375, Cost 64.4897096157074 s\n",
      "Model saved in epoch 3670\n",
      "Epoch 3671, Train loss 0.00027969655319775113, Test loss 0.14981742054224015, Train accuracy 100.0, Test accuracy 95.5078125, Cost 64.58916544914246 s\n",
      "Epoch 3672, Train loss 0.00029317119986778693, Test loss 0.149470267444849, Train accuracy 100.0, Test accuracy 95.576171875, Cost 64.49981260299683 s\n",
      "Epoch 3673, Train loss 0.0002915901001257708, Test loss 0.15050726775079964, Train accuracy 100.0, Test accuracy 95.52734375, Cost 64.58931088447571 s\n",
      "Epoch 3674, Train loss 0.00028664706027187523, Test loss 0.14998775199055672, Train accuracy 100.0, Test accuracy 95.703125, Cost 64.52254152297974 s\n",
      "Epoch 3675, Train loss 0.00028525395315896, Test loss 0.1505143605172634, Train accuracy 100.0, Test accuracy 95.595703125, Cost 64.60717558860779 s\n",
      "Model saved in epoch 3675\n",
      "Epoch 3676, Train loss 0.0002982992434913378, Test loss 0.1477225525304675, Train accuracy 100.0, Test accuracy 95.654296875, Cost 64.49579191207886 s\n",
      "Epoch 3677, Train loss 0.0002896883998634009, Test loss 0.1501720067113638, Train accuracy 100.0, Test accuracy 95.478515625, Cost 64.4840817451477 s\n",
      "Epoch 3678, Train loss 0.00028449779956088385, Test loss 0.14842956215143205, Train accuracy 100.0, Test accuracy 95.654296875, Cost 64.56253242492676 s\n",
      "Epoch 3679, Train loss 0.000293318899431532, Test loss 0.14931263476610185, Train accuracy 100.0, Test accuracy 95.60546875, Cost 64.50380253791809 s\n",
      "Epoch 3680, Train loss 0.00029007188759908097, Test loss 0.15006498284637929, Train accuracy 100.0, Test accuracy 95.68359375, Cost 64.50328707695007 s\n",
      "Model saved in epoch 3680\n",
      "Epoch 3681, Train loss 0.0003013852934711803, Test loss 0.1508739409968257, Train accuracy 100.0, Test accuracy 95.48828125, Cost 64.4717047214508 s\n",
      "Epoch 3682, Train loss 0.00029719818670929845, Test loss 0.15014112442731858, Train accuracy 100.0, Test accuracy 95.576171875, Cost 64.44897699356079 s\n",
      "Epoch 3683, Train loss 0.0002847561190719716, Test loss 0.15118169579654933, Train accuracy 100.0, Test accuracy 95.517578125, Cost 64.45094227790833 s\n",
      "Epoch 3684, Train loss 0.0002842354097454666, Test loss 0.15066866762936115, Train accuracy 100.0, Test accuracy 95.517578125, Cost 64.46035647392273 s\n",
      "Epoch 3685, Train loss 0.00027596678031544317, Test loss 0.15124142952263356, Train accuracy 100.0, Test accuracy 95.5859375, Cost 64.56551790237427 s\n",
      "Model saved in epoch 3685\n",
      "Epoch 3686, Train loss 0.00028991366551573653, Test loss 0.15127184353768824, Train accuracy 100.0, Test accuracy 95.693359375, Cost 64.7702796459198 s\n",
      "Epoch 3687, Train loss 0.00028965288494910797, Test loss 0.15279053542762994, Train accuracy 100.0, Test accuracy 95.556640625, Cost 64.68522810935974 s\n",
      "Epoch 3688, Train loss 0.0002855379608838714, Test loss 0.1523677885532379, Train accuracy 100.0, Test accuracy 95.556640625, Cost 64.60486841201782 s\n",
      "Epoch 3689, Train loss 0.0002802511891266996, Test loss 0.15179357323795556, Train accuracy 100.0, Test accuracy 95.517578125, Cost 64.59322023391724 s\n",
      "Epoch 3690, Train loss 0.0002850632343473322, Test loss 0.15050320103764533, Train accuracy 100.0, Test accuracy 95.56640625, Cost 64.57539892196655 s\n",
      "Model saved in epoch 3690\n",
      "Epoch 3691, Train loss 0.0002753101558037273, Test loss 0.15212348625063896, Train accuracy 100.0, Test accuracy 95.537109375, Cost 64.75227570533752 s\n",
      "Epoch 3692, Train loss 0.00028460443131827595, Test loss 0.1525111621245742, Train accuracy 100.0, Test accuracy 95.517578125, Cost 64.75408887863159 s\n",
      "Epoch 3693, Train loss 0.00028195423948666445, Test loss 0.15040890201926232, Train accuracy 100.0, Test accuracy 95.546875, Cost 64.76655721664429 s\n",
      "Epoch 3694, Train loss 0.0003031296149930888, Test loss 0.15304013378918171, Train accuracy 100.0, Test accuracy 95.732421875, Cost 64.72742938995361 s\n",
      "Epoch 3695, Train loss 0.000281883429198963, Test loss 0.1521109564229846, Train accuracy 100.0, Test accuracy 95.654296875, Cost 64.64722013473511 s\n",
      "Model saved in epoch 3695\n",
      "Epoch 3696, Train loss 0.0002843422973492867, Test loss 0.15141891967505217, Train accuracy 100.0, Test accuracy 95.44921875, Cost 64.62193083763123 s\n",
      "Epoch 3697, Train loss 0.00027697121022727666, Test loss 0.15119011513888836, Train accuracy 100.0, Test accuracy 95.537109375, Cost 64.66501784324646 s\n",
      "Epoch 3698, Train loss 0.0002781124330423915, Test loss 0.15147189740091563, Train accuracy 100.0, Test accuracy 95.546875, Cost 64.6706953048706 s\n",
      "Epoch 3699, Train loss 0.00027623941905960457, Test loss 0.1510259686037898, Train accuracy 100.0, Test accuracy 95.654296875, Cost 64.66585993766785 s\n",
      "Epoch 3700, Train loss 0.000269030342567522, Test loss 0.15149793680757284, Train accuracy 100.0, Test accuracy 95.654296875, Cost 64.7136778831482 s\n",
      "Model saved in epoch 3700\n",
      "Epoch 3701, Train loss 0.00029422291570844377, Test loss 0.15093261282891035, Train accuracy 100.0, Test accuracy 95.68359375, Cost 64.74058127403259 s\n",
      "Epoch 3702, Train loss 0.00027081157984829756, Test loss 0.1522018188610673, Train accuracy 100.0, Test accuracy 95.64453125, Cost 64.7001838684082 s\n",
      "Epoch 3703, Train loss 0.0002709844113120866, Test loss 0.15188925825059413, Train accuracy 100.0, Test accuracy 95.546875, Cost 64.66674304008484 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3704, Train loss 0.00026707064297420865, Test loss 0.15285251047462226, Train accuracy 100.0, Test accuracy 95.44921875, Cost 64.66083312034607 s\n",
      "Epoch 3705, Train loss 0.00027683860441486886, Test loss 0.15416743494570256, Train accuracy 100.0, Test accuracy 95.52734375, Cost 64.669504404068 s\n",
      "Model saved in epoch 3705\n",
      "Epoch 3706, Train loss 0.00027018597474849155, Test loss 0.15179488714784384, Train accuracy 100.0, Test accuracy 95.537109375, Cost 64.71012854576111 s\n",
      "Epoch 3707, Train loss 0.00027740259225093, Test loss 0.1537685113027692, Train accuracy 100.0, Test accuracy 95.5078125, Cost 64.67824053764343 s\n",
      "Epoch 3708, Train loss 0.0002695848266665387, Test loss 0.15319801215082407, Train accuracy 100.0, Test accuracy 95.5078125, Cost 64.6728584766388 s\n",
      "Epoch 3709, Train loss 0.00028344651649121614, Test loss 0.15140049196779728, Train accuracy 100.0, Test accuracy 95.56640625, Cost 64.68467998504639 s\n",
      "Epoch 3710, Train loss 0.000271737741764364, Test loss 0.15331452637910842, Train accuracy 100.0, Test accuracy 95.625, Cost 64.64199614524841 s\n",
      "Model saved in epoch 3710\n",
      "Epoch 3711, Train loss 0.00028485047020082246, Test loss 0.15422443971037864, Train accuracy 100.0, Test accuracy 95.546875, Cost 64.6739227771759 s\n",
      "Epoch 3712, Train loss 0.00027391211974923973, Test loss 0.1533493397757411, Train accuracy 100.0, Test accuracy 95.556640625, Cost 64.67708349227905 s\n",
      "Epoch 3713, Train loss 0.00033240651464438997, Test loss 0.15422214157879352, Train accuracy 100.0, Test accuracy 95.25390625, Cost 64.67634391784668 s\n",
      "Epoch 3714, Train loss 0.00029289292559747546, Test loss 0.15473552960902454, Train accuracy 100.0, Test accuracy 95.478515625, Cost 65.04567861557007 s\n",
      "Epoch 3715, Train loss 0.00028577605494041453, Test loss 0.15449168104678393, Train accuracy 100.0, Test accuracy 95.29296875, Cost 65.24158430099487 s\n",
      "Model saved in epoch 3715\n",
      "Epoch 3716, Train loss 0.0002719794580598875, Test loss 0.15332623440772294, Train accuracy 100.0, Test accuracy 95.44921875, Cost 65.25373983383179 s\n",
      "Epoch 3717, Train loss 0.0002750073525726757, Test loss 0.15448020529001952, Train accuracy 100.0, Test accuracy 95.419921875, Cost 65.22062468528748 s\n",
      "Epoch 3718, Train loss 0.0002728514862573487, Test loss 0.15549826789647342, Train accuracy 100.0, Test accuracy 95.205078125, Cost 65.19593071937561 s\n",
      "Epoch 3719, Train loss 0.0002826074141550486, Test loss 0.1532280994579196, Train accuracy 100.0, Test accuracy 95.3125, Cost 65.22625088691711 s\n",
      "Epoch 3720, Train loss 0.00028258204868191627, Test loss 0.15623354632407427, Train accuracy 100.0, Test accuracy 95.2734375, Cost 65.23836064338684 s\n",
      "Model saved in epoch 3720\n",
      "Epoch 3721, Train loss 0.15117818010519246, Test loss 0.27871421054005624, Train accuracy 95.0179368622449, Test accuracy 90.44921875, Cost 65.19734954833984 s\n",
      "Epoch 3722, Train loss 0.12356987633571333, Test loss 0.26941343434154985, Train accuracy 95.97616390306122, Test accuracy 91.435546875, Cost 65.16650247573853 s\n",
      "Epoch 3723, Train loss 0.08329079101546383, Test loss 0.25080618597567084, Train accuracy 97.23891900510205, Test accuracy 92.158203125, Cost 65.02381944656372 s\n",
      "Epoch 3724, Train loss 0.058513956334517926, Test loss 0.22749859411269427, Train accuracy 98.11822385204081, Test accuracy 92.978515625, Cost 64.68050503730774 s\n",
      "Epoch 3725, Train loss 0.03961142647669327, Test loss 0.2297054460272193, Train accuracy 98.78946109693878, Test accuracy 93.0859375, Cost 64.66126108169556 s\n",
      "Model saved in epoch 3725\n",
      "Epoch 3726, Train loss 0.04686549836674667, Test loss 0.22697326689958572, Train accuracy 98.4375, Test accuracy 93.359375, Cost 64.6811854839325 s\n",
      "Epoch 3727, Train loss 0.03392827213380714, Test loss 0.24222134314477445, Train accuracy 98.95886479591837, Test accuracy 93.095703125, Cost 65.23613739013672 s\n",
      "Epoch 3728, Train loss 0.03180315617795045, Test loss 0.24935512728989123, Train accuracy 98.9975286989796, Test accuracy 92.75390625, Cost 65.2286024093628 s\n",
      "Epoch 3729, Train loss 0.028040796558714796, Test loss 0.2189698576927185, Train accuracy 99.13105867346938, Test accuracy 93.80859375, Cost 65.23558902740479 s\n",
      "Epoch 3730, Train loss 0.018970663743616292, Test loss 0.23058731965720652, Train accuracy 99.43797831632654, Test accuracy 93.232421875, Cost 65.22591090202332 s\n",
      "Model saved in epoch 3730\n",
      "Epoch 3731, Train loss 0.01731647645617474, Test loss 0.221048603951931, Train accuracy 99.48979591836735, Test accuracy 93.73046875, Cost 65.21371626853943 s\n",
      "Epoch 3732, Train loss 0.01090547697599597, Test loss 0.23834506161510943, Train accuracy 99.72098214285714, Test accuracy 93.69140625, Cost 65.33519077301025 s\n",
      "Epoch 3733, Train loss 0.012894307114112628, Test loss 0.22053672131150961, Train accuracy 99.67075892857143, Test accuracy 93.896484375, Cost 65.26564288139343 s\n",
      "Epoch 3734, Train loss 0.013476938812290224, Test loss 0.2506582625210285, Train accuracy 99.61734693877551, Test accuracy 93.623046875, Cost 65.22625827789307 s\n",
      "Epoch 3735, Train loss 0.012824189743473746, Test loss 0.2423273455351591, Train accuracy 99.61734693877551, Test accuracy 93.603515625, Cost 65.20506358146667 s\n",
      "Model saved in epoch 3735\n",
      "Epoch 3736, Train loss 0.012166093427887452, Test loss 0.2172688130289316, Train accuracy 99.64046556122449, Test accuracy 94.19921875, Cost 64.8475034236908 s\n",
      "Epoch 3737, Train loss 0.012477982694245115, Test loss 0.26008118465542795, Train accuracy 99.59303252551021, Test accuracy 93.65234375, Cost 64.66274738311768 s\n",
      "Epoch 3738, Train loss 0.011036096599870076, Test loss 0.22785689365118741, Train accuracy 99.6827168367347, Test accuracy 94.248046875, Cost 64.67156481742859 s\n",
      "Epoch 3739, Train loss 0.00816810396511811, Test loss 0.22298050075769424, Train accuracy 99.77439413265306, Test accuracy 94.27734375, Cost 64.70077395439148 s\n",
      "Epoch 3740, Train loss 0.009793636017854383, Test loss 0.23455593250691892, Train accuracy 99.71101721938776, Test accuracy 93.955078125, Cost 64.69144797325134 s\n",
      "Model saved in epoch 3740\n",
      "Epoch 3741, Train loss 0.006470049466826117, Test loss 0.2401867039501667, Train accuracy 99.83657525510205, Test accuracy 93.76953125, Cost 64.68309044837952 s\n",
      "Epoch 3742, Train loss 0.0062672732188841515, Test loss 0.23485720101743937, Train accuracy 99.82860331632654, Test accuracy 94.23828125, Cost 64.6680839061737 s\n",
      "Epoch 3743, Train loss 0.00338758824408596, Test loss 0.23544864896684886, Train accuracy 99.91629464285714, Test accuracy 94.248046875, Cost 64.68069672584534 s\n",
      "Epoch 3744, Train loss 0.005505952755718644, Test loss 0.23800843823701143, Train accuracy 99.84654017857143, Test accuracy 94.052734375, Cost 64.87835478782654 s\n",
      "Epoch 3745, Train loss 0.0031434815265333317, Test loss 0.21755097117275, Train accuracy 99.92426658163265, Test accuracy 94.580078125, Cost 65.20245957374573 s\n",
      "Model saved in epoch 3745\n",
      "Epoch 3746, Train loss 0.0026747157213061917, Test loss 0.22574818767607213, Train accuracy 99.94021045918367, Test accuracy 94.228515625, Cost 65.22439098358154 s\n",
      "Epoch 3747, Train loss 0.0022000032592159745, Test loss 0.2286392290145159, Train accuracy 99.95575573979592, Test accuracy 94.43359375, Cost 65.10003113746643 s\n",
      "Epoch 3748, Train loss 0.005551350898286375, Test loss 0.2332591198384762, Train accuracy 99.84255420918367, Test accuracy 93.90625, Cost 64.81151342391968 s\n",
      "Epoch 3749, Train loss 0.005882313515847235, Test loss 0.230294987000525, Train accuracy 99.84056122448979, Test accuracy 94.0625, Cost 64.77094054222107 s\n",
      "Epoch 3750, Train loss 0.0029379598732814385, Test loss 0.2128164717927575, Train accuracy 99.9282525510204, Test accuracy 94.765625, Cost 64.79215908050537 s\n",
      "Model saved in epoch 3750\n",
      "Epoch 3751, Train loss 0.002970560436830167, Test loss 0.23693681564182043, Train accuracy 99.93622448979592, Test accuracy 94.12109375, Cost 64.70633912086487 s\n",
      "Epoch 3752, Train loss 0.0023605688786156693, Test loss 0.2211820274591446, Train accuracy 99.96014030612245, Test accuracy 94.345703125, Cost 64.7298469543457 s\n",
      "Epoch 3753, Train loss 0.00302533864097703, Test loss 0.2397408841177821, Train accuracy 99.93024553571429, Test accuracy 94.140625, Cost 64.74084687232971 s\n",
      "Epoch 3754, Train loss 0.0024418697775013707, Test loss 0.23506890796124935, Train accuracy 99.95017538265306, Test accuracy 94.16015625, Cost 64.7569694519043 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3755, Train loss 0.0016716598745136122, Test loss 0.22571779061108826, Train accuracy 99.96412627551021, Test accuracy 94.47265625, Cost 64.77101230621338 s\n",
      "Model saved in epoch 3755\n",
      "Epoch 3756, Train loss 0.001163351985807673, Test loss 0.22281818464398384, Train accuracy 99.98604910714286, Test accuracy 94.62890625, Cost 64.80190300941467 s\n",
      "Epoch 3757, Train loss 0.000594591705966919, Test loss 0.20437568463385106, Train accuracy 99.99800701530613, Test accuracy 95.2734375, Cost 64.80203080177307 s\n",
      "Epoch 3758, Train loss 0.0004691343523778154, Test loss 0.2070890637114644, Train accuracy 100.0, Test accuracy 94.990234375, Cost 64.7844648361206 s\n",
      "Epoch 3759, Train loss 0.0003565807645809029, Test loss 0.2101249847561121, Train accuracy 100.0, Test accuracy 95.146484375, Cost 64.78739738464355 s\n",
      "Epoch 3760, Train loss 0.00036491663050416105, Test loss 0.2080275435000658, Train accuracy 99.99800701530613, Test accuracy 95.048828125, Cost 64.8041501045227 s\n",
      "Model saved in epoch 3760\n",
      "Epoch 3761, Train loss 0.00032777323261199147, Test loss 0.20215107668191196, Train accuracy 100.0, Test accuracy 95.107421875, Cost 64.7136869430542 s\n",
      "Epoch 3762, Train loss 0.000282084255763484, Test loss 0.2036579603329301, Train accuracy 100.0, Test accuracy 95.029296875, Cost 64.68971514701843 s\n",
      "Epoch 3763, Train loss 0.00041024320040489734, Test loss 0.2046415401622653, Train accuracy 99.99402104591837, Test accuracy 94.84375, Cost 64.82580399513245 s\n",
      "Epoch 3764, Train loss 0.0004760374580358502, Test loss 0.2040081424638629, Train accuracy 99.99601403061224, Test accuracy 94.9609375, Cost 64.72524738311768 s\n",
      "Epoch 3765, Train loss 0.0003143039794311483, Test loss 0.1992153214290738, Train accuracy 99.99800701530613, Test accuracy 95.107421875, Cost 64.7098035812378 s\n",
      "Model saved in epoch 3765\n",
      "Epoch 3766, Train loss 0.0005023376463436669, Test loss 0.20411650296300649, Train accuracy 99.99202806122449, Test accuracy 94.990234375, Cost 64.75552582740784 s\n",
      "Epoch 3767, Train loss 0.00027379769089376927, Test loss 0.1996203750371933, Train accuracy 100.0, Test accuracy 94.990234375, Cost 64.77997422218323 s\n",
      "Epoch 3768, Train loss 0.00028033924558703617, Test loss 0.20073513146489858, Train accuracy 100.0, Test accuracy 94.98046875, Cost 64.80120205879211 s\n",
      "Epoch 3769, Train loss 0.00021814335210662222, Test loss 0.20196465495973825, Train accuracy 100.0, Test accuracy 94.931640625, Cost 64.80159282684326 s\n",
      "Epoch 3770, Train loss 0.00031439959002455, Test loss 0.2020201249048114, Train accuracy 99.99601403061224, Test accuracy 94.873046875, Cost 64.77602028846741 s\n",
      "Model saved in epoch 3770\n",
      "Epoch 3771, Train loss 0.0002293665148703885, Test loss 0.19643541146069765, Train accuracy 100.0, Test accuracy 95.205078125, Cost 64.76705026626587 s\n",
      "Epoch 3772, Train loss 0.00021866414674001804, Test loss 0.19907697569578886, Train accuracy 100.0, Test accuracy 95.146484375, Cost 64.73864531517029 s\n",
      "Epoch 3773, Train loss 0.00025610580265418657, Test loss 0.19730164892971516, Train accuracy 100.0, Test accuracy 95.29296875, Cost 64.9436731338501 s\n",
      "Epoch 3774, Train loss 0.00022540985799200918, Test loss 0.19422212187200785, Train accuracy 100.0, Test accuracy 95.263671875, Cost 65.24470925331116 s\n",
      "Epoch 3775, Train loss 0.00021405901731798491, Test loss 0.19208868276327848, Train accuracy 100.0, Test accuracy 95.29296875, Cost 65.22802305221558 s\n",
      "Model saved in epoch 3775\n",
      "Epoch 3776, Train loss 0.00018499543868380657, Test loss 0.1923696521669626, Train accuracy 100.0, Test accuracy 95.17578125, Cost 65.23442602157593 s\n",
      "Epoch 3777, Train loss 0.00017858625821589864, Test loss 0.19126079473644494, Train accuracy 100.0, Test accuracy 95.283203125, Cost 65.23524141311646 s\n",
      "Epoch 3778, Train loss 0.0001713831174203399, Test loss 0.19039593860507012, Train accuracy 100.0, Test accuracy 95.205078125, Cost 65.1958224773407 s\n",
      "Epoch 3779, Train loss 0.00017917335169061386, Test loss 0.18947408795356752, Train accuracy 100.0, Test accuracy 95.283203125, Cost 65.18396735191345 s\n",
      "Epoch 3780, Train loss 0.0001685059465411801, Test loss 0.18704976029694081, Train accuracy 100.0, Test accuracy 95.224609375, Cost 65.22417068481445 s\n",
      "Model saved in epoch 3780\n",
      "Epoch 3781, Train loss 0.00017145295547676625, Test loss 0.1877745410427451, Train accuracy 100.0, Test accuracy 95.234375, Cost 65.21746873855591 s\n",
      "Epoch 3782, Train loss 0.0001816804591986251, Test loss 0.18634068164974452, Train accuracy 100.0, Test accuracy 95.419921875, Cost 65.216867685318 s\n",
      "Epoch 3783, Train loss 0.00016764821107151837, Test loss 0.1876389542594552, Train accuracy 100.0, Test accuracy 95.439453125, Cost 65.21072387695312 s\n",
      "Epoch 3784, Train loss 0.00018338045087222448, Test loss 0.18522907327860594, Train accuracy 100.0, Test accuracy 95.390625, Cost 65.20539212226868 s\n",
      "Epoch 3785, Train loss 0.00018549226245210906, Test loss 0.18396930880844592, Train accuracy 100.0, Test accuracy 95.400390625, Cost 65.22196507453918 s\n",
      "Model saved in epoch 3785\n",
      "Epoch 3786, Train loss 0.00016646888033559364, Test loss 0.18481302224099636, Train accuracy 100.0, Test accuracy 95.37109375, Cost 65.26014542579651 s\n",
      "Epoch 3787, Train loss 0.0001898804315418119, Test loss 0.18497648946940898, Train accuracy 100.0, Test accuracy 95.44921875, Cost 65.09706974029541 s\n",
      "Epoch 3788, Train loss 0.0001958897270683059, Test loss 0.18601702097803355, Train accuracy 100.0, Test accuracy 95.302734375, Cost 64.72338509559631 s\n",
      "Epoch 3789, Train loss 0.00018646123758766668, Test loss 0.1857899548485875, Train accuracy 100.0, Test accuracy 95.41015625, Cost 64.69913482666016 s\n",
      "Epoch 3790, Train loss 0.00019568794804009876, Test loss 0.18873358685523273, Train accuracy 100.0, Test accuracy 95.380859375, Cost 65.11328315734863 s\n",
      "Model saved in epoch 3790\n",
      "Epoch 3791, Train loss 0.00018606341120398518, Test loss 0.18551042452454566, Train accuracy 100.0, Test accuracy 95.3515625, Cost 64.8606743812561 s\n",
      "Epoch 3792, Train loss 0.00020051536212493522, Test loss 0.18389973733574153, Train accuracy 100.0, Test accuracy 95.41015625, Cost 64.80056548118591 s\n",
      "Epoch 3793, Train loss 0.00018640012158543034, Test loss 0.18454727306962013, Train accuracy 100.0, Test accuracy 95.41015625, Cost 64.77041625976562 s\n",
      "Epoch 3794, Train loss 0.0001903148423313111, Test loss 0.18240432050079108, Train accuracy 100.0, Test accuracy 95.380859375, Cost 64.7541196346283 s\n",
      "Epoch 3795, Train loss 0.00016557700811452896, Test loss 0.18114041816443205, Train accuracy 100.0, Test accuracy 95.41015625, Cost 64.76435732841492 s\n",
      "Model saved in epoch 3795\n",
      "Epoch 3796, Train loss 0.00020921570051411566, Test loss 0.1839684983715415, Train accuracy 99.99800701530613, Test accuracy 95.244140625, Cost 64.8160629272461 s\n",
      "Epoch 3797, Train loss 0.00022408351491767277, Test loss 0.183262836933136, Train accuracy 100.0, Test accuracy 95.3515625, Cost 64.80370163917542 s\n",
      "Epoch 3798, Train loss 0.00019184178266613697, Test loss 0.1841001795604825, Train accuracy 100.0, Test accuracy 95.3125, Cost 64.80457019805908 s\n",
      "Epoch 3799, Train loss 0.00019852118800502337, Test loss 0.1817914256826043, Train accuracy 100.0, Test accuracy 95.322265625, Cost 64.78113293647766 s\n",
      "Epoch 3800, Train loss 0.00019898475856818402, Test loss 0.17973457872867585, Train accuracy 100.0, Test accuracy 95.439453125, Cost 64.805490732193 s\n",
      "Model saved in epoch 3800\n",
      "Epoch 3801, Train loss 0.00020630279857646294, Test loss 0.17957323417067528, Train accuracy 100.0, Test accuracy 95.37109375, Cost 64.78725099563599 s\n",
      "Epoch 3802, Train loss 0.00019389786668435422, Test loss 0.17987841200083493, Train accuracy 100.0, Test accuracy 95.3515625, Cost 64.78450345993042 s\n",
      "Epoch 3803, Train loss 0.0002021135736199818, Test loss 0.18025814946740865, Train accuracy 100.0, Test accuracy 95.37109375, Cost 64.79203343391418 s\n",
      "Epoch 3804, Train loss 0.00019975146917241378, Test loss 0.1791374247521162, Train accuracy 100.0, Test accuracy 95.390625, Cost 64.7918221950531 s\n",
      "Epoch 3805, Train loss 0.00018995538708363062, Test loss 0.17803852427750827, Train accuracy 100.0, Test accuracy 95.3515625, Cost 64.73388266563416 s\n",
      "Model saved in epoch 3805\n",
      "Epoch 3806, Train loss 0.0001996556081709913, Test loss 0.17648899517953395, Train accuracy 100.0, Test accuracy 95.380859375, Cost 64.79671692848206 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3807, Train loss 0.00018924537913075516, Test loss 0.17658968474715947, Train accuracy 100.0, Test accuracy 95.439453125, Cost 64.76762223243713 s\n",
      "Epoch 3808, Train loss 0.00019555014255367534, Test loss 0.1761974034830928, Train accuracy 100.0, Test accuracy 95.498046875, Cost 64.72056818008423 s\n",
      "Epoch 3809, Train loss 0.00019682957667546176, Test loss 0.1781589187681675, Train accuracy 100.0, Test accuracy 95.439453125, Cost 64.7178168296814 s\n",
      "Epoch 3810, Train loss 0.00020517896437199018, Test loss 0.17698182836174964, Train accuracy 100.0, Test accuracy 95.390625, Cost 64.7132179737091 s\n",
      "Model saved in epoch 3810\n",
      "Epoch 3811, Train loss 0.00020381855173749202, Test loss 0.17569182626903057, Train accuracy 100.0, Test accuracy 95.400390625, Cost 64.61219525337219 s\n",
      "Epoch 3812, Train loss 0.00019683536150723183, Test loss 0.1775427082553506, Train accuracy 100.0, Test accuracy 95.400390625, Cost 64.67570400238037 s\n",
      "Epoch 3813, Train loss 0.00020510194279230913, Test loss 0.17598244026303292, Train accuracy 100.0, Test accuracy 95.517578125, Cost 64.65055751800537 s\n",
      "Epoch 3814, Train loss 0.000202716854411327, Test loss 0.17671214491128923, Train accuracy 100.0, Test accuracy 95.44921875, Cost 64.6952793598175 s\n",
      "Epoch 3815, Train loss 0.000200407656050128, Test loss 0.1762481989338994, Train accuracy 100.0, Test accuracy 95.3515625, Cost 64.68935441970825 s\n",
      "Model saved in epoch 3815\n",
      "Epoch 3816, Train loss 0.000210933985207313, Test loss 0.1755265614017844, Train accuracy 100.0, Test accuracy 95.390625, Cost 64.72375893592834 s\n",
      "Epoch 3817, Train loss 0.0001982308809713185, Test loss 0.173332766443491, Train accuracy 100.0, Test accuracy 95.400390625, Cost 64.71078538894653 s\n",
      "Epoch 3818, Train loss 0.0002121289316517282, Test loss 0.17391980960965156, Train accuracy 100.0, Test accuracy 95.4296875, Cost 64.68890190124512 s\n",
      "Epoch 3819, Train loss 0.00021379104350207668, Test loss 0.17439730558544397, Train accuracy 100.0, Test accuracy 95.41015625, Cost 64.65591835975647 s\n",
      "Epoch 3820, Train loss 0.0002059956451765694, Test loss 0.17453664876520633, Train accuracy 100.0, Test accuracy 95.380859375, Cost 64.66563940048218 s\n",
      "Model saved in epoch 3820\n",
      "Epoch 3821, Train loss 0.0002112914329960144, Test loss 0.17422476094216108, Train accuracy 100.0, Test accuracy 95.44921875, Cost 64.69954442977905 s\n",
      "Epoch 3822, Train loss 0.00022074735448879846, Test loss 0.17312478125095368, Train accuracy 100.0, Test accuracy 95.419921875, Cost 64.71305394172668 s\n",
      "Epoch 3823, Train loss 0.0002142879271856628, Test loss 0.17257517613470555, Train accuracy 100.0, Test accuracy 95.390625, Cost 64.76461601257324 s\n",
      "Epoch 3824, Train loss 0.00021429893455874384, Test loss 0.17172489929944276, Train accuracy 100.0, Test accuracy 95.37109375, Cost 64.72315311431885 s\n",
      "Epoch 3825, Train loss 0.00022469214290678644, Test loss 0.17162392996251583, Train accuracy 100.0, Test accuracy 95.3515625, Cost 64.67468571662903 s\n",
      "Model saved in epoch 3825\n",
      "Epoch 3826, Train loss 0.00022398201471499917, Test loss 0.17131303977221252, Train accuracy 100.0, Test accuracy 95.419921875, Cost 64.684250831604 s\n",
      "Epoch 3827, Train loss 0.00022409998631218867, Test loss 0.1713094472885132, Train accuracy 100.0, Test accuracy 95.341796875, Cost 64.77250862121582 s\n",
      "Epoch 3828, Train loss 0.00023067631906198993, Test loss 0.1698769371956587, Train accuracy 100.0, Test accuracy 95.4296875, Cost 64.97911834716797 s\n",
      "Epoch 3829, Train loss 0.00021776395401595474, Test loss 0.17432577051222325, Train accuracy 100.0, Test accuracy 95.33203125, Cost 64.92493295669556 s\n",
      "Epoch 3830, Train loss 0.00024306736426928072, Test loss 0.17145232539623975, Train accuracy 100.0, Test accuracy 95.390625, Cost 64.82476305961609 s\n",
      "Model saved in epoch 3830\n",
      "Epoch 3831, Train loss 0.0002296088416781514, Test loss 0.17098957430571318, Train accuracy 100.0, Test accuracy 95.400390625, Cost 64.77851057052612 s\n",
      "Epoch 3832, Train loss 0.0002928024542245334, Test loss 0.17020596899092197, Train accuracy 99.99800701530613, Test accuracy 95.419921875, Cost 64.7588701248169 s\n",
      "Epoch 3833, Train loss 0.000235396435230968, Test loss 0.17052927929908038, Train accuracy 100.0, Test accuracy 95.41015625, Cost 64.72990489006042 s\n",
      "Epoch 3834, Train loss 0.00023776254149234606, Test loss 0.16843992304056882, Train accuracy 100.0, Test accuracy 95.380859375, Cost 64.75976157188416 s\n",
      "Epoch 3835, Train loss 0.0002203109510149688, Test loss 0.1683364288881421, Train accuracy 100.0, Test accuracy 95.419921875, Cost 64.7714581489563 s\n",
      "Model saved in epoch 3835\n",
      "Epoch 3836, Train loss 0.00023451269340994815, Test loss 0.16949415411800145, Train accuracy 100.0, Test accuracy 95.3515625, Cost 64.78595852851868 s\n",
      "Epoch 3837, Train loss 0.00024212274469651414, Test loss 0.17202838249504565, Train accuracy 100.0, Test accuracy 95.283203125, Cost 64.7995502948761 s\n",
      "Epoch 3838, Train loss 0.00024551469705700734, Test loss 0.16926708891987802, Train accuracy 100.0, Test accuracy 95.3125, Cost 64.77853655815125 s\n",
      "Epoch 3839, Train loss 0.00023173493358700974, Test loss 0.16976395025849342, Train accuracy 100.0, Test accuracy 95.3125, Cost 64.79001784324646 s\n",
      "Epoch 3840, Train loss 0.00023133427537092702, Test loss 0.17064585033804178, Train accuracy 100.0, Test accuracy 95.29296875, Cost 64.76836276054382 s\n",
      "Model saved in epoch 3840\n",
      "Epoch 3841, Train loss 0.00023042066633785667, Test loss 0.16998876221477985, Train accuracy 100.0, Test accuracy 95.283203125, Cost 65.01547956466675 s\n",
      "Epoch 3842, Train loss 0.00022550433400005094, Test loss 0.16975773572921754, Train accuracy 100.0, Test accuracy 95.302734375, Cost 65.18080282211304 s\n",
      "Epoch 3843, Train loss 0.00024499065935111613, Test loss 0.16970325242727996, Train accuracy 100.0, Test accuracy 95.302734375, Cost 65.19919991493225 s\n",
      "Epoch 3844, Train loss 0.00023328974718739973, Test loss 0.16892762538045644, Train accuracy 100.0, Test accuracy 95.283203125, Cost 65.17897439002991 s\n",
      "Epoch 3845, Train loss 0.00024114895799988407, Test loss 0.16891906149685382, Train accuracy 100.0, Test accuracy 95.302734375, Cost 65.04561829566956 s\n",
      "Model saved in epoch 3845\n",
      "Epoch 3846, Train loss 0.0002378430041173896, Test loss 0.16957301180809736, Train accuracy 100.0, Test accuracy 95.33203125, Cost 65.16174936294556 s\n",
      "Epoch 3847, Train loss 0.0002442093777879526, Test loss 0.16759532056748866, Train accuracy 100.0, Test accuracy 95.341796875, Cost 64.75971221923828 s\n",
      "Epoch 3848, Train loss 0.0002477991228242528, Test loss 0.16750969756394624, Train accuracy 100.0, Test accuracy 95.3515625, Cost 64.70391368865967 s\n",
      "Epoch 3849, Train loss 0.00024063565370499641, Test loss 0.16930343452841043, Train accuracy 100.0, Test accuracy 95.380859375, Cost 64.69606637954712 s\n",
      "Epoch 3850, Train loss 0.0002465120611601861, Test loss 0.16849028300493957, Train accuracy 100.0, Test accuracy 95.37109375, Cost 64.69809365272522 s\n",
      "Model saved in epoch 3850\n",
      "Epoch 3851, Train loss 0.0002454356109985977, Test loss 0.16849806103855372, Train accuracy 100.0, Test accuracy 95.361328125, Cost 64.66770911216736 s\n",
      "Epoch 3852, Train loss 0.00023505779961628925, Test loss 0.1685095399618149, Train accuracy 100.0, Test accuracy 95.3515625, Cost 64.68435502052307 s\n",
      "Epoch 3853, Train loss 0.00024789584791988647, Test loss 0.16962230950593948, Train accuracy 100.0, Test accuracy 95.322265625, Cost 64.68817353248596 s\n",
      "Epoch 3854, Train loss 0.0002474561456159679, Test loss 0.17002736479043962, Train accuracy 100.0, Test accuracy 95.3515625, Cost 64.74513602256775 s\n",
      "Epoch 3855, Train loss 0.0002509374941410544, Test loss 0.16924420837312937, Train accuracy 100.0, Test accuracy 95.322265625, Cost 64.70416641235352 s\n",
      "Model saved in epoch 3855\n",
      "Epoch 3856, Train loss 0.0002547713602882363, Test loss 0.16923236642032863, Train accuracy 100.0, Test accuracy 95.341796875, Cost 64.68283081054688 s\n",
      "Epoch 3857, Train loss 0.00030454806961197577, Test loss 0.1665806133300066, Train accuracy 99.99800701530613, Test accuracy 95.33203125, Cost 64.68833470344543 s\n",
      "Epoch 3858, Train loss 0.00029018619170528837, Test loss 0.16734876334667206, Train accuracy 100.0, Test accuracy 95.33203125, Cost 64.67637634277344 s\n",
      "Epoch 3859, Train loss 0.00026644003001096355, Test loss 0.16817527040839195, Train accuracy 100.0, Test accuracy 95.33203125, Cost 64.67028498649597 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3860, Train loss 0.0002591120847144487, Test loss 0.16883814595639707, Train accuracy 100.0, Test accuracy 95.3125, Cost 64.63632774353027 s\n",
      "Model saved in epoch 3860\n",
      "Epoch 3861, Train loss 0.0002619629507980604, Test loss 0.16744358744472265, Train accuracy 100.0, Test accuracy 95.361328125, Cost 64.63220739364624 s\n",
      "Epoch 3862, Train loss 0.0002501789209900937, Test loss 0.16716282293200493, Train accuracy 100.0, Test accuracy 95.41015625, Cost 64.92119550704956 s\n",
      "Epoch 3863, Train loss 0.00026672459100563156, Test loss 0.16862028520554304, Train accuracy 100.0, Test accuracy 95.283203125, Cost 64.947829246521 s\n",
      "Epoch 3864, Train loss 0.00025627611485477396, Test loss 0.16655613016337156, Train accuracy 100.0, Test accuracy 95.400390625, Cost 64.93859624862671 s\n",
      "Epoch 3865, Train loss 0.00025680131496913847, Test loss 0.1654565054923296, Train accuracy 100.0, Test accuracy 95.3515625, Cost 64.94454646110535 s\n",
      "Model saved in epoch 3865\n",
      "Epoch 3866, Train loss 0.00026452975577498996, Test loss 0.1669287785887718, Train accuracy 100.0, Test accuracy 95.33203125, Cost 65.16388487815857 s\n",
      "Epoch 3867, Train loss 0.00024884394625420396, Test loss 0.16698514837771655, Train accuracy 100.0, Test accuracy 95.361328125, Cost 65.23925685882568 s\n",
      "Epoch 3868, Train loss 0.0002604077643048427, Test loss 0.1670454990118742, Train accuracy 100.0, Test accuracy 95.302734375, Cost 65.21772813796997 s\n",
      "Epoch 3869, Train loss 0.00026216985037424414, Test loss 0.16624845061451196, Train accuracy 100.0, Test accuracy 95.33203125, Cost 65.21110320091248 s\n",
      "Epoch 3870, Train loss 0.000268287940900559, Test loss 0.16687762513756751, Train accuracy 100.0, Test accuracy 95.322265625, Cost 65.21470761299133 s\n",
      "Model saved in epoch 3870\n",
      "Epoch 3871, Train loss 0.0002728451422162649, Test loss 0.16760913636535407, Train accuracy 100.0, Test accuracy 95.341796875, Cost 65.19562911987305 s\n",
      "Epoch 3872, Train loss 0.0002577623016971914, Test loss 0.16777378767728807, Train accuracy 100.0, Test accuracy 95.322265625, Cost 65.19057369232178 s\n",
      "Epoch 3873, Train loss 0.0002536951269204871, Test loss 0.16650113593786955, Train accuracy 100.0, Test accuracy 95.361328125, Cost 65.17356896400452 s\n",
      "Epoch 3874, Train loss 0.00025450161321751525, Test loss 0.16725187115371226, Train accuracy 100.0, Test accuracy 95.3125, Cost 65.02607774734497 s\n",
      "Epoch 3875, Train loss 0.00025159199841644816, Test loss 0.1680284971371293, Train accuracy 100.0, Test accuracy 95.2734375, Cost 65.00853252410889 s\n",
      "Model saved in epoch 3875\n",
      "Epoch 3876, Train loss 0.0002601412924544705, Test loss 0.16702716872096063, Train accuracy 100.0, Test accuracy 95.29296875, Cost 65.22725939750671 s\n",
      "Epoch 3877, Train loss 0.0002591458971289043, Test loss 0.1665149314329028, Train accuracy 100.0, Test accuracy 95.283203125, Cost 65.22409534454346 s\n",
      "Epoch 3878, Train loss 0.00025877615449384654, Test loss 0.16647278368473054, Train accuracy 100.0, Test accuracy 95.322265625, Cost 65.21366548538208 s\n",
      "Epoch 3879, Train loss 0.00025776506329432835, Test loss 0.16559744924306868, Train accuracy 100.0, Test accuracy 95.341796875, Cost 65.21570158004761 s\n",
      "Epoch 3880, Train loss 0.00025601135630680876, Test loss 0.16483954396098852, Train accuracy 100.0, Test accuracy 95.322265625, Cost 65.224285364151 s\n",
      "Model saved in epoch 3880\n",
      "Epoch 3881, Train loss 0.00025518419827175404, Test loss 0.16500178314745426, Train accuracy 100.0, Test accuracy 95.380859375, Cost 65.21925711631775 s\n",
      "Epoch 3882, Train loss 0.00026069062213147324, Test loss 0.16455372478812932, Train accuracy 100.0, Test accuracy 95.37109375, Cost 65.21645545959473 s\n",
      "Epoch 3883, Train loss 0.0002651394214789972, Test loss 0.16530721336603166, Train accuracy 100.0, Test accuracy 95.25390625, Cost 65.21524214744568 s\n",
      "Epoch 3884, Train loss 0.00025178512939363624, Test loss 0.16597516592592002, Train accuracy 100.0, Test accuracy 95.302734375, Cost 65.20157837867737 s\n",
      "Epoch 3885, Train loss 0.00026298154930094714, Test loss 0.16588324159383774, Train accuracy 100.0, Test accuracy 95.3125, Cost 65.23873519897461 s\n",
      "Model saved in epoch 3885\n",
      "Epoch 3886, Train loss 0.00026447552613253534, Test loss 0.16530652064830065, Train accuracy 100.0, Test accuracy 95.341796875, Cost 65.27580857276917 s\n",
      "Epoch 3887, Train loss 0.0002665128918959788, Test loss 0.1653912305831909, Train accuracy 100.0, Test accuracy 95.3515625, Cost 65.19033908843994 s\n",
      "Epoch 3888, Train loss 0.00026575753531223923, Test loss 0.1649335529655218, Train accuracy 100.0, Test accuracy 95.390625, Cost 65.17623496055603 s\n",
      "Epoch 3889, Train loss 0.00026311667014462207, Test loss 0.16555965337902306, Train accuracy 100.0, Test accuracy 95.3515625, Cost 65.21503901481628 s\n",
      "Epoch 3890, Train loss 0.000262633318888387, Test loss 0.166121537797153, Train accuracy 100.0, Test accuracy 95.3515625, Cost 65.23141813278198 s\n",
      "Model saved in epoch 3890\n",
      "Epoch 3891, Train loss 0.00025863025387349935, Test loss 0.16413272451609373, Train accuracy 100.0, Test accuracy 95.341796875, Cost 65.19251823425293 s\n",
      "Epoch 3892, Train loss 0.00025783713002111856, Test loss 0.16362206172198057, Train accuracy 100.0, Test accuracy 95.361328125, Cost 65.20080018043518 s\n",
      "Epoch 3893, Train loss 0.0002569583910149142, Test loss 0.16464110147207975, Train accuracy 100.0, Test accuracy 95.380859375, Cost 65.19709610939026 s\n",
      "Epoch 3894, Train loss 0.00025345568146618386, Test loss 0.16305011976510286, Train accuracy 100.0, Test accuracy 95.37109375, Cost 65.19015192985535 s\n",
      "Epoch 3895, Train loss 0.0002668687541569982, Test loss 0.16384801547974348, Train accuracy 100.0, Test accuracy 95.3515625, Cost 65.20084381103516 s\n",
      "Model saved in epoch 3895\n",
      "Epoch 3896, Train loss 0.00025839833042296884, Test loss 0.16448784787207843, Train accuracy 100.0, Test accuracy 95.390625, Cost 65.22257900238037 s\n",
      "Epoch 3897, Train loss 0.00026764991685477256, Test loss 0.16623231302946806, Train accuracy 100.0, Test accuracy 95.302734375, Cost 65.18909358978271 s\n",
      "Epoch 3898, Train loss 0.0002690827773500243, Test loss 0.16346213705837725, Train accuracy 100.0, Test accuracy 95.33203125, Cost 65.21532320976257 s\n",
      "Epoch 3899, Train loss 0.00026384155653988493, Test loss 0.16364291850477458, Train accuracy 100.0, Test accuracy 95.400390625, Cost 65.19911074638367 s\n",
      "Epoch 3900, Train loss 0.0002693944595509437, Test loss 0.16408771630376578, Train accuracy 100.0, Test accuracy 95.3515625, Cost 65.17978572845459 s\n",
      "Model saved in epoch 3900\n",
      "Epoch 3901, Train loss 0.0002581094899030678, Test loss 0.1631098108366132, Train accuracy 100.0, Test accuracy 95.361328125, Cost 65.14900350570679 s\n",
      "Epoch 3902, Train loss 0.00026787968090502545, Test loss 0.16478926111012698, Train accuracy 100.0, Test accuracy 95.390625, Cost 65.18466305732727 s\n",
      "Epoch 3903, Train loss 0.0002725071742820639, Test loss 0.16498962938785552, Train accuracy 100.0, Test accuracy 95.341796875, Cost 65.1930525302887 s\n",
      "Epoch 3904, Train loss 0.0002786606650149725, Test loss 0.1632035542279482, Train accuracy 100.0, Test accuracy 95.390625, Cost 65.20479106903076 s\n",
      "Epoch 3905, Train loss 0.00027667695632066616, Test loss 0.16266125310212373, Train accuracy 100.0, Test accuracy 95.322265625, Cost 65.20602703094482 s\n",
      "Model saved in epoch 3905\n",
      "Epoch 3906, Train loss 0.0002793653969705219, Test loss 0.1630431279540062, Train accuracy 100.0, Test accuracy 95.302734375, Cost 65.21707725524902 s\n",
      "Epoch 3907, Train loss 0.00026076586926843, Test loss 0.16425974555313588, Train accuracy 100.0, Test accuracy 95.263671875, Cost 65.21137547492981 s\n",
      "Epoch 3908, Train loss 0.0002638401583309894, Test loss 0.1636557150632143, Train accuracy 100.0, Test accuracy 95.361328125, Cost 65.19790506362915 s\n",
      "Epoch 3909, Train loss 0.00029727335603805545, Test loss 0.1639403525739908, Train accuracy 100.0, Test accuracy 95.29296875, Cost 65.21964812278748 s\n",
      "Epoch 3910, Train loss 0.00027745309608337486, Test loss 0.163381321541965, Train accuracy 100.0, Test accuracy 95.341796875, Cost 65.24750280380249 s\n",
      "Model saved in epoch 3910\n",
      "Epoch 3911, Train loss 0.000264750139334011, Test loss 0.1644992170855403, Train accuracy 100.0, Test accuracy 95.3125, Cost 65.20391774177551 s\n",
      "Epoch 3912, Train loss 0.00026448183988187727, Test loss 0.16298416908830404, Train accuracy 100.0, Test accuracy 95.33203125, Cost 65.12668871879578 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3913, Train loss 0.0002658765932915694, Test loss 0.16349926684051752, Train accuracy 100.0, Test accuracy 95.380859375, Cost 65.18025851249695 s\n",
      "Epoch 3914, Train loss 0.0002754146901549705, Test loss 0.16392908226698638, Train accuracy 100.0, Test accuracy 95.29296875, Cost 65.13252830505371 s\n",
      "Epoch 3915, Train loss 0.0002704298260549858, Test loss 0.16477430500090123, Train accuracy 100.0, Test accuracy 95.29296875, Cost 65.17917799949646 s\n",
      "Model saved in epoch 3915\n",
      "Epoch 3916, Train loss 0.00026531002694522317, Test loss 0.1628613794222474, Train accuracy 100.0, Test accuracy 95.3125, Cost 65.27848553657532 s\n",
      "Epoch 3917, Train loss 0.00029532459413939233, Test loss 0.1622368784621358, Train accuracy 100.0, Test accuracy 95.302734375, Cost 65.14916181564331 s\n",
      "Epoch 3918, Train loss 0.00027217068945530477, Test loss 0.16178280990570784, Train accuracy 100.0, Test accuracy 95.322265625, Cost 65.14280033111572 s\n",
      "Epoch 3919, Train loss 0.00028191565048027954, Test loss 0.1618688168004155, Train accuracy 100.0, Test accuracy 95.380859375, Cost 65.24339818954468 s\n",
      "Epoch 3920, Train loss 0.00027461121951964, Test loss 0.16269823536276817, Train accuracy 100.0, Test accuracy 95.33203125, Cost 65.25370478630066 s\n",
      "Model saved in epoch 3920\n",
      "Epoch 3921, Train loss 0.0002685488491676681, Test loss 0.16320611909031868, Train accuracy 100.0, Test accuracy 95.390625, Cost 65.25810861587524 s\n",
      "Epoch 3922, Train loss 0.00026583633111191114, Test loss 0.16193226240575315, Train accuracy 100.0, Test accuracy 95.361328125, Cost 65.2380952835083 s\n",
      "Epoch 3923, Train loss 0.0002709532405899562, Test loss 0.16390779986977577, Train accuracy 100.0, Test accuracy 95.29296875, Cost 65.23646903038025 s\n",
      "Epoch 3924, Train loss 0.0002583208951531263, Test loss 0.16220284309238195, Train accuracy 100.0, Test accuracy 95.3515625, Cost 65.23433232307434 s\n",
      "Epoch 3925, Train loss 0.000265081606571306, Test loss 0.16212219428271055, Train accuracy 100.0, Test accuracy 95.302734375, Cost 65.24675965309143 s\n",
      "Model saved in epoch 3925\n",
      "Epoch 3926, Train loss 0.0002619421417077728, Test loss 0.16330286618322135, Train accuracy 100.0, Test accuracy 95.361328125, Cost 65.23120641708374 s\n",
      "Epoch 3927, Train loss 0.00026239533638415324, Test loss 0.1627609958872199, Train accuracy 100.0, Test accuracy 95.3125, Cost 65.21099066734314 s\n",
      "Epoch 3928, Train loss 0.0002584158550865939, Test loss 0.16371033899486065, Train accuracy 100.0, Test accuracy 95.29296875, Cost 65.16640996932983 s\n",
      "Epoch 3929, Train loss 0.00026874771794275744, Test loss 0.16252620574086904, Train accuracy 100.0, Test accuracy 95.29296875, Cost 65.19792580604553 s\n",
      "Epoch 3930, Train loss 0.0002686669018769361, Test loss 0.16275336109101773, Train accuracy 100.0, Test accuracy 95.322265625, Cost 65.11939454078674 s\n",
      "Model saved in epoch 3930\n",
      "Epoch 3931, Train loss 0.00026554967352778326, Test loss 0.16431756373494863, Train accuracy 100.0, Test accuracy 95.37109375, Cost 64.97618699073792 s\n",
      "Epoch 3932, Train loss 0.00027034064356596397, Test loss 0.1629192341119051, Train accuracy 100.0, Test accuracy 95.390625, Cost 64.96178436279297 s\n",
      "Epoch 3933, Train loss 0.0002628696216115899, Test loss 0.16253550574183465, Train accuracy 100.0, Test accuracy 95.37109375, Cost 65.01729536056519 s\n",
      "Epoch 3934, Train loss 0.00026145964184994523, Test loss 0.16114431712776423, Train accuracy 100.0, Test accuracy 95.341796875, Cost 65.23461771011353 s\n",
      "Epoch 3935, Train loss 0.00026080473216264795, Test loss 0.16116728261113167, Train accuracy 100.0, Test accuracy 95.2734375, Cost 65.21742177009583 s\n",
      "Model saved in epoch 3935\n",
      "Epoch 3936, Train loss 0.0002576853219913889, Test loss 0.16133389249444008, Train accuracy 100.0, Test accuracy 95.341796875, Cost 65.24459052085876 s\n",
      "Epoch 3937, Train loss 0.00025971780232051674, Test loss 0.16066789198666812, Train accuracy 100.0, Test accuracy 95.322265625, Cost 65.22387838363647 s\n",
      "Epoch 3938, Train loss 0.0002699979774419893, Test loss 0.160013896971941, Train accuracy 100.0, Test accuracy 95.390625, Cost 65.2376275062561 s\n",
      "Epoch 3939, Train loss 0.0002635610607638005, Test loss 0.16067776661366223, Train accuracy 100.0, Test accuracy 95.380859375, Cost 65.22968673706055 s\n",
      "Epoch 3940, Train loss 0.0002574598249190544, Test loss 0.16248902305960655, Train accuracy 100.0, Test accuracy 95.3125, Cost 65.2190043926239 s\n",
      "Model saved in epoch 3940\n",
      "Epoch 3941, Train loss 0.00026847773633377, Test loss 0.16195521894842385, Train accuracy 100.0, Test accuracy 95.3125, Cost 65.18475937843323 s\n",
      "Epoch 3942, Train loss 0.00027680477551814185, Test loss 0.1621634816750884, Train accuracy 100.0, Test accuracy 95.37109375, Cost 65.18851852416992 s\n",
      "Epoch 3943, Train loss 0.00027056267163989476, Test loss 0.1608561184257269, Train accuracy 100.0, Test accuracy 95.341796875, Cost 65.24037480354309 s\n",
      "Epoch 3944, Train loss 0.00027880396158493846, Test loss 0.16294700745493174, Train accuracy 100.0, Test accuracy 95.361328125, Cost 65.23010611534119 s\n",
      "Epoch 3945, Train loss 0.00025048177233155894, Test loss 0.16091308686882258, Train accuracy 100.0, Test accuracy 95.361328125, Cost 65.23590326309204 s\n",
      "Model saved in epoch 3945\n",
      "Epoch 3946, Train loss 0.0002537747279756313, Test loss 0.1628806248307228, Train accuracy 100.0, Test accuracy 95.341796875, Cost 65.22513175010681 s\n",
      "Epoch 3947, Train loss 0.0002644751943340192, Test loss 0.16187251061201097, Train accuracy 100.0, Test accuracy 95.361328125, Cost 64.9744725227356 s\n",
      "Epoch 3948, Train loss 0.00026210418804928815, Test loss 0.1615174040198326, Train accuracy 100.0, Test accuracy 95.302734375, Cost 65.04108929634094 s\n",
      "Epoch 3949, Train loss 0.00024898717800875156, Test loss 0.1615129379555583, Train accuracy 100.0, Test accuracy 95.41015625, Cost 65.24366307258606 s\n",
      "Epoch 3950, Train loss 0.00026312533662682967, Test loss 0.16361330077052116, Train accuracy 100.0, Test accuracy 95.263671875, Cost 65.24555850028992 s\n",
      "Model saved in epoch 3950\n",
      "Epoch 3951, Train loss 0.000261451377550007, Test loss 0.16290831808000802, Train accuracy 100.0, Test accuracy 95.341796875, Cost 65.25195074081421 s\n",
      "Epoch 3952, Train loss 0.00028360219874564195, Test loss 0.16419905051589012, Train accuracy 100.0, Test accuracy 95.234375, Cost 65.25411033630371 s\n",
      "Epoch 3953, Train loss 0.000277513190221911, Test loss 0.163766635581851, Train accuracy 100.0, Test accuracy 95.283203125, Cost 65.23099994659424 s\n",
      "Epoch 3954, Train loss 0.0002566077032961588, Test loss 0.1630976602435112, Train accuracy 100.0, Test accuracy 95.322265625, Cost 65.20276689529419 s\n",
      "Epoch 3955, Train loss 0.00027304635778466256, Test loss 0.16230811569839715, Train accuracy 100.0, Test accuracy 95.322265625, Cost 65.18637132644653 s\n",
      "Model saved in epoch 3955\n",
      "Epoch 3956, Train loss 0.00028413530444780993, Test loss 0.16314051654189826, Train accuracy 100.0, Test accuracy 95.244140625, Cost 65.23961091041565 s\n",
      "Epoch 3957, Train loss 0.0002607014944909939, Test loss 0.16295329220592975, Train accuracy 100.0, Test accuracy 95.29296875, Cost 65.22536873817444 s\n",
      "Epoch 3958, Train loss 0.0002642122568171804, Test loss 0.16216995548456908, Train accuracy 100.0, Test accuracy 95.283203125, Cost 65.25469994544983 s\n",
      "Epoch 3959, Train loss 0.00027797353233873596, Test loss 0.1600494345650077, Train accuracy 100.0, Test accuracy 95.322265625, Cost 65.11628937721252 s\n",
      "Epoch 3960, Train loss 0.00026717077217858323, Test loss 0.16194776222109794, Train accuracy 100.0, Test accuracy 95.3125, Cost 64.82173228263855 s\n",
      "Model saved in epoch 3960\n",
      "Epoch 3961, Train loss 0.00027500952036257795, Test loss 0.16131171248853207, Train accuracy 100.0, Test accuracy 95.390625, Cost 64.80881023406982 s\n",
      "Epoch 3962, Train loss 0.0002673104471035245, Test loss 0.16240448150783776, Train accuracy 100.0, Test accuracy 95.3125, Cost 64.82795476913452 s\n",
      "Epoch 3963, Train loss 0.0002851016341045746, Test loss 0.1603709314018488, Train accuracy 100.0, Test accuracy 95.3125, Cost 64.82565307617188 s\n",
      "Epoch 3964, Train loss 0.0002586658771847118, Test loss 0.16306909266859293, Train accuracy 100.0, Test accuracy 95.322265625, Cost 64.83002495765686 s\n",
      "Epoch 3965, Train loss 0.0002586555678952172, Test loss 0.16259409114718437, Train accuracy 100.0, Test accuracy 95.341796875, Cost 64.82994484901428 s\n",
      "Model saved in epoch 3965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3966, Train loss 0.00025670136320903633, Test loss 0.16222622375935317, Train accuracy 100.0, Test accuracy 95.33203125, Cost 64.85335612297058 s\n",
      "Epoch 3967, Train loss 0.0002659831487256511, Test loss 0.16267868168652058, Train accuracy 100.0, Test accuracy 95.322265625, Cost 64.80748534202576 s\n",
      "Epoch 3968, Train loss 0.0002656424034544865, Test loss 0.16245652232319116, Train accuracy 100.0, Test accuracy 95.33203125, Cost 64.80022978782654 s\n",
      "Epoch 3969, Train loss 0.0002595158965013237, Test loss 0.16339808087795973, Train accuracy 100.0, Test accuracy 95.322265625, Cost 64.7902238368988 s\n",
      "Epoch 3970, Train loss 0.00025737264914656703, Test loss 0.16290652062743902, Train accuracy 100.0, Test accuracy 95.33203125, Cost 64.8065550327301 s\n",
      "Model saved in epoch 3970\n",
      "Epoch 3971, Train loss 0.0002588196737039597, Test loss 0.16480207331478597, Train accuracy 100.0, Test accuracy 95.2734375, Cost 64.82490706443787 s\n",
      "Epoch 3972, Train loss 0.000267579458263104, Test loss 0.1637973112985492, Train accuracy 100.0, Test accuracy 95.341796875, Cost 64.82749629020691 s\n",
      "Epoch 3973, Train loss 0.00027689534188687746, Test loss 0.16247739344835282, Train accuracy 100.0, Test accuracy 95.44921875, Cost 64.83093643188477 s\n",
      "Epoch 3974, Train loss 0.0002586124218377874, Test loss 0.16158596742898226, Train accuracy 100.0, Test accuracy 95.419921875, Cost 64.83385467529297 s\n",
      "Epoch 3975, Train loss 0.0002781253458625561, Test loss 0.16017892472445966, Train accuracy 100.0, Test accuracy 95.3515625, Cost 64.82092952728271 s\n",
      "Model saved in epoch 3975\n",
      "Epoch 3976, Train loss 0.00036085427460160905, Test loss 0.1619107149541378, Train accuracy 100.0, Test accuracy 95.2734375, Cost 64.82259392738342 s\n",
      "Epoch 3977, Train loss 0.0003388381511304404, Test loss 0.16418244913220406, Train accuracy 100.0, Test accuracy 95.3125, Cost 64.8291244506836 s\n",
      "Epoch 3978, Train loss 0.0003271963355566223, Test loss 0.16255317628383636, Train accuracy 100.0, Test accuracy 95.419921875, Cost 64.81865572929382 s\n",
      "Epoch 3979, Train loss 0.00028885258106296237, Test loss 0.1647577503696084, Train accuracy 100.0, Test accuracy 95.380859375, Cost 64.8778805732727 s\n",
      "Epoch 3980, Train loss 0.00027783774158724925, Test loss 0.1639747442677617, Train accuracy 100.0, Test accuracy 95.3125, Cost 65.01395630836487 s\n",
      "Model saved in epoch 3980\n",
      "Epoch 3981, Train loss 0.00026837060981126006, Test loss 0.16363750491291285, Train accuracy 100.0, Test accuracy 95.33203125, Cost 65.22454285621643 s\n",
      "Epoch 3982, Train loss 0.00026415619548951865, Test loss 0.16519140657037495, Train accuracy 100.0, Test accuracy 95.302734375, Cost 65.22513580322266 s\n",
      "Epoch 3983, Train loss 0.00026046994196581274, Test loss 0.1639646902680397, Train accuracy 100.0, Test accuracy 95.302734375, Cost 65.24765682220459 s\n",
      "Epoch 3984, Train loss 0.00027096438661457646, Test loss 0.16236424930393695, Train accuracy 100.0, Test accuracy 95.283203125, Cost 65.26268148422241 s\n",
      "Epoch 3985, Train loss 0.0002495052311652606, Test loss 0.16292838994413614, Train accuracy 100.0, Test accuracy 95.283203125, Cost 65.2523410320282 s\n",
      "Model saved in epoch 3985\n",
      "Epoch 3986, Train loss 0.00025179688021367206, Test loss 0.16284907273948193, Train accuracy 100.0, Test accuracy 95.29296875, Cost 65.2830376625061 s\n",
      "Epoch 3987, Train loss 0.00025085076925520576, Test loss 0.16235460862517356, Train accuracy 100.0, Test accuracy 95.302734375, Cost 65.28053092956543 s\n",
      "Epoch 3988, Train loss 0.00025673666103251223, Test loss 0.16426932364702224, Train accuracy 100.0, Test accuracy 95.3125, Cost 65.28546380996704 s\n",
      "Epoch 3989, Train loss 0.0002464705329639029, Test loss 0.16387554183602332, Train accuracy 100.0, Test accuracy 95.361328125, Cost 64.78749227523804 s\n",
      "Epoch 3990, Train loss 0.0002642209671036226, Test loss 0.1660787831991911, Train accuracy 100.0, Test accuracy 95.21484375, Cost 64.73736596107483 s\n",
      "Model saved in epoch 3990\n",
      "Epoch 3991, Train loss 0.00025499916911049156, Test loss 0.16365363467484711, Train accuracy 100.0, Test accuracy 95.29296875, Cost 64.73555254936218 s\n",
      "Epoch 3992, Train loss 0.00025960274567240755, Test loss 0.16515109017491342, Train accuracy 100.0, Test accuracy 95.29296875, Cost 64.72003746032715 s\n",
      "Epoch 3993, Train loss 0.0002581481867124165, Test loss 0.16584826949983836, Train accuracy 100.0, Test accuracy 95.185546875, Cost 64.71359610557556 s\n",
      "Epoch 3994, Train loss 0.00025774284690019807, Test loss 0.16577331349253654, Train accuracy 100.0, Test accuracy 95.17578125, Cost 64.71354079246521 s\n",
      "Epoch 3995, Train loss 0.00025166945146784016, Test loss 0.16585265416651965, Train accuracy 100.0, Test accuracy 95.146484375, Cost 64.728182554245 s\n",
      "Model saved in epoch 3995\n",
      "Epoch 3996, Train loss 0.00024812498898482975, Test loss 0.16485490072518588, Train accuracy 100.0, Test accuracy 95.341796875, Cost 64.68089628219604 s\n",
      "Epoch 3997, Train loss 0.00025460160113467207, Test loss 0.16555260997265578, Train accuracy 100.0, Test accuracy 95.341796875, Cost 64.68320655822754 s\n",
      "Epoch 3998, Train loss 0.0002490515856022414, Test loss 0.1650942848995328, Train accuracy 100.0, Test accuracy 95.341796875, Cost 64.70913982391357 s\n",
      "Epoch 3999, Train loss 0.0002571805230310966, Test loss 0.16271907091140747, Train accuracy 100.0, Test accuracy 95.46875, Cost 64.71562266349792 s\n",
      "Epoch 4000, Train loss 0.0002564188985068503, Test loss 0.1651305476203561, Train accuracy 100.0, Test accuracy 95.341796875, Cost 64.70738816261292 s\n",
      "Model saved in epoch 4000\n",
      "Epoch 4001, Train loss 0.00025049347162593575, Test loss 0.16378613468259573, Train accuracy 100.0, Test accuracy 95.3515625, Cost 64.70242953300476 s\n",
      "Epoch 4002, Train loss 0.0003178591559473568, Test loss 0.17026464864611626, Train accuracy 99.99800701530613, Test accuracy 95.17578125, Cost 64.71074390411377 s\n",
      "Epoch 4003, Train loss 0.0002694840144873264, Test loss 0.1666410095989704, Train accuracy 100.0, Test accuracy 95.263671875, Cost 64.71090579032898 s\n",
      "Epoch 4004, Train loss 0.0002644154101661264, Test loss 0.1666877442970872, Train accuracy 100.0, Test accuracy 95.302734375, Cost 64.69004774093628 s\n",
      "Epoch 4005, Train loss 0.0002635808388211964, Test loss 0.16688854135572911, Train accuracy 100.0, Test accuracy 95.205078125, Cost 64.72004246711731 s\n",
      "Model saved in epoch 4005\n",
      "Epoch 4006, Train loss 0.0002550656732934413, Test loss 0.16792211625725031, Train accuracy 100.0, Test accuracy 95.185546875, Cost 64.72379326820374 s\n",
      "Epoch 4007, Train loss 0.00025775012523363515, Test loss 0.16635427605360747, Train accuracy 100.0, Test accuracy 95.21484375, Cost 64.71383309364319 s\n",
      "Epoch 4008, Train loss 0.0002506001500830967, Test loss 0.16559897568076848, Train accuracy 100.0, Test accuracy 95.21484375, Cost 64.71545457839966 s\n",
      "Epoch 4009, Train loss 0.0002517478524354448, Test loss 0.16622386332601308, Train accuracy 100.0, Test accuracy 95.1953125, Cost 64.68272423744202 s\n",
      "Epoch 4010, Train loss 0.0002477247428626525, Test loss 0.1659796817228198, Train accuracy 100.0, Test accuracy 95.1953125, Cost 64.67972993850708 s\n",
      "Model saved in epoch 4010\n",
      "Epoch 4011, Train loss 0.00024552083688868893, Test loss 0.1654237972572446, Train accuracy 100.0, Test accuracy 95.3515625, Cost 64.77609992027283 s\n",
      "Epoch 4012, Train loss 0.00024981765417745623, Test loss 0.16686541363596916, Train accuracy 100.0, Test accuracy 95.224609375, Cost 64.78211283683777 s\n",
      "Epoch 4013, Train loss 0.00024076280815465073, Test loss 0.16647773161530494, Train accuracy 100.0, Test accuracy 95.380859375, Cost 64.81958293914795 s\n",
      "Epoch 4014, Train loss 0.0002572094501597256, Test loss 0.16656234189867974, Train accuracy 100.0, Test accuracy 95.244140625, Cost 64.82948422431946 s\n",
      "Epoch 4015, Train loss 0.0002530384842931217, Test loss 0.1661591088399291, Train accuracy 100.0, Test accuracy 95.33203125, Cost 64.76400995254517 s\n",
      "Model saved in epoch 4015\n",
      "Epoch 4016, Train loss 0.0002430548555988638, Test loss 0.16671173200011252, Train accuracy 100.0, Test accuracy 95.244140625, Cost 64.73595595359802 s\n",
      "Epoch 4017, Train loss 0.0002677250084495742, Test loss 0.1654958538711071, Train accuracy 100.0, Test accuracy 95.302734375, Cost 64.7404043674469 s\n",
      "Epoch 4018, Train loss 0.0002527510739443586, Test loss 0.16709804497659206, Train accuracy 100.0, Test accuracy 95.234375, Cost 64.75960111618042 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4019, Train loss 0.0002528306751479917, Test loss 0.16664078813046218, Train accuracy 100.0, Test accuracy 95.380859375, Cost 64.75546717643738 s\n",
      "Epoch 4020, Train loss 0.00025449197502374385, Test loss 0.16781385857611894, Train accuracy 100.0, Test accuracy 95.185546875, Cost 64.75413393974304 s\n",
      "Model saved in epoch 4020\n",
      "Epoch 4021, Train loss 0.00024421074006252696, Test loss 0.1671501588076353, Train accuracy 100.0, Test accuracy 95.37109375, Cost 64.73701238632202 s\n",
      "Epoch 4022, Train loss 0.0002456910729144548, Test loss 0.16686372719705106, Train accuracy 100.0, Test accuracy 95.400390625, Cost 64.7165060043335 s\n",
      "Epoch 4023, Train loss 0.0002472753869221137, Test loss 0.16751786787062883, Train accuracy 100.0, Test accuracy 95.3125, Cost 64.68541026115417 s\n",
      "Epoch 4024, Train loss 0.00025539719658530775, Test loss 0.1721544111147523, Train accuracy 100.0, Test accuracy 95.0390625, Cost 64.67480063438416 s\n",
      "Epoch 4025, Train loss 0.0002722816719383724, Test loss 0.1701313428580761, Train accuracy 100.0, Test accuracy 95.15625, Cost 64.71988534927368 s\n",
      "Model saved in epoch 4025\n",
      "Epoch 4026, Train loss 0.00026528657200492026, Test loss 0.16806116718798875, Train accuracy 100.0, Test accuracy 95.17578125, Cost 64.82367610931396 s\n",
      "Epoch 4027, Train loss 0.0002492408032650223, Test loss 0.16659793630242348, Train accuracy 100.0, Test accuracy 95.185546875, Cost 65.02774596214294 s\n",
      "Epoch 4028, Train loss 0.0002590137278739534, Test loss 0.16721418723464013, Train accuracy 100.0, Test accuracy 95.17578125, Cost 65.30318021774292 s\n",
      "Epoch 4029, Train loss 0.00024637939669465057, Test loss 0.1654299557209015, Train accuracy 100.0, Test accuracy 95.21484375, Cost 65.29385423660278 s\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5000 # param\n",
    "epoch_start = 0\n",
    "# path = 'adam_rotate_center_crop1.pt'\n",
    "# path = 'block_3.pt'\n",
    "path = 'batch_256_lr_0.1-0.0001_no_crop_decay_0.0001_channel_80-5.pt'\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "test_accuracy_history = []\n",
    "train_accuracy_history = []\n",
    "\n",
    "Loss = torch.nn.CrossEntropyLoss()\n",
    "lr = 0.1 # param\n",
    "lr_min=0.0001\n",
    "# optimizer = torch.optim.SGD(model1.parameters(),lr=lr,momentum=0.9,weight_decay=5e-4) # changable optimizer\n",
    "# optimizer = torch.optim.SGD(model1.parameters(),lr=lr,momentum=0.9) # changable optimizer\n",
    "# optimizer = torch.optim.Adam(model1.parameters(),lr=lr, betas=(0.9,0.999), eps=1e-08, amsgrad=False) # changable optimizer\n",
    "momentum = 0.9\n",
    "nesterov = True\n",
    "optimizer = torch.optim.SGD(model1.parameters(),lr=lr,momentum=momentum,nesterov=nesterov,weight_decay=0.0001)\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "if os.path.exists(path):\n",
    "  checkpoint = torch.load(path)\n",
    "  print('Read model from checkpoint')\n",
    "  model1.cuda().load_state_dict(checkpoint['model_state_dict'])\n",
    "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "  epoch_start = checkpoint['epoch']\n",
    "  Loss = checkpoint['Loss']\n",
    "  train_loss_history = checkpoint['train_loss_history']\n",
    "  test_loss_history = checkpoint['test_loss_history']\n",
    "  test_accuracy_history = checkpoint['test_accuracy_history']\n",
    "  train_accuracy_history = checkpoint['train_accuracy_history']\n",
    "  print('Restart from epoch',epoch_start)\n",
    "    \n",
    "\n",
    "for epoch in range(epoch_start+1, num_epochs + 1):\n",
    "  timestart = time.time()\n",
    "\n",
    "  train_loss = 0.0\n",
    "  test_loss = 0.0\n",
    "  test_accuracy = 0.0\n",
    "  train_accuracy = 0.0\n",
    "\n",
    "  for i, data in enumerate(trainDataLoader):\n",
    "    images, labels = data\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    optimizer.zero_grad()\n",
    "    predicted_output = model1.cuda()(images)\n",
    "    fit = Loss(predicted_output,labels)\n",
    "    fit.backward()\n",
    "    adjust_learning_rate(optimizer=optimizer,current_epoch=epoch,max_epoch=num_epochs,lr_min=lr_min,lr_max=lr,warmup=True)\n",
    "    optimizer.step()\n",
    "    train_loss += fit.item()\n",
    "    train_accuracy += (torch.eq(torch.max(predicted_output,1)[1],labels).sum()/len(labels)*100).data.cpu().numpy()\n",
    "\n",
    "  for i, data in enumerate(testDataLoader):\n",
    "    with torch.no_grad():\n",
    "      images, labels = data\n",
    "      images = images.cuda()\n",
    "      labels = labels.cuda()\n",
    "      predicted_output = model1.cuda()(images)\n",
    "      fit = Loss(predicted_output,labels)\n",
    "      test_loss += fit.item()\n",
    "      test_accuracy += (torch.eq(torch.max(predicted_output,1)[1],labels).sum()/len(labels)*100).data.cpu().numpy()\n",
    "\n",
    "\n",
    "  train_loss = train_loss/len(trainDataLoader)\n",
    "  test_loss = test_loss/len(testDataLoader)\n",
    "  test_accu = test_accuracy/len(testDataLoader)\n",
    "  train_accu = train_accuracy/len(trainDataLoader)\n",
    "  train_loss_history.append(train_loss)\n",
    "  test_loss_history.append(test_loss)\n",
    "  test_accuracy_history.append(test_accu)\n",
    "  train_accuracy_history.append(train_accu)\n",
    "  print('Epoch %s, Train loss %s, Test loss %s, Train accuracy %s, Test accuracy %s, Cost %s s'%(epoch,\n",
    "                                                                                                   train_loss,test_loss,\n",
    "                                                                                                   train_accu,test_accu,\n",
    "                                                                                                   time.time()-timestart))\n",
    "  \n",
    "  if epoch % 5 == 0 and epoch != 0:\n",
    "    torch.save({'epoch':epoch,\n",
    "          'model_state_dict':model1.cuda().state_dict(),\n",
    "          'optimizer_state_dict':optimizer.state_dict(),\n",
    "          'Loss':Loss,\n",
    "          'train_loss_history':train_loss_history,\n",
    "          'test_loss_history':test_loss_history,\n",
    "          'test_accuracy_history':test_accuracy_history,\n",
    "          'train_accuracy_history':train_accuracy_history},path)\n",
    "    print('Model saved in epoch %s'%(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RUy08Iyn7tUl",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(num_epochs),train_loss_history,'-',linewidth=3,label='Train error')\n",
    "plt.plot(range(num_epochs),test_loss_history,'-',linewidth=3,label='Test error')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(num_epochs),train_accuracy_history,'-',linewidth=3,label='Train accuracy')\n",
    "plt.plot(range(num_epochs),test_accuracy_history,'-',linewidth=3,label='Test accuracy')\n",
    "# plt.plot(range(num_epochs),test_accuracy_history,'-',linewidth=3,label='Test accuracy')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVQJgMts7vcg"
   },
   "outputs": [],
   "source": [
    "print('Accuracy:',sum(test_accuracy_history[-5:])/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LaMUB4p_Ucip"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "“ResNet.ipynb”的副本",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0130588af6254c76a2c8c382288cfcea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4aa5668c8eaa49f88148d499240b6ea5",
      "placeholder": "​",
      "style": "IPY_MODEL_a66b114e4595419f84ac44a676a1ca61",
      "value": " 170499072/? [00:03&lt;00:00, 56047078.45it/s]"
     }
    },
    "1121692d91114d58b3db79e41b0a24c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d40f4bf0c0e48709cdec5f80069ed2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "321ea7fa0b4d4c9dab9ed5231954e54c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3983cfe844f847899487b2745a203a9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8148f05b38d94ec19351ac920b70acba",
       "IPY_MODEL_af7b660f147d4d1d8796d3419673c9b7",
       "IPY_MODEL_0130588af6254c76a2c8c382288cfcea"
      ],
      "layout": "IPY_MODEL_1121692d91114d58b3db79e41b0a24c9"
     }
    },
    "4aa5668c8eaa49f88148d499240b6ea5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8148f05b38d94ec19351ac920b70acba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_accf52fe298b4716af9d9c351e7326dc",
      "placeholder": "​",
      "style": "IPY_MODEL_fb3e769eb8324af3b77041879c9b54cf",
      "value": ""
     }
    },
    "a66b114e4595419f84ac44a676a1ca61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "accf52fe298b4716af9d9c351e7326dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af7b660f147d4d1d8796d3419673c9b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_321ea7fa0b4d4c9dab9ed5231954e54c",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d40f4bf0c0e48709cdec5f80069ed2f",
      "value": 170498071
     }
    },
    "fb3e769eb8324af3b77041879c9b54cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
