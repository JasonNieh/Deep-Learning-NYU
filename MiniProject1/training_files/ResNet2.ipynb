{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "azOQDGfMLFN8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import math\n",
    "import torchvision\n",
    "from torchvision import transforms as transforms\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from math import cos,pi\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nnaef49GOhPH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Vb_Gr3w9vzx8"
   },
   "outputs": [],
   "source": [
    "# torch.manual_seed(17)\n",
    "\n",
    "# class HaS(object): \n",
    "# #     def __init__(self):\n",
    "        \n",
    "#     def __call__(self, img):\n",
    "#         # get width and height of the image\n",
    "#         img_= np.array(img).copy()\n",
    "#         s = img_.shape\n",
    "#         wd = s[0]\n",
    "#         ht = s[1]\n",
    "\n",
    "#         # possible grid size, 0 means no hiding\n",
    "#         grid_size=3\n",
    "\n",
    "#         # hiding probability\n",
    "#         hide_prob = 0.1\n",
    " \n",
    "#         # randomly choose one grid size\n",
    "# #         grid_size= grid_sizes[random.randint(0,len(grid_sizes)-1)]\n",
    "\n",
    "#         # hide the patches\n",
    "#         if(grid_size>0):\n",
    "#              for x in range(0,wd,grid_size):\n",
    "#                  for y in range(0,ht,grid_size):\n",
    "#                      x_end = min(wd, x+grid_size)  \n",
    "#                      y_end = min(ht, y+grid_size)\n",
    "#                      if(random.random() <=  hide_prob):\n",
    "#                            img_[x:x_end,y:y_end,:]=0\n",
    "\n",
    "#         return img_\n",
    "    \n",
    "# torch.manual_seed(17)\n",
    "\n",
    "        \n",
    "# class HideEdge(object): \n",
    "#     def __init__(self,hide_size):\n",
    "#         self.hide_size=hide_size\n",
    "        \n",
    "#     def __call__(self, img):\n",
    "#         # get width and height of the image\n",
    "#         img_= np.array(img).copy()\n",
    "#         s = img_.shape\n",
    "#         wd = s[0]\n",
    "#         ht = s[1]\n",
    "\n",
    "#         hide_size=self.hide_size\n",
    "        \n",
    "# #         img_[:,:,:] = img()\n",
    "   \n",
    "#         x_end = wd - hide_size \n",
    "#         y_end = ht - hide_size\n",
    "\n",
    "#         img_[x_end:,y_end:,:]=0\n",
    "# #         img_[x_end:,:hide_size,:]=0\n",
    "# #         img_[:hide_size,y_end:,:]=0\n",
    "#         img_[:hide_size,:hide_size,:]=0\n",
    "# #         img_[x_end:,:,:]=0\n",
    "# #         img_[:,y_end:,:]=0\n",
    "# #         img_[:hide_size,:,:]=0\n",
    "# #         img_[:,:hide_size,:]=0\n",
    "# #         print(img_[x_end,y_end,:])\n",
    "# #         print(img_[hide_size,hide_size,:])\n",
    "# #         print(x_end,y_end,hide_size)\n",
    "        \n",
    "# #         mean = img_[hide_size:x_end-1,hide_size:y_end,:].mean()\n",
    "# #         std = img_[hide_size:x_end-1,hide_size:y_end,:].std()\n",
    "# #         print(mean, std)\n",
    "# #         img_[hide_size:x_end-1,hide_size:y_end,:] = (img_[hide_size:x_end-1,hide_size:y_end,:] - mean) / std\n",
    "# #         print(img_[hide_size:x_end-1,hide_size:y_end,:])\n",
    "        \n",
    "#         return img_\n",
    "\n",
    "   \n",
    "# class Hide_after_Norm(object): \n",
    "#     def __init__(self,hide_size):\n",
    "#         self.hide_size=hide_size\n",
    "        \n",
    "#     def __call__(self, img_):\n",
    "#         # get width and height of the image\n",
    "# #         img_= np.array(img).copy()\n",
    "#         s = img_.shape\n",
    "#         wd = s[1]\n",
    "#         ht = s[2]\n",
    "\n",
    "#         hide_size=self.hide_size\n",
    "        \n",
    "# #         img_[:,:,:] = img()\n",
    "   \n",
    "#         x_end = wd - hide_size \n",
    "#         y_end = ht - hide_size\n",
    "        \n",
    "#         x_end = wd - hide_size \n",
    "#         y_end = ht - hide_size\n",
    "\n",
    "#         img_[:,x_end:,y_end:]=0\n",
    "# #         img_[x_end:,:hide_size,:]=0\n",
    "# #         img_[:hide_size,y_end:,:]=0\n",
    "#         img_[:,:hide_size,:hide_size]=0\n",
    "# #         print(img_[x_end,y_end,:])\n",
    "# #         print(img_[hide_size,hide_size,:])\n",
    "# #         print(x_end,y_end,hide_size)\n",
    "        \n",
    "# #         mean = img_[hide_size:x_end-1,hide_size:y_end,:].mean()\n",
    "# #         std = img_[hide_size:x_end-1,hide_size:y_end,:].std()\n",
    "# #         print(mean, std)\n",
    "# #         img_[hide_size:x_end-1,hide_size:y_end,:] = (img_[hide_size:x_end-1,hide_size:y_end,:] - mean) / std\n",
    "# #         print(img_[hide_size:x_end-1,hide_size:y_end,:])\n",
    "        \n",
    "#         return img_\n",
    "    \n",
    "    \n",
    "\n",
    "# # torch.cuda.manual_seed(17) # for GPU\n",
    "# aug_train = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(), # 水平翻转\n",
    "# #     torchvision.transforms.CenterCrop(26),\n",
    "# #     HideEdge(),\n",
    "#     torchvision.transforms.RandomRotation(15),\n",
    "# #     torchvision.transforms.CenterCrop(28),\n",
    "#     # transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5), # color aug\n",
    "# #     transforms.RandomCrop(32, padding=4), # 裁剪\n",
    "#     # transforms.RandomResizedCrop((32,32),scale=(0.1,1),ratio=(0.5,2))\n",
    "# #     hide_patch(),\n",
    "# #     HaS(),\n",
    "# #     HideEdge(2),\n",
    "#     transforms.ToTensor(),\n",
    "# #     Norm(2),\n",
    "#     transforms.Normalize((0.4649, 0.4553, 0.4214), (0.2271, 0.2234, 0.2208)),# normalization\n",
    "#     Hide_after_Norm(2)\n",
    "#     ])\n",
    "\n",
    "# aug_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4649, 0.4553, 0.4214), (0.2271, 0.2234, 0.2208)), # normalization\n",
    "#     Hide_after_Norm(2)\n",
    "#     ])\n",
    "\n",
    "# trainingdata = torchvision.datasets.CIFAR10('./CIFAR10',train=True,download=True,transform=aug_train)\n",
    "# # testdata = torchvision.datasets.CIFAR10('./CIFAR10',train=False,download=True,transform=transforms.ToTensor())\n",
    "# # print(len(trainingdata),len(testdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(17)\n",
    "torch.cuda.manual_seed_all(17)\n",
    "\n",
    "aug_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32,padding=4,padding_mode='reflect'),\n",
    "    transforms.RandomHorizontalFlip(), # 水平翻转\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4244, 0.4146, 0.3836), (0.2539, 0.2491, 0.2420)) # normalization\n",
    "    ])\n",
    "\n",
    "aug_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4244, 0.4146, 0.3836), (0.2539, 0.2491, 0.2420)) # normalization\n",
    "    ])\n",
    "\n",
    "trainingdata = torchvision.datasets.CIFAR10('./CIFAR10',train=True,download=True,transform=aug_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "3983cfe844f847899487b2745a203a9b",
      "1121692d91114d58b3db79e41b0a24c9",
      "8148f05b38d94ec19351ac920b70acba",
      "af7b660f147d4d1d8796d3419673c9b7",
      "0130588af6254c76a2c8c382288cfcea",
      "fb3e769eb8324af3b77041879c9b54cf",
      "accf52fe298b4716af9d9c351e7326dc",
      "1d40f4bf0c0e48709cdec5f80069ed2f",
      "321ea7fa0b4d4c9dab9ed5231954e54c",
      "a66b114e4595419f84ac44a676a1ca61",
      "4aa5668c8eaa49f88148d499240b6ea5"
     ]
    },
    "id": "1lqsbqYCMja7",
    "outputId": "3b4aa629-06a0-480a-afec-dcdb971e4bf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def get_mean_and_std(dataset):\n",
    "  '''Compute the mean and std value of dataset.'''\n",
    "  dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "  mean = torch.zeros(3)\n",
    "  std = torch.zeros(3)\n",
    "  print('==> Computing mean and std..')\n",
    "  for inputs, targets in dataloader:\n",
    "      for i in range(3):\n",
    "          mean[i] += inputs[:,i,:,:].mean()\n",
    "          std[i] += inputs[:,i,:,:].std()\n",
    "  mean.div_(len(dataset))\n",
    "  std.div_(len(dataset))\n",
    "  return mean, std\n",
    "\n",
    "def load_data(is_train,aug,batch_size):\n",
    "  dataset = torchvision.datasets.CIFAR10('./CIFAR10',train=is_train,download=True,transform=aug)\n",
    "#   mean, std = get_mean_and_std(dataset)\n",
    "#   print(mean, std)\n",
    "  dataloader = torch.utils.data.DataLoader(dataset,batch_size=batch_size,shuffle=is_train)\n",
    "  return dataloader\n",
    "\n",
    "batch_size = 256 # param\n",
    "trainDataLoader = load_data(is_train=True,aug=aug_train,batch_size=batch_size)\n",
    "testDataLoader = load_data(is_train=False,aug=aug_test,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-TD4UKtgzXbh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32]) 6\n",
      "[[[-0.9147032  -0.38956204  0.0274618  ...  0.01201648  0.18191507\n",
      "    0.15102442]\n",
      "  [-0.32778072 -0.03431951  0.10468844 ... -0.21966343  0.1973604\n",
      "    0.2591417 ]\n",
      "  [-0.09610081  0.29003236  0.24369638 ... -0.6366873  -0.51312464\n",
      "   -0.32778072]\n",
      "  ...\n",
      "  [ 1.0931895   1.2321974   1.448432   ...  0.22825105  0.66072035\n",
      "    1.6646665 ]\n",
      "  [ 1.2013068   1.3248694   1.3866507  ... -0.38956204 -0.17332745\n",
      "    1.1704161 ]\n",
      "  [ 1.3866507   1.2785335   1.1549708  ... -0.8529219  -0.8065859\n",
      "    0.7997283 ]]\n",
      "\n",
      " [[-1.2393323  -0.8772444  -0.53089947 ... -0.5151565  -0.3419841\n",
      "   -0.3419841 ]\n",
      "  [-0.8142726  -0.6725861  -0.5623854  ... -0.68832904 -0.32624117\n",
      "   -0.29475525]\n",
      "  [-0.6411001  -0.42069885 -0.45218474 ... -1.003188   -0.9244732\n",
      "   -0.76704377]\n",
      "  ...\n",
      "  [ 0.57110703  0.6813077   0.9804237  ... -0.21604052  0.19327614\n",
      "    1.2323109 ]\n",
      "  [ 0.6025929   0.74427944  0.8229942  ... -0.83001554 -0.68832904\n",
      "    0.6655647 ]\n",
      "  [ 0.87022305  0.8072512   0.6340788  ... -1.1291317  -1.1763605\n",
      "    0.42942047]]\n",
      "\n",
      " [[-1.4554853  -1.212413   -0.92072594 ... -0.9045211  -0.7748825\n",
      "   -0.7748825 ]\n",
      "  [-1.1800033  -1.1313888  -1.0503646  ... -1.017955   -0.80729216\n",
      "   -0.7748825 ]\n",
      "  [-1.0341598  -0.9531356  -1.0017501  ... -1.1800033  -1.212413\n",
      "   -1.1475936 ]\n",
      "  ...\n",
      "  [-0.17530379 -0.49940035 -0.4831955  ... -0.4183762  -0.22391827\n",
      "    0.6835522 ]\n",
      "  [-1.0989791  -1.1800033  -1.0341598  ... -1.0341598  -1.0341598\n",
      "   -0.06186999]\n",
      "  [-1.1637985  -1.1475936  -1.0341598  ... -1.2610275  -1.4716902\n",
      "   -0.45078588]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "image,label = trainingdata[0]\n",
    "image_= np.array(image).copy()\n",
    "print(image.shape, label)\n",
    "print(image_)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.imshow(image.numpy().transpose(1,2,0))\n",
    "plt.title(str(classes[label]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jo4vcA1BwajW"
   },
   "outputs": [],
   "source": [
    "# trainDataLoader = torch.utils.data.DataLoader(trainingdata,batch_size=batch_size,shuffle=True)\n",
    "# testDataLoader = torch.utils.data.DataLoader(testdata,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "# images, labels = iter(trainDataLoader).next()\n",
    "# plt.figure(figsize=(17,8))\n",
    "# for index in np.arange(0,5):\n",
    "#   plt.subplot(1,5,index+1)\n",
    "#   plt.imshow(images[index].numpy().transpose(1,2,0))\n",
    "#   plt.title(str(classes[labels[index]]))\n",
    "\n",
    "def get_mean_and_std(dataset):\n",
    "  '''Compute the mean and std value of dataset.'''\n",
    "  dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "  mean = torch.zeros(3)\n",
    "  std = torch.zeros(3)\n",
    "  print('==> Computing mean and std..')\n",
    "  for inputs, targets in dataloader:\n",
    "      for i in range(3):\n",
    "          mean[i] += inputs[:,i,:,:].mean()\n",
    "          std[i] += inputs[:,i,:,:].std()\n",
    "  mean.div_(len(dataset))\n",
    "  std.div_(len(dataset))\n",
    "  return mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YDBTjSf2jDNm"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_planes, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = in_planes\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_planes)\n",
    "        self.layer1 = self._make_layer(block, in_planes, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, in_planes*2, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, in_planes*4, num_blocks[2], stride=2)\n",
    "#         self.layer4 = self._make_layer(block, in_planes*8, num_blocks[3], stride=2)\n",
    "#         self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "#         self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "#         self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "#         self.layer4 = self._make_layer(block, self.in_planes*8, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(320, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(x.shape)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "#         print(out.shape)\n",
    "        out = self.layer1(out)\n",
    "#         print(out.shape)\n",
    "        out = self.layer2(out)\n",
    "#         print(out.shape)\n",
    "        out = self.layer3(out)\n",
    "#         print(out.shape)\n",
    "#         out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "#         print(out.shape)\n",
    "        out = out.view(out.size(0), -1)\n",
    "#         print(out.shape)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu') # weight initialization\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)\n",
    "            elif isinstance(m,nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "            elif isinstance(m,nn.Linear):\n",
    "                nn.init.normal_(m.weight,std=1e-3)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)\n",
    "\n",
    "def project1_model():\n",
    "#     return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "#     return ResNet(BasicBlock, [2, 2, 2])\n",
    "    return ResNet(80, BasicBlock, [3, 3, 2])\n",
    "\n",
    "# model1 = nn.Sequential(project1_model(), nn.AdaptiveAvgPool2d((1,1)), nn.Flatten(), nn.Linear(512, 10)).cuda()\n",
    "model1 = project1_model().cuda()\n",
    "model1.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FDnI9zbyLK6B",
    "outputId": "4a1b7b4e-5d52-42d6-8563-500023c3acae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4914330\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    # torch.numel() returns number of elements in a tensor\n",
    "\n",
    "print(count_parameters(model1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbLtFYydjoIx",
    "outputId": "0321ff7b-c60c-4099-f5fb-4a9536f10244"
   },
   "outputs": [],
   "source": [
    "# X = torch.rand(size=(1, 3, 32, 32)).cuda()\n",
    "# for layer in model1:\n",
    "#   X = layer(X)\n",
    "#   print(layer.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, current_epoch,max_epoch,lr_min=0,lr_max=0.1,warmup=True):\n",
    "    warmup_epoch = 10 if warmup else 0\n",
    "    if current_epoch < warmup_epoch:\n",
    "        lr = lr_max * current_epoch / warmup_epoch\n",
    "    else:\n",
    "        lr = lr_min + (lr_max-lr_min)*(1 + cos(pi * (current_epoch - warmup_epoch) / (max_epoch - warmup_epoch))) / 2\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "j5xklXYe6gRe",
    "outputId": "b846ff14-cc67-4bdc-d6bb-f727fa580bcc",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read model from checkpoint\n",
      "Restart from epoch 395\n",
      "Epoch 396, Train loss 2.5001605256803413e-05, Test loss 0.4069094069302082, Train accuracy 100.0, Test accuracy 94.189453125, Cost 61.951008796691895 s\n",
      "Epoch 397, Train loss 1.6471225050297888e-05, Test loss 0.4075302477926016, Train accuracy 100.0, Test accuracy 94.19921875, Cost 61.899245262145996 s\n",
      "Epoch 398, Train loss 2.4953838484279634e-05, Test loss 0.40766853727400304, Train accuracy 100.0, Test accuracy 94.208984375, Cost 61.88175368309021 s\n",
      "Epoch 399, Train loss 2.41791375369688e-05, Test loss 0.40913010500371455, Train accuracy 100.0, Test accuracy 94.140625, Cost 61.88531541824341 s\n",
      "Epoch 400, Train loss 2.7122882836952806e-05, Test loss 0.40931070148944854, Train accuracy 100.0, Test accuracy 94.16015625, Cost 62.08302855491638 s\n",
      "Model saved in epoch 400\n",
      "Epoch 401, Train loss 2.1001798600360528e-05, Test loss 0.4089284248650074, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.10115361213684 s\n",
      "Epoch 402, Train loss 2.2535309271370815e-05, Test loss 0.40872240364551543, Train accuracy 100.0, Test accuracy 94.16015625, Cost 61.98258304595947 s\n",
      "Epoch 403, Train loss 2.193820868141028e-05, Test loss 0.4092416040599346, Train accuracy 100.0, Test accuracy 94.169921875, Cost 62.18367075920105 s\n",
      "Epoch 404, Train loss 1.3814073075856905e-05, Test loss 0.4089401211589575, Train accuracy 100.0, Test accuracy 94.1796875, Cost 62.12703251838684 s\n",
      "Epoch 405, Train loss 2.2038928277339085e-05, Test loss 0.408920494094491, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.159672021865845 s\n",
      "Model saved in epoch 405\n",
      "Epoch 406, Train loss 1.6184083500721795e-05, Test loss 0.40913546048104765, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.10931921005249 s\n",
      "Epoch 407, Train loss 2.2300662391739007e-05, Test loss 0.40917254127562047, Train accuracy 100.0, Test accuracy 94.189453125, Cost 62.118563413619995 s\n",
      "Epoch 408, Train loss 1.5672336321087213e-05, Test loss 0.4095004517585039, Train accuracy 100.0, Test accuracy 94.1796875, Cost 62.10099244117737 s\n",
      "Epoch 409, Train loss 1.6584449559612653e-05, Test loss 0.4094316389411688, Train accuracy 100.0, Test accuracy 94.21875, Cost 62.13710021972656 s\n",
      "Epoch 410, Train loss 2.291976704999941e-05, Test loss 0.41046847887337207, Train accuracy 100.0, Test accuracy 94.12109375, Cost 62.14811706542969 s\n",
      "Model saved in epoch 410\n",
      "Epoch 411, Train loss 1.5731064724850885e-05, Test loss 0.4114319905638695, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.20854187011719 s\n",
      "Epoch 412, Train loss 2.241116127731799e-05, Test loss 0.41188189163804056, Train accuracy 100.0, Test accuracy 94.111328125, Cost 62.20802092552185 s\n",
      "Epoch 413, Train loss 1.93173911579184e-05, Test loss 0.4143753621727228, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.18236804008484 s\n",
      "Epoch 414, Train loss 1.6189109583636738e-05, Test loss 0.41434354819357394, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.21142601966858 s\n",
      "Epoch 415, Train loss 1.8962090079491405e-05, Test loss 0.4140617158263922, Train accuracy 100.0, Test accuracy 94.12109375, Cost 62.21071696281433 s\n",
      "Model saved in epoch 415\n",
      "Epoch 416, Train loss 2.5106794955822622e-05, Test loss 0.4156458429992199, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.155686378479004 s\n",
      "Epoch 417, Train loss 1.5074334035428978e-05, Test loss 0.4151728119701147, Train accuracy 100.0, Test accuracy 94.16015625, Cost 62.088045597076416 s\n",
      "Epoch 418, Train loss 1.4141150167870596e-05, Test loss 0.4156947884708643, Train accuracy 100.0, Test accuracy 94.19921875, Cost 62.38545370101929 s\n",
      "Epoch 419, Train loss 3.772561701834097e-05, Test loss 0.4182645570486784, Train accuracy 99.99800701530613, Test accuracy 94.072265625, Cost 62.26724147796631 s\n",
      "Epoch 420, Train loss 2.048860333898073e-05, Test loss 0.41538305692374705, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.138657093048096 s\n",
      "Model saved in epoch 420\n",
      "Epoch 421, Train loss 1.970956168986736e-05, Test loss 0.4142979681491852, Train accuracy 100.0, Test accuracy 94.169921875, Cost 62.17386031150818 s\n",
      "Epoch 422, Train loss 4.828820864704586e-05, Test loss 0.4174933794885874, Train accuracy 99.99800701530613, Test accuracy 94.150390625, Cost 62.183820724487305 s\n",
      "Epoch 423, Train loss 5.143793035505941e-05, Test loss 0.4195865001529455, Train accuracy 99.99800701530613, Test accuracy 94.04296875, Cost 62.171448945999146 s\n",
      "Epoch 424, Train loss 2.0955138596173592e-05, Test loss 0.41829602494835855, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.162935972213745 s\n",
      "Epoch 425, Train loss 2.6357612268804347e-05, Test loss 0.4177348081022501, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.13278388977051 s\n",
      "Model saved in epoch 425\n",
      "Epoch 426, Train loss 2.1416354841523236e-05, Test loss 0.41654173098504543, Train accuracy 100.0, Test accuracy 94.12109375, Cost 62.15684747695923 s\n",
      "Epoch 427, Train loss 1.6118903265961234e-05, Test loss 0.41676536574959755, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.131125688552856 s\n",
      "Epoch 428, Train loss 2.358107808597234e-05, Test loss 0.4153477232903242, Train accuracy 100.0, Test accuracy 94.1015625, Cost 62.11932611465454 s\n",
      "Epoch 429, Train loss 2.298419081500692e-05, Test loss 0.4140700165182352, Train accuracy 100.0, Test accuracy 94.072265625, Cost 62.1195011138916 s\n",
      "Epoch 430, Train loss 2.4394624953650198e-05, Test loss 0.41507778465747835, Train accuracy 100.0, Test accuracy 94.111328125, Cost 62.113449811935425 s\n",
      "Model saved in epoch 430\n",
      "Epoch 431, Train loss 2.239953560249154e-05, Test loss 0.4137085922062397, Train accuracy 100.0, Test accuracy 94.072265625, Cost 62.13286471366882 s\n",
      "Epoch 432, Train loss 2.6005211932953194e-05, Test loss 0.41722748018801215, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.11913228034973 s\n",
      "Epoch 433, Train loss 1.57729994932524e-05, Test loss 0.41619292087852955, Train accuracy 100.0, Test accuracy 94.16015625, Cost 62.10351228713989 s\n",
      "Epoch 434, Train loss 1.461632127287356e-05, Test loss 0.4157382294535637, Train accuracy 100.0, Test accuracy 94.19921875, Cost 62.13822388648987 s\n",
      "Epoch 435, Train loss 2.367407446359136e-05, Test loss 0.41784168817102907, Train accuracy 100.0, Test accuracy 94.0625, Cost 62.16389489173889 s\n",
      "Model saved in epoch 435\n",
      "Epoch 436, Train loss 1.3121053423996811e-05, Test loss 0.41827462762594225, Train accuracy 100.0, Test accuracy 94.052734375, Cost 62.26394748687744 s\n",
      "Epoch 437, Train loss 1.5845650505859656e-05, Test loss 0.41680670753121374, Train accuracy 100.0, Test accuracy 94.072265625, Cost 62.25032186508179 s\n",
      "Epoch 438, Train loss 2.2793062463367222e-05, Test loss 0.41775076314806936, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.16216063499451 s\n",
      "Epoch 439, Train loss 1.0768692868144946e-05, Test loss 0.4173530533909798, Train accuracy 100.0, Test accuracy 94.08203125, Cost 62.17374396324158 s\n",
      "Epoch 440, Train loss 1.0072447794033571e-05, Test loss 0.4169613093137741, Train accuracy 100.0, Test accuracy 94.0625, Cost 62.13506364822388 s\n",
      "Model saved in epoch 440\n",
      "Epoch 441, Train loss 2.2897650875746903e-05, Test loss 0.41795025765895844, Train accuracy 100.0, Test accuracy 94.08203125, Cost 62.15315580368042 s\n",
      "Epoch 442, Train loss 1.5505450406584603e-05, Test loss 0.41785512343049047, Train accuracy 100.0, Test accuracy 94.091796875, Cost 62.113356590270996 s\n",
      "Epoch 443, Train loss 2.5777943341560266e-05, Test loss 0.41725755520164964, Train accuracy 100.0, Test accuracy 94.052734375, Cost 62.11276078224182 s\n",
      "Epoch 444, Train loss 1.5398524963463657e-05, Test loss 0.41730746775865557, Train accuracy 100.0, Test accuracy 94.0625, Cost 62.14240837097168 s\n",
      "Epoch 445, Train loss 4.276640635921745e-05, Test loss 0.42795734629035, Train accuracy 99.99800701530613, Test accuracy 93.876953125, Cost 62.104029178619385 s\n",
      "Model saved in epoch 445\n",
      "Epoch 446, Train loss 1.6557711499900755e-05, Test loss 0.4247402656823397, Train accuracy 100.0, Test accuracy 93.90625, Cost 61.90766644477844 s\n",
      "Epoch 447, Train loss 2.3173676435924198e-05, Test loss 0.4252016719430685, Train accuracy 100.0, Test accuracy 93.896484375, Cost 61.94354510307312 s\n",
      "Epoch 448, Train loss 2.7642175595588014e-05, Test loss 0.42927110828459264, Train accuracy 100.0, Test accuracy 93.916015625, Cost 61.92317008972168 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449, Train loss 2.436673052493322e-05, Test loss 0.43216184973716737, Train accuracy 100.0, Test accuracy 93.896484375, Cost 61.92343020439148 s\n",
      "Epoch 450, Train loss 1.8779277179036472e-05, Test loss 0.42642318196594714, Train accuracy 100.0, Test accuracy 93.876953125, Cost 62.07629728317261 s\n",
      "Model saved in epoch 450\n",
      "Epoch 451, Train loss 1.9460581412057442e-05, Test loss 0.42335310727357867, Train accuracy 100.0, Test accuracy 93.80859375, Cost 62.15950393676758 s\n",
      "Epoch 452, Train loss 1.4783238237586194e-05, Test loss 0.422449854016304, Train accuracy 100.0, Test accuracy 93.798828125, Cost 62.18683195114136 s\n",
      "Epoch 453, Train loss 1.3186509953300174e-05, Test loss 0.4219543967396021, Train accuracy 100.0, Test accuracy 93.798828125, Cost 62.195961236953735 s\n",
      "Epoch 454, Train loss 1.4996576409313251e-05, Test loss 0.4221533454954624, Train accuracy 100.0, Test accuracy 93.76953125, Cost 62.45021629333496 s\n",
      "Epoch 455, Train loss 1.6393716526979507e-05, Test loss 0.4221760965883732, Train accuracy 100.0, Test accuracy 93.828125, Cost 62.329843282699585 s\n",
      "Model saved in epoch 455\n",
      "Epoch 456, Train loss 1.3325300323444656e-05, Test loss 0.4222503829747438, Train accuracy 100.0, Test accuracy 93.837890625, Cost 62.138625144958496 s\n",
      "Epoch 457, Train loss 1.610981063458778e-05, Test loss 0.4210890244692564, Train accuracy 100.0, Test accuracy 93.80859375, Cost 62.12694764137268 s\n",
      "Epoch 458, Train loss 1.3617069589135822e-05, Test loss 0.4223685674369335, Train accuracy 100.0, Test accuracy 93.818359375, Cost 62.02036714553833 s\n",
      "Epoch 459, Train loss 2.2474148761172535e-05, Test loss 0.4204284269362688, Train accuracy 100.0, Test accuracy 93.837890625, Cost 62.032727003097534 s\n",
      "Epoch 460, Train loss 1.2524565736599442e-05, Test loss 0.41942465454339983, Train accuracy 100.0, Test accuracy 93.896484375, Cost 62.18474340438843 s\n",
      "Model saved in epoch 460\n",
      "Epoch 461, Train loss 2.151388909278374e-05, Test loss 0.42377974428236487, Train accuracy 100.0, Test accuracy 93.8671875, Cost 62.14624071121216 s\n",
      "Epoch 462, Train loss 1.4383604247323278e-05, Test loss 0.4227207239717245, Train accuracy 100.0, Test accuracy 93.876953125, Cost 62.18140530586243 s\n",
      "Epoch 463, Train loss 1.7448292819248845e-05, Test loss 0.42320670522749426, Train accuracy 100.0, Test accuracy 93.876953125, Cost 62.146246671676636 s\n",
      "Epoch 464, Train loss 1.5388528195460693e-05, Test loss 0.42319869697093965, Train accuracy 100.0, Test accuracy 93.8671875, Cost 62.12544512748718 s\n",
      "Epoch 465, Train loss 1.2471098146298637e-05, Test loss 0.4225713461637497, Train accuracy 100.0, Test accuracy 93.857421875, Cost 62.146892786026 s\n",
      "Model saved in epoch 465\n",
      "Epoch 466, Train loss 1.5106053990273128e-05, Test loss 0.4223563838750124, Train accuracy 100.0, Test accuracy 93.955078125, Cost 62.10103416442871 s\n",
      "Epoch 467, Train loss 1.2238812774590278e-05, Test loss 0.4222150698304176, Train accuracy 100.0, Test accuracy 93.984375, Cost 62.130300760269165 s\n",
      "Epoch 468, Train loss 1.4028910089994692e-05, Test loss 0.4221320923417807, Train accuracy 100.0, Test accuracy 93.955078125, Cost 62.10984563827515 s\n",
      "Epoch 469, Train loss 1.6230401137866985e-05, Test loss 0.42137431241571904, Train accuracy 100.0, Test accuracy 94.013671875, Cost 62.124305963516235 s\n",
      "Epoch 470, Train loss 2.342204176749053e-05, Test loss 0.42100057676434516, Train accuracy 100.0, Test accuracy 93.984375, Cost 62.10646343231201 s\n",
      "Model saved in epoch 470\n",
      "Epoch 471, Train loss 2.228362976213749e-05, Test loss 0.42023980617523193, Train accuracy 100.0, Test accuracy 93.994140625, Cost 62.09998798370361 s\n",
      "Epoch 472, Train loss 1.2373615686208129e-05, Test loss 0.419820923358202, Train accuracy 100.0, Test accuracy 94.00390625, Cost 62.31491446495056 s\n",
      "Epoch 473, Train loss 3.164041024177197e-05, Test loss 0.42004312202334404, Train accuracy 100.0, Test accuracy 94.04296875, Cost 62.049418687820435 s\n",
      "Epoch 474, Train loss 2.0679607962218756e-05, Test loss 0.42121828719973564, Train accuracy 100.0, Test accuracy 93.994140625, Cost 61.981897592544556 s\n",
      "Epoch 475, Train loss 1.4852027631032956e-05, Test loss 0.4198884803801775, Train accuracy 100.0, Test accuracy 93.916015625, Cost 61.93176627159119 s\n",
      "Model saved in epoch 475\n",
      "Epoch 476, Train loss 1.2765947545435155e-05, Test loss 0.41938836611807345, Train accuracy 100.0, Test accuracy 93.955078125, Cost 61.992281913757324 s\n",
      "Epoch 477, Train loss 1.5017339599555215e-05, Test loss 0.418183371424675, Train accuracy 100.0, Test accuracy 93.955078125, Cost 62.117960691452026 s\n",
      "Epoch 478, Train loss 1.1833895047668277e-05, Test loss 0.4182987201958895, Train accuracy 100.0, Test accuracy 93.90625, Cost 62.079952239990234 s\n",
      "Epoch 479, Train loss 1.1905465764585893e-05, Test loss 0.4183736864477396, Train accuracy 100.0, Test accuracy 93.935546875, Cost 62.111167430877686 s\n",
      "Epoch 480, Train loss 1.2041903859222211e-05, Test loss 0.41833029948174955, Train accuracy 100.0, Test accuracy 93.92578125, Cost 62.05679154396057 s\n",
      "Model saved in epoch 480\n",
      "Epoch 481, Train loss 1.2136039608068985e-05, Test loss 0.4182484596967697, Train accuracy 100.0, Test accuracy 93.9453125, Cost 62.20439314842224 s\n",
      "Epoch 482, Train loss 1.1223595998058276e-05, Test loss 0.4184407271444798, Train accuracy 100.0, Test accuracy 93.955078125, Cost 62.147745847702026 s\n",
      "Epoch 483, Train loss 1.3093439623698292e-05, Test loss 0.4184737905859947, Train accuracy 100.0, Test accuracy 93.9453125, Cost 62.19770836830139 s\n",
      "Epoch 484, Train loss 1.3202397840405884e-05, Test loss 0.41756516247987746, Train accuracy 100.0, Test accuracy 93.916015625, Cost 62.160810232162476 s\n",
      "Epoch 485, Train loss 1.2210971494469931e-05, Test loss 0.417493062838912, Train accuracy 100.0, Test accuracy 93.857421875, Cost 62.13954544067383 s\n",
      "Model saved in epoch 485\n",
      "Epoch 486, Train loss 1.321903392255946e-05, Test loss 0.4183909114450216, Train accuracy 100.0, Test accuracy 93.876953125, Cost 62.09806489944458 s\n",
      "Epoch 487, Train loss 1.2824535858158015e-05, Test loss 0.4202794320881367, Train accuracy 100.0, Test accuracy 93.876953125, Cost 62.15802764892578 s\n",
      "Epoch 488, Train loss 1.0081714965009751e-05, Test loss 0.4181546252220869, Train accuracy 100.0, Test accuracy 93.896484375, Cost 62.126092195510864 s\n",
      "Epoch 489, Train loss 1.4206909544843803e-05, Test loss 0.4177070166915655, Train accuracy 100.0, Test accuracy 93.955078125, Cost 62.1001877784729 s\n",
      "Epoch 490, Train loss 1.3634133958826355e-05, Test loss 0.41687627509236336, Train accuracy 100.0, Test accuracy 93.92578125, Cost 62.38033366203308 s\n",
      "Model saved in epoch 490\n",
      "Epoch 491, Train loss 1.3055857424685586e-05, Test loss 0.4169387225061655, Train accuracy 100.0, Test accuracy 93.92578125, Cost 62.25369143486023 s\n",
      "Epoch 492, Train loss 1.7632245755071475e-05, Test loss 0.4167575504630804, Train accuracy 100.0, Test accuracy 93.88671875, Cost 62.01349186897278 s\n",
      "Epoch 493, Train loss 1.3256831587856437e-05, Test loss 0.4152090672403574, Train accuracy 100.0, Test accuracy 93.90625, Cost 61.869988441467285 s\n",
      "Epoch 494, Train loss 1.1201300952792531e-05, Test loss 0.4161060657352209, Train accuracy 100.0, Test accuracy 93.857421875, Cost 61.89755606651306 s\n",
      "Epoch 495, Train loss 1.0350989240594441e-05, Test loss 0.41583583131432533, Train accuracy 100.0, Test accuracy 93.88671875, Cost 61.86674642562866 s\n",
      "Model saved in epoch 495\n",
      "Epoch 496, Train loss 1.4814999383535292e-05, Test loss 0.4163147069513798, Train accuracy 100.0, Test accuracy 93.8671875, Cost 61.87403225898743 s\n",
      "Epoch 497, Train loss 7.726760354300347e-06, Test loss 0.416314934194088, Train accuracy 100.0, Test accuracy 93.916015625, Cost 62.2609338760376 s\n",
      "Epoch 498, Train loss 1.6545644661777938e-05, Test loss 0.41518420688807967, Train accuracy 100.0, Test accuracy 93.92578125, Cost 61.882386207580566 s\n",
      "Epoch 499, Train loss 8.964385474184513e-06, Test loss 0.4148312024772167, Train accuracy 100.0, Test accuracy 93.92578125, Cost 61.85496973991394 s\n",
      "Epoch 500, Train loss 9.982202586409317e-06, Test loss 0.41469280757009985, Train accuracy 100.0, Test accuracy 93.9453125, Cost 61.88226318359375 s\n",
      "Model saved in epoch 500\n",
      "Epoch 501, Train loss 9.21953359783847e-06, Test loss 0.41428471468389033, Train accuracy 100.0, Test accuracy 93.96484375, Cost 61.886263370513916 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 502, Train loss 8.750232658177984e-06, Test loss 0.4143998999148607, Train accuracy 100.0, Test accuracy 93.955078125, Cost 62.19379115104675 s\n",
      "Epoch 503, Train loss 1.2887080320139403e-05, Test loss 0.4134718727320433, Train accuracy 100.0, Test accuracy 93.955078125, Cost 61.88779807090759 s\n",
      "Epoch 504, Train loss 8.336438769192125e-06, Test loss 0.41339488737285135, Train accuracy 100.0, Test accuracy 93.955078125, Cost 61.90096735954285 s\n",
      "Epoch 505, Train loss 7.754830466593858e-06, Test loss 0.4136297222226858, Train accuracy 100.0, Test accuracy 94.091796875, Cost 61.871158838272095 s\n",
      "Model saved in epoch 505\n",
      "Epoch 506, Train loss 9.800553287704485e-06, Test loss 0.41391642540693285, Train accuracy 100.0, Test accuracy 94.130859375, Cost 61.88169980049133 s\n",
      "Epoch 507, Train loss 1.411327129873445e-05, Test loss 0.41403722316026687, Train accuracy 100.0, Test accuracy 93.96484375, Cost 61.85537838935852 s\n",
      "Epoch 508, Train loss 1.043351064755389e-05, Test loss 0.413825311511755, Train accuracy 100.0, Test accuracy 93.955078125, Cost 62.10759997367859 s\n",
      "Epoch 509, Train loss 1.171778993060118e-05, Test loss 0.41358028426766397, Train accuracy 100.0, Test accuracy 93.9453125, Cost 62.14263439178467 s\n",
      "Epoch 510, Train loss 1.057894564359096e-05, Test loss 0.413888356462121, Train accuracy 100.0, Test accuracy 93.88671875, Cost 62.16447973251343 s\n",
      "Model saved in epoch 510\n",
      "Epoch 511, Train loss 1.0472284601034948e-05, Test loss 0.4149044848978519, Train accuracy 100.0, Test accuracy 93.88671875, Cost 62.020742416381836 s\n",
      "Epoch 512, Train loss 1.4862262183177503e-05, Test loss 0.4147287406027317, Train accuracy 100.0, Test accuracy 93.994140625, Cost 62.114272594451904 s\n",
      "Epoch 513, Train loss 1.6772157615405355e-05, Test loss 0.41322595775127413, Train accuracy 100.0, Test accuracy 93.90625, Cost 62.15472483634949 s\n",
      "Epoch 514, Train loss 9.726103869246688e-06, Test loss 0.41365358158946036, Train accuracy 100.0, Test accuracy 93.916015625, Cost 62.14181685447693 s\n",
      "Epoch 515, Train loss 8.065631112801886e-06, Test loss 0.4136995211243629, Train accuracy 100.0, Test accuracy 93.896484375, Cost 62.1831111907959 s\n",
      "Model saved in epoch 515\n",
      "Epoch 516, Train loss 1.0080638447377345e-05, Test loss 0.4141288366168737, Train accuracy 100.0, Test accuracy 93.90625, Cost 62.16866898536682 s\n",
      "Epoch 517, Train loss 9.767281879617815e-06, Test loss 0.4142361801117659, Train accuracy 100.0, Test accuracy 93.9453125, Cost 62.12387180328369 s\n",
      "Epoch 518, Train loss 9.559593374203767e-06, Test loss 0.41463999152183534, Train accuracy 100.0, Test accuracy 93.935546875, Cost 62.12492871284485 s\n",
      "Epoch 519, Train loss 8.462927013977382e-06, Test loss 0.4149035096168518, Train accuracy 100.0, Test accuracy 93.92578125, Cost 62.10546541213989 s\n",
      "Epoch 520, Train loss 9.38888314454182e-06, Test loss 0.4144599366933107, Train accuracy 100.0, Test accuracy 94.12109375, Cost 62.09760618209839 s\n",
      "Model saved in epoch 520\n",
      "Epoch 521, Train loss 7.5711890456123654e-06, Test loss 0.41492984965443613, Train accuracy 100.0, Test accuracy 94.111328125, Cost 61.88276481628418 s\n",
      "Epoch 522, Train loss 1.2104950073856631e-05, Test loss 0.41543598622083666, Train accuracy 100.0, Test accuracy 94.12109375, Cost 61.85711312294006 s\n",
      "Epoch 523, Train loss 1.3648241324587189e-05, Test loss 0.41421015597879884, Train accuracy 100.0, Test accuracy 94.072265625, Cost 61.812904357910156 s\n",
      "Epoch 524, Train loss 8.945581475753601e-06, Test loss 0.41477545723319054, Train accuracy 100.0, Test accuracy 94.072265625, Cost 61.89999866485596 s\n",
      "Epoch 525, Train loss 6.248200718903031e-06, Test loss 0.41492394655942916, Train accuracy 100.0, Test accuracy 94.052734375, Cost 61.94862985610962 s\n",
      "Model saved in epoch 525\n",
      "Epoch 526, Train loss 8.82519193063607e-06, Test loss 0.41505711860954764, Train accuracy 100.0, Test accuracy 94.0625, Cost 62.13605093955994 s\n",
      "Epoch 527, Train loss 9.366535626347578e-06, Test loss 0.4158104207366705, Train accuracy 100.0, Test accuracy 94.111328125, Cost 61.93472695350647 s\n",
      "Epoch 528, Train loss 6.867419101848434e-06, Test loss 0.41623275466263293, Train accuracy 100.0, Test accuracy 94.130859375, Cost 61.91498875617981 s\n",
      "Epoch 529, Train loss 1.8542239445594947e-05, Test loss 0.4172760047018528, Train accuracy 100.0, Test accuracy 94.072265625, Cost 61.86987352371216 s\n",
      "Epoch 530, Train loss 8.658868382287103e-06, Test loss 0.41784697622060774, Train accuracy 100.0, Test accuracy 94.052734375, Cost 61.91194224357605 s\n",
      "Model saved in epoch 530\n",
      "Epoch 531, Train loss 1.0531071382192239e-05, Test loss 0.4178468633443117, Train accuracy 100.0, Test accuracy 94.0234375, Cost 61.93552565574646 s\n",
      "Epoch 532, Train loss 9.216108762058416e-06, Test loss 0.41750316619873046, Train accuracy 100.0, Test accuracy 94.00390625, Cost 61.944968938827515 s\n",
      "Epoch 533, Train loss 1.3217981240373143e-05, Test loss 0.4172786954790354, Train accuracy 100.0, Test accuracy 93.984375, Cost 61.90730357170105 s\n",
      "Epoch 534, Train loss 9.530042351205534e-06, Test loss 0.4177813667804003, Train accuracy 100.0, Test accuracy 94.04296875, Cost 61.872992277145386 s\n",
      "Epoch 535, Train loss 8.662052730165455e-06, Test loss 0.41797182857990267, Train accuracy 100.0, Test accuracy 94.013671875, Cost 61.92381405830383 s\n",
      "Model saved in epoch 535\n",
      "Epoch 536, Train loss 6.534086735694807e-06, Test loss 0.4180116582661867, Train accuracy 100.0, Test accuracy 94.00390625, Cost 61.933743476867676 s\n",
      "Epoch 537, Train loss 8.046602356072833e-06, Test loss 0.4180197067558765, Train accuracy 100.0, Test accuracy 93.994140625, Cost 61.880009174346924 s\n",
      "Epoch 538, Train loss 8.64441273559383e-06, Test loss 0.4179156441241503, Train accuracy 100.0, Test accuracy 94.04296875, Cost 61.90589618682861 s\n",
      "Epoch 539, Train loss 7.318476465752263e-06, Test loss 0.4176981244236231, Train accuracy 100.0, Test accuracy 94.033203125, Cost 61.9215829372406 s\n",
      "Epoch 540, Train loss 8.699051967218278e-06, Test loss 0.4178683213889599, Train accuracy 100.0, Test accuracy 94.04296875, Cost 61.90804052352905 s\n",
      "Model saved in epoch 540\n",
      "Epoch 541, Train loss 9.979897864626282e-06, Test loss 0.4169677734375, Train accuracy 100.0, Test accuracy 94.072265625, Cost 61.912633180618286 s\n",
      "Epoch 542, Train loss 6.577124397510107e-06, Test loss 0.41696569658815863, Train accuracy 100.0, Test accuracy 94.04296875, Cost 61.86328196525574 s\n",
      "Epoch 543, Train loss 9.493263453020044e-06, Test loss 0.4170128062367439, Train accuracy 100.0, Test accuracy 94.0234375, Cost 61.95580983161926 s\n",
      "Epoch 544, Train loss 8.951074185423917e-06, Test loss 0.4170870166271925, Train accuracy 100.0, Test accuracy 94.04296875, Cost 62.17294478416443 s\n",
      "Epoch 545, Train loss 1.0598548697501252e-05, Test loss 0.4168111652135849, Train accuracy 100.0, Test accuracy 94.013671875, Cost 61.93781495094299 s\n",
      "Model saved in epoch 545\n",
      "Epoch 546, Train loss 8.560229773387252e-06, Test loss 0.41708088479936123, Train accuracy 100.0, Test accuracy 94.033203125, Cost 61.97467756271362 s\n",
      "Epoch 547, Train loss 1.2326470820854104e-05, Test loss 0.41612682677805424, Train accuracy 100.0, Test accuracy 94.033203125, Cost 61.93296217918396 s\n",
      "Epoch 548, Train loss 7.843981632861738e-06, Test loss 0.41653846092522145, Train accuracy 100.0, Test accuracy 94.0625, Cost 61.91482853889465 s\n",
      "Epoch 549, Train loss 7.422239289464219e-06, Test loss 0.4164430875331163, Train accuracy 100.0, Test accuracy 94.0625, Cost 61.87934970855713 s\n",
      "Epoch 550, Train loss 6.411420799293187e-06, Test loss 0.41634863018989565, Train accuracy 100.0, Test accuracy 94.052734375, Cost 61.91412281990051 s\n",
      "Model saved in epoch 550\n",
      "Epoch 551, Train loss 6.699074922218122e-06, Test loss 0.4166339810937643, Train accuracy 100.0, Test accuracy 94.072265625, Cost 61.8859179019928 s\n",
      "Epoch 552, Train loss 7.58649354943535e-06, Test loss 0.41737815029919145, Train accuracy 100.0, Test accuracy 94.08203125, Cost 61.91079306602478 s\n",
      "Epoch 553, Train loss 1.717151492540227e-05, Test loss 0.42396801970899106, Train accuracy 100.0, Test accuracy 94.111328125, Cost 61.92011380195618 s\n",
      "Epoch 554, Train loss 9.633102758688002e-06, Test loss 0.42271324843168256, Train accuracy 100.0, Test accuracy 94.0625, Cost 61.882612466812134 s\n",
      "Epoch 555, Train loss 1.1339120266087571e-05, Test loss 0.4239105168730021, Train accuracy 100.0, Test accuracy 94.091796875, Cost 61.90187168121338 s\n",
      "Model saved in epoch 555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556, Train loss 8.579181405995155e-06, Test loss 0.4235896483063698, Train accuracy 100.0, Test accuracy 94.091796875, Cost 61.89235544204712 s\n",
      "Epoch 557, Train loss 8.078543937534269e-06, Test loss 0.422715437784791, Train accuracy 100.0, Test accuracy 94.111328125, Cost 61.878750801086426 s\n",
      "Epoch 558, Train loss 8.365816704559963e-06, Test loss 0.42231237441301345, Train accuracy 100.0, Test accuracy 94.1015625, Cost 61.86049509048462 s\n",
      "Epoch 559, Train loss 7.11516918809069e-06, Test loss 0.4220379631966352, Train accuracy 100.0, Test accuracy 94.08203125, Cost 61.848304748535156 s\n",
      "Epoch 560, Train loss 6.679785712569068e-06, Test loss 0.4220127783715725, Train accuracy 100.0, Test accuracy 94.08203125, Cost 61.843857526779175 s\n",
      "Model saved in epoch 560\n",
      "Epoch 561, Train loss 9.43145029307799e-06, Test loss 0.4215919688344002, Train accuracy 100.0, Test accuracy 94.091796875, Cost 61.99170637130737 s\n",
      "Epoch 562, Train loss 6.8696266696731205e-06, Test loss 0.42150162123143675, Train accuracy 100.0, Test accuracy 94.072265625, Cost 62.159358739852905 s\n",
      "Epoch 563, Train loss 8.412510778981062e-06, Test loss 0.4213402111083269, Train accuracy 100.0, Test accuracy 94.111328125, Cost 61.91673421859741 s\n",
      "Epoch 564, Train loss 7.328009101657392e-06, Test loss 0.42127038426697255, Train accuracy 100.0, Test accuracy 94.140625, Cost 61.88013243675232 s\n",
      "Epoch 565, Train loss 1.7947805942140705e-05, Test loss 0.4214009214192629, Train accuracy 100.0, Test accuracy 94.08203125, Cost 61.89431118965149 s\n",
      "Model saved in epoch 565\n",
      "Epoch 566, Train loss 8.815949602046542e-06, Test loss 0.42176113501191137, Train accuracy 100.0, Test accuracy 94.0625, Cost 61.865652322769165 s\n",
      "Epoch 567, Train loss 9.128143336384682e-06, Test loss 0.4211380250751972, Train accuracy 100.0, Test accuracy 94.08203125, Cost 61.867411375045776 s\n",
      "Epoch 568, Train loss 7.751870103537126e-06, Test loss 0.42079600542783735, Train accuracy 100.0, Test accuracy 94.072265625, Cost 61.881442070007324 s\n",
      "Epoch 569, Train loss 9.895722460491785e-06, Test loss 0.4202317535877228, Train accuracy 100.0, Test accuracy 94.1015625, Cost 61.85873818397522 s\n",
      "Epoch 570, Train loss 9.734233320789464e-06, Test loss 0.4194140139967203, Train accuracy 100.0, Test accuracy 94.150390625, Cost 61.87008500099182 s\n",
      "Model saved in epoch 570\n",
      "Epoch 571, Train loss 9.451136615708998e-06, Test loss 0.4193726722151041, Train accuracy 100.0, Test accuracy 94.111328125, Cost 61.93586778640747 s\n",
      "Epoch 572, Train loss 6.1804536685207385e-06, Test loss 0.41932938545942305, Train accuracy 100.0, Test accuracy 94.130859375, Cost 61.87122583389282 s\n",
      "Epoch 573, Train loss 6.551208525648894e-06, Test loss 0.4191221624612808, Train accuracy 100.0, Test accuracy 94.111328125, Cost 61.88753390312195 s\n",
      "Epoch 574, Train loss 7.2559864934806705e-06, Test loss 0.4199005112051964, Train accuracy 100.0, Test accuracy 94.08203125, Cost 61.905970096588135 s\n",
      "Epoch 575, Train loss 7.409329445893639e-06, Test loss 0.42010022737085817, Train accuracy 100.0, Test accuracy 94.08203125, Cost 61.92064547538757 s\n",
      "Model saved in epoch 575\n",
      "Epoch 576, Train loss 6.465625987767008e-06, Test loss 0.42042653299868105, Train accuracy 100.0, Test accuracy 94.08203125, Cost 61.97291088104248 s\n",
      "Epoch 577, Train loss 6.883215648032922e-06, Test loss 0.42022792920470237, Train accuracy 100.0, Test accuracy 94.04296875, Cost 61.91107797622681 s\n",
      "Epoch 578, Train loss 7.996960532323658e-06, Test loss 0.4203909646719694, Train accuracy 100.0, Test accuracy 94.111328125, Cost 61.85860061645508 s\n",
      "Epoch 579, Train loss 7.36231932046858e-06, Test loss 0.4204150982201099, Train accuracy 100.0, Test accuracy 94.140625, Cost 61.97753834724426 s\n",
      "Epoch 580, Train loss 7.918513884289045e-06, Test loss 0.4209753852337599, Train accuracy 100.0, Test accuracy 94.12109375, Cost 62.12029218673706 s\n",
      "Model saved in epoch 580\n",
      "Epoch 581, Train loss 8.166479608433395e-06, Test loss 0.42031503915786744, Train accuracy 100.0, Test accuracy 94.1015625, Cost 61.97526168823242 s\n",
      "Epoch 582, Train loss 7.225455245891597e-06, Test loss 0.4206156250089407, Train accuracy 100.0, Test accuracy 94.111328125, Cost 61.94186091423035 s\n",
      "Epoch 583, Train loss 1.268878571215853e-05, Test loss 0.4214246470481157, Train accuracy 100.0, Test accuracy 94.1796875, Cost 61.929916858673096 s\n",
      "Epoch 584, Train loss 1.1255446559212775e-05, Test loss 0.4213722113519907, Train accuracy 100.0, Test accuracy 94.111328125, Cost 61.98305654525757 s\n",
      "Epoch 585, Train loss 6.428793787928178e-06, Test loss 0.42102690376341345, Train accuracy 100.0, Test accuracy 94.130859375, Cost 61.9263277053833 s\n",
      "Model saved in epoch 585\n",
      "Epoch 586, Train loss 6.38653485434217e-06, Test loss 0.42110311724245547, Train accuracy 100.0, Test accuracy 94.16015625, Cost 61.91017985343933 s\n",
      "Epoch 587, Train loss 7.304657397993679e-06, Test loss 0.4212595097720623, Train accuracy 100.0, Test accuracy 94.140625, Cost 61.90306615829468 s\n",
      "Epoch 588, Train loss 7.3692040706535e-06, Test loss 0.42161290124058726, Train accuracy 100.0, Test accuracy 94.16015625, Cost 61.859920024871826 s\n",
      "Epoch 589, Train loss 8.479507930245494e-06, Test loss 0.4215457521378994, Train accuracy 100.0, Test accuracy 94.169921875, Cost 61.887836933135986 s\n",
      "Epoch 590, Train loss 7.3663912030729175e-06, Test loss 0.421447192505002, Train accuracy 100.0, Test accuracy 94.189453125, Cost 61.88758993148804 s\n",
      "Model saved in epoch 590\n",
      "Epoch 591, Train loss 7.0051870663950915e-06, Test loss 0.42143105529248714, Train accuracy 100.0, Test accuracy 94.189453125, Cost 61.9235520362854 s\n",
      "Epoch 592, Train loss 8.218321772192536e-06, Test loss 0.42161911725997925, Train accuracy 100.0, Test accuracy 94.169921875, Cost 62.14175748825073 s\n",
      "Epoch 593, Train loss 6.861906661421406e-06, Test loss 0.42167108580470086, Train accuracy 100.0, Test accuracy 94.208984375, Cost 62.1275954246521 s\n",
      "Epoch 594, Train loss 8.940533843092545e-06, Test loss 0.42171345353126527, Train accuracy 100.0, Test accuracy 94.1796875, Cost 62.16553258895874 s\n",
      "Epoch 595, Train loss 1.0702577608447088e-05, Test loss 0.42117358557879925, Train accuracy 100.0, Test accuracy 94.21875, Cost 62.1148567199707 s\n",
      "Model saved in epoch 595\n",
      "Epoch 596, Train loss 6.640625192880393e-06, Test loss 0.4211718238890171, Train accuracy 100.0, Test accuracy 94.228515625, Cost 62.12975263595581 s\n",
      "Epoch 597, Train loss 7.234310872835364e-06, Test loss 0.42182463929057123, Train accuracy 100.0, Test accuracy 94.19921875, Cost 62.24219298362732 s\n",
      "Epoch 598, Train loss 8.164824279788263e-06, Test loss 0.4220665667206049, Train accuracy 100.0, Test accuracy 94.21875, Cost 62.35081934928894 s\n",
      "Epoch 599, Train loss 6.36413708199788e-06, Test loss 0.4220509462058544, Train accuracy 100.0, Test accuracy 94.189453125, Cost 62.140668630599976 s\n",
      "Epoch 600, Train loss 6.074597845692356e-06, Test loss 0.42216700278222563, Train accuracy 100.0, Test accuracy 94.1796875, Cost 62.09723615646362 s\n",
      "Model saved in epoch 600\n",
      "Epoch 601, Train loss 9.244548679726458e-06, Test loss 0.4228428706526756, Train accuracy 100.0, Test accuracy 94.189453125, Cost 62.08031392097473 s\n",
      "Epoch 602, Train loss 5.681461792891919e-06, Test loss 0.4229531854391098, Train accuracy 100.0, Test accuracy 94.189453125, Cost 62.100759506225586 s\n",
      "Epoch 603, Train loss 8.805893351973514e-06, Test loss 0.425785568729043, Train accuracy 100.0, Test accuracy 94.19921875, Cost 62.090397357940674 s\n",
      "Epoch 604, Train loss 5.738853613240213e-06, Test loss 0.42575694508850576, Train accuracy 100.0, Test accuracy 94.208984375, Cost 62.105154275894165 s\n",
      "Epoch 605, Train loss 6.00535021852252e-06, Test loss 0.42545782811939714, Train accuracy 100.0, Test accuracy 94.189453125, Cost 62.15173029899597 s\n",
      "Model saved in epoch 605\n",
      "Epoch 606, Train loss 5.8735548209248075e-06, Test loss 0.42536206506192686, Train accuracy 100.0, Test accuracy 94.169921875, Cost 62.13042426109314 s\n",
      "Epoch 607, Train loss 8.060819767574893e-06, Test loss 0.4252114240080118, Train accuracy 100.0, Test accuracy 94.16015625, Cost 62.09961676597595 s\n",
      "Epoch 608, Train loss 5.7275964510717945e-06, Test loss 0.42514545619487765, Train accuracy 100.0, Test accuracy 94.169921875, Cost 62.093284368515015 s\n",
      "Epoch 609, Train loss 6.804195764353418e-06, Test loss 0.4248009767383337, Train accuracy 100.0, Test accuracy 94.169921875, Cost 62.13132834434509 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 610, Train loss 6.140778700665458e-06, Test loss 0.42485199831426146, Train accuracy 100.0, Test accuracy 94.169921875, Cost 62.12612462043762 s\n",
      "Model saved in epoch 610\n",
      "Epoch 611, Train loss 5.419347770577346e-06, Test loss 0.4251440417021513, Train accuracy 100.0, Test accuracy 94.16015625, Cost 62.13169240951538 s\n",
      "Epoch 612, Train loss 6.913918172963511e-06, Test loss 0.4252386841922998, Train accuracy 100.0, Test accuracy 94.169921875, Cost 62.13010215759277 s\n",
      "Epoch 613, Train loss 6.707448370801159e-06, Test loss 0.4255478423088789, Train accuracy 100.0, Test accuracy 94.169921875, Cost 62.189709186553955 s\n",
      "Epoch 614, Train loss 6.241575546655486e-06, Test loss 0.4256771828979254, Train accuracy 100.0, Test accuracy 94.19921875, Cost 62.11050820350647 s\n",
      "Epoch 615, Train loss 7.824931803755283e-06, Test loss 0.4251671351492405, Train accuracy 100.0, Test accuracy 94.228515625, Cost 62.28470754623413 s\n",
      "Model saved in epoch 615\n",
      "Epoch 616, Train loss 5.727905396938416e-06, Test loss 0.42533193379640577, Train accuracy 100.0, Test accuracy 94.21875, Cost 62.282455921173096 s\n",
      "Epoch 617, Train loss 5.955592437171548e-06, Test loss 0.4254025109112263, Train accuracy 100.0, Test accuracy 94.228515625, Cost 62.0665020942688 s\n",
      "Epoch 618, Train loss 5.261657906000822e-06, Test loss 0.4253179643303156, Train accuracy 100.0, Test accuracy 94.228515625, Cost 62.113261461257935 s\n",
      "Epoch 619, Train loss 5.0701584790002075e-06, Test loss 0.4253727667033672, Train accuracy 100.0, Test accuracy 94.21875, Cost 62.11520743370056 s\n",
      "Epoch 620, Train loss 6.064751468264669e-06, Test loss 0.42514229714870455, Train accuracy 100.0, Test accuracy 94.19921875, Cost 62.05735182762146 s\n",
      "Model saved in epoch 620\n",
      "Epoch 621, Train loss 5.416496672462379e-06, Test loss 0.42515960298478606, Train accuracy 100.0, Test accuracy 94.19921875, Cost 62.149580001831055 s\n",
      "Epoch 622, Train loss 5.937908420489702e-06, Test loss 0.42527509704232214, Train accuracy 100.0, Test accuracy 94.19921875, Cost 62.13571786880493 s\n",
      "Epoch 623, Train loss 4.479853967116385e-06, Test loss 0.4251262523233891, Train accuracy 100.0, Test accuracy 94.19921875, Cost 62.13283944129944 s\n",
      "Epoch 624, Train loss 1.046577264217165e-05, Test loss 0.42797260247170926, Train accuracy 100.0, Test accuracy 94.16015625, Cost 62.14027428627014 s\n",
      "Epoch 625, Train loss 4.7245770027847225e-06, Test loss 0.42785770893096925, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.16200137138367 s\n",
      "Model saved in epoch 625\n",
      "Epoch 626, Train loss 5.285182004370756e-06, Test loss 0.4277476415038109, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.13171076774597 s\n",
      "Epoch 627, Train loss 7.898849863274372e-06, Test loss 0.4278783731162548, Train accuracy 100.0, Test accuracy 94.111328125, Cost 62.16902422904968 s\n",
      "Epoch 628, Train loss 7.622667104652344e-06, Test loss 0.4274401467293501, Train accuracy 100.0, Test accuracy 94.1015625, Cost 62.15402817726135 s\n",
      "Epoch 629, Train loss 5.469989889647019e-06, Test loss 0.42729377187788486, Train accuracy 100.0, Test accuracy 94.12109375, Cost 62.17482328414917 s\n",
      "Epoch 630, Train loss 6.808794535495091e-06, Test loss 0.4273011177778244, Train accuracy 100.0, Test accuracy 94.111328125, Cost 62.11737370491028 s\n",
      "Model saved in epoch 630\n",
      "Epoch 631, Train loss 5.2662673178824845e-06, Test loss 0.42744141146540643, Train accuracy 100.0, Test accuracy 94.111328125, Cost 62.13410449028015 s\n",
      "Epoch 632, Train loss 4.922724468711953e-06, Test loss 0.4274049811065197, Train accuracy 100.0, Test accuracy 94.12109375, Cost 62.142847299575806 s\n",
      "Epoch 633, Train loss 7.271885229341381e-06, Test loss 0.42697737105190753, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.356486082077026 s\n",
      "Epoch 634, Train loss 6.908068682022002e-06, Test loss 0.4260575123131275, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.2936635017395 s\n",
      "Epoch 635, Train loss 7.084499932076068e-06, Test loss 0.42635435052216053, Train accuracy 100.0, Test accuracy 94.1015625, Cost 62.210028648376465 s\n",
      "Model saved in epoch 635\n",
      "Epoch 636, Train loss 5.055424621111356e-06, Test loss 0.4261522252112627, Train accuracy 100.0, Test accuracy 94.1015625, Cost 62.16248893737793 s\n",
      "Epoch 637, Train loss 5.203860025451191e-06, Test loss 0.42597076296806335, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.226706743240356 s\n",
      "Epoch 638, Train loss 6.0803942880207446e-06, Test loss 0.4258702971041203, Train accuracy 100.0, Test accuracy 94.12109375, Cost 62.18829345703125 s\n",
      "Epoch 639, Train loss 5.262442664345298e-06, Test loss 0.4256561078131199, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.16789627075195 s\n",
      "Epoch 640, Train loss 6.885782666159332e-06, Test loss 0.42522786259651185, Train accuracy 100.0, Test accuracy 94.16015625, Cost 62.18328356742859 s\n",
      "Model saved in epoch 640\n",
      "Epoch 641, Train loss 6.605231048231231e-06, Test loss 0.42505414187908175, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.15747404098511 s\n",
      "Epoch 642, Train loss 7.0986054765273585e-06, Test loss 0.4247786205261946, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.03323221206665 s\n",
      "Epoch 643, Train loss 5.650778627205696e-06, Test loss 0.42487324625253675, Train accuracy 100.0, Test accuracy 94.130859375, Cost 61.98200798034668 s\n",
      "Epoch 644, Train loss 6.484618434964715e-06, Test loss 0.42458116374909877, Train accuracy 100.0, Test accuracy 94.12109375, Cost 61.93459415435791 s\n",
      "Epoch 645, Train loss 7.69774650813574e-06, Test loss 0.424706656858325, Train accuracy 100.0, Test accuracy 94.130859375, Cost 61.93231010437012 s\n",
      "Model saved in epoch 645\n",
      "Epoch 646, Train loss 6.331415300323618e-06, Test loss 0.42485427111387253, Train accuracy 100.0, Test accuracy 94.1796875, Cost 61.92677402496338 s\n",
      "Epoch 647, Train loss 6.503641270190117e-06, Test loss 0.4248997211456299, Train accuracy 100.0, Test accuracy 94.19921875, Cost 61.964624881744385 s\n",
      "Epoch 648, Train loss 5.732723717882464e-06, Test loss 0.4249496694654226, Train accuracy 100.0, Test accuracy 94.189453125, Cost 61.95351767539978 s\n",
      "Epoch 649, Train loss 5.104738248143562e-06, Test loss 0.42534573152661326, Train accuracy 100.0, Test accuracy 94.19921875, Cost 61.94070482254028 s\n",
      "Epoch 650, Train loss 7.364543987576707e-06, Test loss 0.42555768638849256, Train accuracy 100.0, Test accuracy 94.19921875, Cost 61.95249342918396 s\n",
      "Model saved in epoch 650\n",
      "Epoch 651, Train loss 6.307029806862374e-06, Test loss 0.4256202556192875, Train accuracy 100.0, Test accuracy 94.1796875, Cost 62.173749685287476 s\n",
      "Epoch 652, Train loss 6.780394611449974e-06, Test loss 0.4255351360887289, Train accuracy 100.0, Test accuracy 94.21875, Cost 62.054516553878784 s\n",
      "Epoch 653, Train loss 5.819732447427984e-06, Test loss 0.42570885047316553, Train accuracy 100.0, Test accuracy 94.228515625, Cost 61.93291735649109 s\n",
      "Epoch 654, Train loss 6.3636624958950374e-06, Test loss 0.4253516461700201, Train accuracy 100.0, Test accuracy 94.21875, Cost 62.06970024108887 s\n",
      "Epoch 655, Train loss 6.037575194226269e-06, Test loss 0.4249615278095007, Train accuracy 100.0, Test accuracy 94.248046875, Cost 62.145381689071655 s\n",
      "Model saved in epoch 655\n",
      "Epoch 656, Train loss 5.691391021197692e-06, Test loss 0.42481934539973737, Train accuracy 100.0, Test accuracy 94.21875, Cost 62.156189918518066 s\n",
      "Epoch 657, Train loss 5.0988079776285465e-06, Test loss 0.4246411770582199, Train accuracy 100.0, Test accuracy 94.189453125, Cost 62.12056827545166 s\n",
      "Epoch 658, Train loss 7.162475108251394e-06, Test loss 0.4245609063655138, Train accuracy 100.0, Test accuracy 94.189453125, Cost 62.12820792198181 s\n",
      "Epoch 659, Train loss 6.1976101931389504e-06, Test loss 0.42478697299957274, Train accuracy 100.0, Test accuracy 94.208984375, Cost 62.129854679107666 s\n",
      "Epoch 660, Train loss 5.33700495150161e-06, Test loss 0.42501455284655093, Train accuracy 100.0, Test accuracy 94.19921875, Cost 62.12811255455017 s\n",
      "Model saved in epoch 660\n",
      "Epoch 661, Train loss 5.915432184723711e-06, Test loss 0.4245863653719425, Train accuracy 100.0, Test accuracy 94.208984375, Cost 62.127066135406494 s\n",
      "Epoch 662, Train loss 5.481299856197619e-06, Test loss 0.4246479358524084, Train accuracy 100.0, Test accuracy 94.19921875, Cost 62.116705656051636 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 663, Train loss 6.488785658700867e-06, Test loss 0.42487240545451643, Train accuracy 100.0, Test accuracy 94.21875, Cost 62.11779046058655 s\n",
      "Epoch 664, Train loss 4.422637064227292e-06, Test loss 0.42489696815609934, Train accuracy 100.0, Test accuracy 94.208984375, Cost 62.14357829093933 s\n",
      "Epoch 665, Train loss 5.82434741524631e-06, Test loss 0.42455468140542507, Train accuracy 100.0, Test accuracy 94.228515625, Cost 62.08377122879028 s\n",
      "Model saved in epoch 665\n",
      "Epoch 666, Train loss 7.4349475998047865e-06, Test loss 0.4248833078891039, Train accuracy 100.0, Test accuracy 94.19921875, Cost 62.16641354560852 s\n",
      "Epoch 667, Train loss 5.289859030411588e-06, Test loss 0.4253451727330685, Train accuracy 100.0, Test accuracy 94.208984375, Cost 62.14622449874878 s\n",
      "Epoch 668, Train loss 6.1504773185561135e-06, Test loss 0.4252291515469551, Train accuracy 100.0, Test accuracy 94.189453125, Cost 62.20269966125488 s\n",
      "Epoch 669, Train loss 8.522053822243184e-06, Test loss 0.42510818466544154, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.44162464141846 s\n",
      "Epoch 670, Train loss 6.364976564531255e-06, Test loss 0.4253738697618246, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.182756662368774 s\n",
      "Model saved in epoch 670\n",
      "Epoch 671, Train loss 6.567197461212187e-06, Test loss 0.4254368465393782, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.14277458190918 s\n",
      "Epoch 672, Train loss 5.664992443724036e-06, Test loss 0.42569715678691866, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.11621165275574 s\n",
      "Epoch 673, Train loss 6.746025555930039e-06, Test loss 0.4255327686667442, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.12678384780884 s\n",
      "Epoch 674, Train loss 5.73547842347988e-06, Test loss 0.42569285705685617, Train accuracy 100.0, Test accuracy 94.189453125, Cost 62.1607551574707 s\n",
      "Epoch 675, Train loss 5.923035780626276e-06, Test loss 0.42567993737757204, Train accuracy 100.0, Test accuracy 94.189453125, Cost 62.144641637802124 s\n",
      "Model saved in epoch 675\n",
      "Epoch 676, Train loss 5.361682868463235e-06, Test loss 0.42571797147393226, Train accuracy 100.0, Test accuracy 94.189453125, Cost 62.12649393081665 s\n",
      "Epoch 677, Train loss 6.582892851342621e-06, Test loss 0.42526590302586553, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.120882511138916 s\n",
      "Epoch 678, Train loss 5.733649363655647e-06, Test loss 0.42545019909739495, Train accuracy 100.0, Test accuracy 94.1796875, Cost 62.139631509780884 s\n",
      "Epoch 679, Train loss 6.070619256841694e-06, Test loss 0.4257085308432579, Train accuracy 100.0, Test accuracy 94.1796875, Cost 62.1586549282074 s\n",
      "Epoch 680, Train loss 5.979916191646987e-06, Test loss 0.4257861889898777, Train accuracy 100.0, Test accuracy 94.16015625, Cost 62.15700101852417 s\n",
      "Model saved in epoch 680\n",
      "Epoch 681, Train loss 4.5623449955462085e-06, Test loss 0.42567283399403094, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.09791374206543 s\n",
      "Epoch 682, Train loss 6.164838047470535e-06, Test loss 0.42570670396089555, Train accuracy 100.0, Test accuracy 94.169921875, Cost 62.1101291179657 s\n",
      "Epoch 683, Train loss 5.156383837934717e-06, Test loss 0.42564965412020683, Train accuracy 100.0, Test accuracy 94.16015625, Cost 62.116509199142456 s\n",
      "Epoch 684, Train loss 5.16076702308742e-06, Test loss 0.42583439238369464, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.11518883705139 s\n",
      "Epoch 685, Train loss 5.142611438913036e-06, Test loss 0.4258534055203199, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.131162881851196 s\n",
      "Model saved in epoch 685\n",
      "Epoch 686, Train loss 6.1181175124379575e-06, Test loss 0.425826333835721, Train accuracy 100.0, Test accuracy 94.16015625, Cost 62.189276933670044 s\n",
      "Epoch 687, Train loss 5.477822645877486e-06, Test loss 0.4256870403885841, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.39720034599304 s\n",
      "Epoch 688, Train loss 5.759263698290833e-06, Test loss 0.42589538879692557, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.15332078933716 s\n",
      "Epoch 689, Train loss 6.656553928797964e-06, Test loss 0.42633899860084057, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.172630310058594 s\n",
      "Epoch 690, Train loss 5.068281485092967e-06, Test loss 0.42643006443977355, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.160069942474365 s\n",
      "Model saved in epoch 690\n",
      "Epoch 691, Train loss 5.6407716824906504e-06, Test loss 0.42647047378122804, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.16090631484985 s\n",
      "Epoch 692, Train loss 5.773471919720155e-06, Test loss 0.4265501003712416, Train accuracy 100.0, Test accuracy 94.169921875, Cost 62.145968198776245 s\n",
      "Epoch 693, Train loss 5.466361252229267e-06, Test loss 0.4266198892146349, Train accuracy 100.0, Test accuracy 94.16015625, Cost 62.12319207191467 s\n",
      "Epoch 694, Train loss 5.102424328529822e-06, Test loss 0.4267265286296606, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.12595748901367 s\n",
      "Epoch 695, Train loss 7.5382975052729285e-06, Test loss 0.4262518294155598, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.14971160888672 s\n",
      "Model saved in epoch 695\n",
      "Epoch 696, Train loss 5.3913552280892895e-06, Test loss 0.42622502371668813, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.10252785682678 s\n",
      "Epoch 697, Train loss 4.548193091879131e-06, Test loss 0.42612599581480026, Train accuracy 100.0, Test accuracy 94.1015625, Cost 62.199820041656494 s\n",
      "Epoch 698, Train loss 5.5561235265048825e-06, Test loss 0.42619975060224535, Train accuracy 100.0, Test accuracy 94.12109375, Cost 62.18999981880188 s\n",
      "Epoch 699, Train loss 5.347728618535338e-06, Test loss 0.42613038048148155, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.20052242279053 s\n",
      "Epoch 700, Train loss 5.587363644081608e-06, Test loss 0.42614937350153925, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.18149280548096 s\n",
      "Model saved in epoch 700\n",
      "Epoch 701, Train loss 5.81605854836546e-06, Test loss 0.42637110911309717, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.17814564704895 s\n",
      "Epoch 702, Train loss 4.646276740438262e-06, Test loss 0.42630129419267176, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.164827823638916 s\n",
      "Epoch 703, Train loss 5.4064676184125625e-06, Test loss 0.42658146768808364, Train accuracy 100.0, Test accuracy 94.169921875, Cost 62.17625117301941 s\n",
      "Epoch 704, Train loss 5.279347605211945e-06, Test loss 0.4266111746430397, Train accuracy 100.0, Test accuracy 94.16015625, Cost 62.260608434677124 s\n",
      "Epoch 705, Train loss 4.856211367218307e-06, Test loss 0.4269602358341217, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.281092166900635 s\n",
      "Model saved in epoch 705\n",
      "Epoch 706, Train loss 6.2673892854663834e-06, Test loss 0.42691739127039907, Train accuracy 100.0, Test accuracy 94.169921875, Cost 61.1615834236145 s\n",
      "Epoch 707, Train loss 6.439335872466834e-06, Test loss 0.42712124064564705, Train accuracy 100.0, Test accuracy 94.169921875, Cost 61.99058818817139 s\n",
      "Epoch 708, Train loss 6.752656093282769e-06, Test loss 0.42729309387505054, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.122612714767456 s\n",
      "Epoch 709, Train loss 5.419837643390862e-06, Test loss 0.42739461474120616, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.13376569747925 s\n",
      "Epoch 710, Train loss 5.3363232531031995e-06, Test loss 0.42758010141551495, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.16399264335632 s\n",
      "Model saved in epoch 710\n",
      "Epoch 711, Train loss 6.14416363533815e-06, Test loss 0.4276439055800438, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.114808797836304 s\n",
      "Epoch 712, Train loss 6.1911067301191356e-06, Test loss 0.42755173072218894, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.081501483917236 s\n",
      "Epoch 713, Train loss 4.357084427421021e-06, Test loss 0.4275212798267603, Train accuracy 100.0, Test accuracy 94.12109375, Cost 62.1622531414032 s\n",
      "Epoch 714, Train loss 6.011921808017317e-06, Test loss 0.42722627744078634, Train accuracy 100.0, Test accuracy 94.16015625, Cost 62.13721513748169 s\n",
      "Epoch 715, Train loss 5.631006526188026e-06, Test loss 0.4271898340433836, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.095027923583984 s\n",
      "Model saved in epoch 715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 716, Train loss 7.059415920147265e-06, Test loss 0.42734625078737737, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.129626750946045 s\n",
      "Epoch 717, Train loss 4.992501858854509e-06, Test loss 0.4277444452047348, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.14120697975159 s\n",
      "Epoch 718, Train loss 4.6277179610361065e-06, Test loss 0.4275710079818964, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.1160204410553 s\n",
      "Epoch 719, Train loss 6.216927255845734e-06, Test loss 0.42777502052485944, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.100043296813965 s\n",
      "Epoch 720, Train loss 5.786042916118193e-06, Test loss 0.42760139517486095, Train accuracy 100.0, Test accuracy 94.12109375, Cost 62.06068825721741 s\n",
      "Model saved in epoch 720\n",
      "Epoch 721, Train loss 4.8807302951675e-06, Test loss 0.42752027586102487, Train accuracy 100.0, Test accuracy 94.111328125, Cost 61.99444532394409 s\n",
      "Epoch 722, Train loss 6.552174684611253e-06, Test loss 0.427721244096756, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.10297679901123 s\n",
      "Epoch 723, Train loss 4.110890278235966e-06, Test loss 0.4278909280896187, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.099018812179565 s\n",
      "Epoch 724, Train loss 4.604546138371377e-06, Test loss 0.4278590686619282, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.12258958816528 s\n",
      "Epoch 725, Train loss 6.292214829354565e-06, Test loss 0.4282893639057875, Train accuracy 100.0, Test accuracy 94.12109375, Cost 62.069175243377686 s\n",
      "Model saved in epoch 725\n",
      "Epoch 726, Train loss 5.424569967637618e-06, Test loss 0.4280634507536888, Train accuracy 100.0, Test accuracy 94.111328125, Cost 62.072500228881836 s\n",
      "Epoch 727, Train loss 5.045209139716323e-06, Test loss 0.4280486974865198, Train accuracy 100.0, Test accuracy 94.1015625, Cost 62.100322008132935 s\n",
      "Epoch 728, Train loss 7.392682135569741e-06, Test loss 0.42807813808321954, Train accuracy 100.0, Test accuracy 94.111328125, Cost 61.92322397232056 s\n",
      "Epoch 729, Train loss 4.44448676983673e-06, Test loss 0.4285080708563328, Train accuracy 100.0, Test accuracy 94.08203125, Cost 61.94091486930847 s\n",
      "Epoch 730, Train loss 5.851383069977128e-06, Test loss 0.4285928186029196, Train accuracy 100.0, Test accuracy 94.12109375, Cost 61.86552929878235 s\n",
      "Model saved in epoch 730\n",
      "Epoch 731, Train loss 4.54196362566642e-06, Test loss 0.42875780165195465, Train accuracy 100.0, Test accuracy 94.1015625, Cost 61.981345653533936 s\n",
      "Epoch 732, Train loss 4.5297654540145136e-06, Test loss 0.4287650302052498, Train accuracy 100.0, Test accuracy 94.091796875, Cost 61.90777277946472 s\n",
      "Epoch 733, Train loss 6.322793372045713e-06, Test loss 0.4285578906536102, Train accuracy 100.0, Test accuracy 94.130859375, Cost 61.93285918235779 s\n",
      "Epoch 734, Train loss 5.050688752633932e-06, Test loss 0.428685050830245, Train accuracy 100.0, Test accuracy 94.130859375, Cost 61.91005182266235 s\n",
      "Epoch 735, Train loss 6.311841098653651e-06, Test loss 0.42869148440659044, Train accuracy 100.0, Test accuracy 94.12109375, Cost 61.94055891036987 s\n",
      "Model saved in epoch 735\n",
      "Epoch 736, Train loss 7.046286434621268e-06, Test loss 0.42840314768254756, Train accuracy 100.0, Test accuracy 94.1015625, Cost 61.899263858795166 s\n",
      "Epoch 737, Train loss 4.9192222824521364e-06, Test loss 0.42807807847857476, Train accuracy 100.0, Test accuracy 94.111328125, Cost 61.965065002441406 s\n",
      "Epoch 738, Train loss 7.256516783922614e-06, Test loss 0.42814752496778963, Train accuracy 100.0, Test accuracy 94.111328125, Cost 62.2134644985199 s\n",
      "Epoch 739, Train loss 5.356192513662053e-06, Test loss 0.428342192620039, Train accuracy 100.0, Test accuracy 94.12109375, Cost 62.1257119178772 s\n",
      "Epoch 740, Train loss 5.324162792854455e-06, Test loss 0.4284279480576515, Train accuracy 100.0, Test accuracy 94.1015625, Cost 62.12479758262634 s\n",
      "Model saved in epoch 740\n",
      "Epoch 741, Train loss 5.115317007490533e-06, Test loss 0.4286780171096325, Train accuracy 100.0, Test accuracy 94.111328125, Cost 62.11484408378601 s\n",
      "Epoch 742, Train loss 4.841118506053369e-06, Test loss 0.4287586249411106, Train accuracy 100.0, Test accuracy 94.111328125, Cost 62.16285061836243 s\n",
      "Epoch 743, Train loss 4.835912340831087e-06, Test loss 0.4287645287811756, Train accuracy 100.0, Test accuracy 94.12109375, Cost 62.091726779937744 s\n",
      "Epoch 744, Train loss 5.826403676910652e-06, Test loss 0.42906503193080425, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.09813928604126 s\n",
      "Epoch 745, Train loss 5.169823182809778e-06, Test loss 0.4291912231594324, Train accuracy 100.0, Test accuracy 94.12109375, Cost 62.10522985458374 s\n",
      "Model saved in epoch 745\n",
      "Epoch 746, Train loss 8.603797660100554e-06, Test loss 0.42954162508249283, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.10931396484375 s\n",
      "Epoch 747, Train loss 6.345343720464227e-06, Test loss 0.42978188805282114, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.140300989151 s\n",
      "Epoch 748, Train loss 4.50534634774912e-06, Test loss 0.4298876851797104, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.19463062286377 s\n",
      "Epoch 749, Train loss 5.124397230177664e-06, Test loss 0.42972290366888044, Train accuracy 100.0, Test accuracy 94.111328125, Cost 62.103177309036255 s\n",
      "Epoch 750, Train loss 1.1848153507441697e-05, Test loss 0.4288463704288006, Train accuracy 100.0, Test accuracy 94.1015625, Cost 62.19652700424194 s\n",
      "Model saved in epoch 750\n",
      "Epoch 751, Train loss 6.798494115821425e-06, Test loss 0.4286848187446594, Train accuracy 100.0, Test accuracy 94.1015625, Cost 62.171069383621216 s\n",
      "Epoch 752, Train loss 4.5080616918891315e-06, Test loss 0.4287936396896839, Train accuracy 100.0, Test accuracy 94.111328125, Cost 62.145334243774414 s\n",
      "Epoch 753, Train loss 5.7470787433501e-06, Test loss 0.42881970591843127, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.19860315322876 s\n",
      "Epoch 754, Train loss 7.131702245825339e-06, Test loss 0.42855507507920265, Train accuracy 100.0, Test accuracy 94.1015625, Cost 62.16849231719971 s\n",
      "Epoch 755, Train loss 4.8612280115155595e-06, Test loss 0.42869002632796765, Train accuracy 100.0, Test accuracy 94.12109375, Cost 62.170475244522095 s\n",
      "Model saved in epoch 755\n",
      "Epoch 756, Train loss 5.406585627670257e-06, Test loss 0.4287834756076336, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.162853479385376 s\n",
      "Epoch 757, Train loss 5.484323982126885e-06, Test loss 0.42909015007317064, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.180448055267334 s\n",
      "Epoch 758, Train loss 8.28812467970109e-06, Test loss 0.42979017458856106, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.14934539794922 s\n",
      "Epoch 759, Train loss 5.272581299963423e-06, Test loss 0.42985149994492533, Train accuracy 100.0, Test accuracy 94.12109375, Cost 62.1554799079895 s\n",
      "Epoch 760, Train loss 6.079355006090389e-06, Test loss 0.429634627699852, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.132598876953125 s\n",
      "Model saved in epoch 760\n",
      "Epoch 761, Train loss 5.26499861714618e-06, Test loss 0.4296901997178793, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.09300661087036 s\n",
      "Epoch 762, Train loss 5.891807515337409e-06, Test loss 0.42983904518187044, Train accuracy 100.0, Test accuracy 94.16015625, Cost 62.22555732727051 s\n",
      "Epoch 763, Train loss 5.804904434723669e-06, Test loss 0.42987235076725483, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.19084644317627 s\n",
      "Epoch 764, Train loss 5.08491672489088e-06, Test loss 0.4300117451697588, Train accuracy 100.0, Test accuracy 94.1796875, Cost 62.1200897693634 s\n",
      "Epoch 765, Train loss 6.0320572765298105e-06, Test loss 0.4303779054433107, Train accuracy 100.0, Test accuracy 94.12109375, Cost 62.14113521575928 s\n",
      "Model saved in epoch 765\n",
      "Epoch 766, Train loss 4.895002103718785e-06, Test loss 0.4304817967116833, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.12014842033386 s\n",
      "Epoch 767, Train loss 5.3351162733353675e-06, Test loss 0.4304222479462624, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.14323616027832 s\n",
      "Epoch 768, Train loss 8.246853579168534e-06, Test loss 0.43020066134631635, Train accuracy 100.0, Test accuracy 94.189453125, Cost 62.12379479408264 s\n",
      "Epoch 769, Train loss 5.7515803858011945e-06, Test loss 0.4303833585232496, Train accuracy 100.0, Test accuracy 94.189453125, Cost 62.143149852752686 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 770, Train loss 5.117448334224681e-06, Test loss 0.43038015365600585, Train accuracy 100.0, Test accuracy 94.169921875, Cost 62.128106355667114 s\n",
      "Model saved in epoch 770\n",
      "Epoch 771, Train loss 4.831691695954407e-06, Test loss 0.43044403195381165, Train accuracy 100.0, Test accuracy 94.169921875, Cost 62.12489366531372 s\n",
      "Epoch 772, Train loss 4.7586448656556036e-06, Test loss 0.43055941350758076, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.09219193458557 s\n",
      "Epoch 773, Train loss 6.134575488426797e-06, Test loss 0.43072775304317473, Train accuracy 100.0, Test accuracy 94.130859375, Cost 62.08165168762207 s\n",
      "Epoch 774, Train loss 5.6516472987621514e-06, Test loss 0.43062424920499326, Train accuracy 100.0, Test accuracy 94.169921875, Cost 62.116551637649536 s\n",
      "Epoch 775, Train loss 5.184074587401363e-06, Test loss 0.43064548783004286, Train accuracy 100.0, Test accuracy 94.1796875, Cost 62.15134310722351 s\n",
      "Model saved in epoch 775\n",
      "Epoch 776, Train loss 4.906188038944492e-06, Test loss 0.4307854775339365, Train accuracy 100.0, Test accuracy 94.16015625, Cost 62.15049171447754 s\n",
      "Epoch 777, Train loss 6.077055644047217e-06, Test loss 0.4311564851552248, Train accuracy 100.0, Test accuracy 94.1796875, Cost 62.165125608444214 s\n",
      "Epoch 778, Train loss 5.126788607505117e-06, Test loss 0.43131671473383904, Train accuracy 100.0, Test accuracy 94.208984375, Cost 62.151556730270386 s\n",
      "Epoch 779, Train loss 4.683330414453958e-06, Test loss 0.4313793584704399, Train accuracy 100.0, Test accuracy 94.208984375, Cost 62.166605949401855 s\n",
      "Epoch 780, Train loss 6.847422035967699e-06, Test loss 0.4312304131686687, Train accuracy 100.0, Test accuracy 94.189453125, Cost 62.15100073814392 s\n",
      "Model saved in epoch 780\n",
      "Epoch 781, Train loss 6.737522367753785e-06, Test loss 0.4317655019462109, Train accuracy 100.0, Test accuracy 94.1796875, Cost 62.18003034591675 s\n",
      "Epoch 782, Train loss 4.08570742350474e-06, Test loss 0.4319608647376299, Train accuracy 100.0, Test accuracy 94.19921875, Cost 62.10222244262695 s\n",
      "Epoch 783, Train loss 5.9305786385382406e-06, Test loss 0.4322955459356308, Train accuracy 100.0, Test accuracy 94.1796875, Cost 62.09560203552246 s\n",
      "Epoch 784, Train loss 5.752979856200171e-06, Test loss 0.43245025128126147, Train accuracy 100.0, Test accuracy 94.189453125, Cost 62.10220193862915 s\n",
      "Epoch 785, Train loss 9.436354264220988e-06, Test loss 0.43235913999378683, Train accuracy 100.0, Test accuracy 94.189453125, Cost 62.103657960891724 s\n",
      "Model saved in epoch 785\n",
      "Epoch 786, Train loss 4.897205388710879e-06, Test loss 0.4323511175811291, Train accuracy 100.0, Test accuracy 94.150390625, Cost 62.14279294013977 s\n",
      "Epoch 787, Train loss 5.212651842684608e-06, Test loss 0.43238169364631174, Train accuracy 100.0, Test accuracy 94.1796875, Cost 62.18437361717224 s\n",
      "Epoch 788, Train loss 4.514720332802157e-06, Test loss 0.4325864288955927, Train accuracy 100.0, Test accuracy 94.1796875, Cost 62.14357852935791 s\n",
      "Epoch 789, Train loss 7.65516419429745e-06, Test loss 0.4328357603400946, Train accuracy 100.0, Test accuracy 94.140625, Cost 62.13273882865906 s\n",
      "Epoch 790, Train loss 6.560477918593715e-06, Test loss 0.43148122653365134, Train accuracy 100.0, Test accuracy 94.1796875, Cost 62.15117263793945 s\n",
      "Model saved in epoch 790\n",
      "Epoch 791, Train loss 8.06957489078634e-06, Test loss 0.4316559135913849, Train accuracy 100.0, Test accuracy 94.169921875, Cost 62.1081817150116 s\n",
      "Epoch 792, Train loss 4.891135383804005e-06, Test loss 0.43163888789713384, Train accuracy 100.0, Test accuracy 94.189453125, Cost 62.13071346282959 s\n",
      "Epoch 793, Train loss 4.637779951931917e-06, Test loss 0.431523110717535, Train accuracy 100.0, Test accuracy 94.19921875, Cost 62.162718772888184 s\n",
      "Epoch 794, Train loss 7.6285374877979195e-06, Test loss 0.43199931383132933, Train accuracy 100.0, Test accuracy 94.189453125, Cost 62.101357221603394 s\n",
      "Epoch 795, Train loss 5.5190717157425025e-06, Test loss 0.4320472851395607, Train accuracy 100.0, Test accuracy 94.16015625, Cost 62.12533736228943 s\n",
      "Model saved in epoch 795\n",
      "Epoch 796, Train loss 6.9907111462499664e-06, Test loss 0.4323834922164679, Train accuracy 100.0, Test accuracy 94.19921875, Cost 62.09567928314209 s\n",
      "Epoch 797, Train loss 5.509055860966559e-06, Test loss 0.43260755091905595, Train accuracy 100.0, Test accuracy 94.189453125, Cost 62.107813358306885 s\n",
      "Epoch 798, Train loss 5.512223006170254e-06, Test loss 0.4333791483193636, Train accuracy 100.0, Test accuracy 94.189453125, Cost 61.93990182876587 s\n",
      "Epoch 799, Train loss 4.2177865697823336e-06, Test loss 0.4335604552179575, Train accuracy 100.0, Test accuracy 94.1796875, Cost 61.91468620300293 s\n",
      "Epoch 800, Train loss 6.613962341434416e-06, Test loss 0.43394389040768144, Train accuracy 100.0, Test accuracy 94.189453125, Cost 61.92814373970032 s\n",
      "Model saved in epoch 800\n",
      "Epoch 801, Train loss 6.294603409753795e-06, Test loss 0.43396854028105736, Train accuracy 100.0, Test accuracy 94.140625, Cost 61.920156717300415 s\n",
      "Epoch 802, Train loss 8.498527892268088e-06, Test loss 0.4338487170636654, Train accuracy 100.0, Test accuracy 94.12109375, Cost 61.89746165275574 s\n",
      "Epoch 803, Train loss 6.170386464706395e-06, Test loss 0.4339059334248304, Train accuracy 100.0, Test accuracy 94.16015625, Cost 61.911383628845215 s\n",
      "Epoch 804, Train loss 6.518721537166325e-06, Test loss 0.43364875465631486, Train accuracy 100.0, Test accuracy 94.08203125, Cost 61.9304256439209 s\n",
      "Epoch 805, Train loss 5.8050623391433675e-06, Test loss 0.4336218725889921, Train accuracy 100.0, Test accuracy 94.12109375, Cost 61.91329097747803 s\n",
      "Model saved in epoch 805\n",
      "Epoch 806, Train loss 1.1903572701247153e-05, Test loss 0.43295666836202146, Train accuracy 100.0, Test accuracy 94.111328125, Cost 61.91781497001648 s\n",
      "Epoch 807, Train loss 6.998302063242456e-06, Test loss 0.4328453872352839, Train accuracy 100.0, Test accuracy 94.140625, Cost 61.93648862838745 s\n",
      "Epoch 808, Train loss 6.687672045969447e-06, Test loss 0.43286832608282566, Train accuracy 100.0, Test accuracy 94.111328125, Cost 61.93484425544739 s\n",
      "Epoch 809, Train loss 1.0174641706395486e-05, Test loss 0.4331654839217663, Train accuracy 100.0, Test accuracy 94.111328125, Cost 61.94132447242737 s\n",
      "Epoch 810, Train loss 7.6090836453969895e-06, Test loss 0.43284211307764053, Train accuracy 100.0, Test accuracy 94.150390625, Cost 61.97221302986145 s\n",
      "Model saved in epoch 810\n",
      "Epoch 811, Train loss 6.099849864544724e-06, Test loss 0.4325039029121399, Train accuracy 100.0, Test accuracy 94.1796875, Cost 61.9163601398468 s\n",
      "Epoch 812, Train loss 3.7646896811570605e-06, Test loss 0.4327646136283875, Train accuracy 100.0, Test accuracy 94.169921875, Cost 61.93722987174988 s\n",
      "Epoch 813, Train loss 5.487634337944015e-06, Test loss 0.43258231356739996, Train accuracy 100.0, Test accuracy 94.21875, Cost 62.09692120552063 s\n",
      "Epoch 814, Train loss 6.265201713329343e-06, Test loss 0.43247616216540335, Train accuracy 100.0, Test accuracy 94.208984375, Cost 62.09671425819397 s\n",
      "Epoch 815, Train loss 4.71490738210686e-06, Test loss 0.4322686653584242, Train accuracy 100.0, Test accuracy 94.208984375, Cost 62.11936020851135 s\n",
      "Model saved in epoch 815\n",
      "Epoch 816, Train loss 1.839131809449601e-05, Test loss 0.4340492028743029, Train accuracy 100.0, Test accuracy 94.1015625, Cost 62.05078077316284 s\n",
      "Epoch 817, Train loss 1.760910905511421e-05, Test loss 0.4344263181090355, Train accuracy 100.0, Test accuracy 94.111328125, Cost 61.936991930007935 s\n",
      "Epoch 818, Train loss 7.0139102230864035e-06, Test loss 0.4341244000941515, Train accuracy 100.0, Test accuracy 94.140625, Cost 61.74094748497009 s\n",
      "Epoch 819, Train loss 1.0030531583920748e-05, Test loss 0.43486844152212145, Train accuracy 100.0, Test accuracy 94.1015625, Cost 61.18663263320923 s\n",
      "Epoch 820, Train loss 8.392760172316174e-06, Test loss 0.43460194729268553, Train accuracy 100.0, Test accuracy 94.091796875, Cost 61.09924364089966 s\n",
      "Model saved in epoch 820\n",
      "Epoch 821, Train loss 7.02320171862309e-06, Test loss 0.43459019996225834, Train accuracy 100.0, Test accuracy 94.091796875, Cost 61.06618928909302 s\n",
      "Epoch 822, Train loss 7.4320890462476596e-06, Test loss 0.43400552235543727, Train accuracy 100.0, Test accuracy 94.1015625, Cost 61.070810317993164 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 823, Train loss 5.539190270220198e-06, Test loss 0.43376918509602547, Train accuracy 100.0, Test accuracy 94.111328125, Cost 61.02980041503906 s\n",
      "Epoch 824, Train loss 7.2893627486733954e-06, Test loss 0.4338500939309597, Train accuracy 100.0, Test accuracy 94.12109375, Cost 61.13538932800293 s\n",
      "Epoch 825, Train loss 4.433441817419217e-06, Test loss 0.43407711386680603, Train accuracy 100.0, Test accuracy 94.111328125, Cost 61.07203197479248 s\n",
      "Model saved in epoch 825\n",
      "Epoch 826, Train loss 1.0090079045884364e-05, Test loss 0.4337244968861341, Train accuracy 100.0, Test accuracy 94.150390625, Cost 61.1551308631897 s\n",
      "Epoch 827, Train loss 1.073028425870009e-05, Test loss 0.4364074531942606, Train accuracy 100.0, Test accuracy 94.140625, Cost 61.65141272544861 s\n",
      "Epoch 828, Train loss 4.533337807239539e-06, Test loss 0.43622674122452737, Train accuracy 100.0, Test accuracy 94.140625, Cost 61.59669852256775 s\n",
      "Epoch 829, Train loss 8.96575690678465e-06, Test loss 0.4359605647623539, Train accuracy 100.0, Test accuracy 94.140625, Cost 61.57266545295715 s\n",
      "Epoch 830, Train loss 1.4741726046640698e-05, Test loss 0.4374522905796766, Train accuracy 100.0, Test accuracy 94.130859375, Cost 61.54820275306702 s\n",
      "Model saved in epoch 830\n",
      "Epoch 831, Train loss 8.298158500658864e-06, Test loss 0.4370993562042713, Train accuracy 100.0, Test accuracy 94.150390625, Cost 61.56889009475708 s\n",
      "Epoch 832, Train loss 1.3203307549865573e-05, Test loss 0.4354774449020624, Train accuracy 100.0, Test accuracy 94.091796875, Cost 61.59673881530762 s\n",
      "Epoch 833, Train loss 1.1652174485442286e-05, Test loss 0.43671731315553186, Train accuracy 100.0, Test accuracy 94.111328125, Cost 61.59231472015381 s\n",
      "Epoch 834, Train loss 1.054759714678574e-05, Test loss 0.43791360333561896, Train accuracy 100.0, Test accuracy 94.08203125, Cost 61.55536341667175 s\n",
      "Epoch 835, Train loss 8.038323930762493e-06, Test loss 0.43781966269016265, Train accuracy 100.0, Test accuracy 94.091796875, Cost 61.52248787879944 s\n",
      "Model saved in epoch 835\n",
      "Epoch 836, Train loss 8.217451303724256e-06, Test loss 0.4379749234765768, Train accuracy 100.0, Test accuracy 94.091796875, Cost 61.7348268032074 s\n",
      "Epoch 837, Train loss 1.0193604601830796e-05, Test loss 0.4375116638839245, Train accuracy 100.0, Test accuracy 94.091796875, Cost 61.716758489608765 s\n",
      "Epoch 838, Train loss 6.994784735099427e-06, Test loss 0.4374238524585962, Train accuracy 100.0, Test accuracy 94.072265625, Cost 61.721152782440186 s\n",
      "Epoch 839, Train loss 1.2437365858442244e-05, Test loss 0.43768481314182284, Train accuracy 100.0, Test accuracy 94.0625, Cost 61.65028691291809 s\n",
      "Epoch 840, Train loss 1.086700080285382e-05, Test loss 0.4374722123146057, Train accuracy 100.0, Test accuracy 94.12109375, Cost 61.710150957107544 s\n",
      "Model saved in epoch 840\n",
      "Epoch 841, Train loss 9.295793449315189e-06, Test loss 0.4371659204363823, Train accuracy 100.0, Test accuracy 94.072265625, Cost 61.773154735565186 s\n",
      "Epoch 842, Train loss 5.594708557298924e-06, Test loss 0.43706163577735424, Train accuracy 100.0, Test accuracy 94.052734375, Cost 61.7491672039032 s\n",
      "Epoch 843, Train loss 5.862328320089272e-06, Test loss 0.43710405193269253, Train accuracy 100.0, Test accuracy 94.072265625, Cost 61.7247257232666 s\n",
      "Epoch 844, Train loss 7.371258273484013e-06, Test loss 0.4366271674633026, Train accuracy 100.0, Test accuracy 94.08203125, Cost 61.730764389038086 s\n",
      "Epoch 845, Train loss 5.920981530450416e-06, Test loss 0.43628660403192043, Train accuracy 100.0, Test accuracy 94.091796875, Cost 61.74825072288513 s\n",
      "Model saved in epoch 845\n",
      "Epoch 846, Train loss 8.918979067567997e-06, Test loss 0.43672190196812155, Train accuracy 100.0, Test accuracy 94.08203125, Cost 61.7170786857605 s\n",
      "Epoch 847, Train loss 7.606668055818286e-06, Test loss 0.43731155171990393, Train accuracy 100.0, Test accuracy 94.072265625, Cost 61.80697846412659 s\n",
      "Epoch 848, Train loss 6.047267848444739e-05, Test loss 0.4451697010546923, Train accuracy 99.99800701530613, Test accuracy 93.9453125, Cost 61.78015446662903 s\n",
      "Epoch 849, Train loss 0.0001356442538256175, Test loss 0.4449640054255724, Train accuracy 99.99601403061224, Test accuracy 93.935546875, Cost 61.75680112838745 s\n",
      "Epoch 850, Train loss 0.0023747422131240297, Test loss 0.5141726493835449, Train accuracy 99.93423150510205, Test accuracy 92.734375, Cost 61.77101016044617 s\n",
      "Model saved in epoch 850\n",
      "Epoch 851, Train loss 0.00571103774383137, Test loss 0.5797403287142515, Train accuracy 99.82063137755102, Test accuracy 92.1875, Cost 61.7499680519104 s\n",
      "Epoch 852, Train loss 0.018028132795883053, Test loss 0.5901436559855938, Train accuracy 99.46189413265306, Test accuracy 91.396484375, Cost 61.77970767021179 s\n",
      "Epoch 853, Train loss 0.03176129877398608, Test loss 0.5025492895394563, Train accuracy 99.04496173469387, Test accuracy 91.806640625, Cost 61.83891725540161 s\n",
      "Epoch 854, Train loss 0.022742931134416722, Test loss 0.4471300505101681, Train accuracy 99.29249043367346, Test accuracy 92.412109375, Cost 61.79429817199707 s\n",
      "Epoch 855, Train loss 0.012247495236658083, Test loss 0.4422323234379292, Train accuracy 99.5850605867347, Test accuracy 92.509765625, Cost 61.85308790206909 s\n",
      "Model saved in epoch 855\n",
      "Epoch 856, Train loss 0.01181252743162058, Test loss 0.4553137142211199, Train accuracy 99.61535395408163, Test accuracy 92.5, Cost 61.77818202972412 s\n",
      "Epoch 857, Train loss 0.008321290837408683, Test loss 0.4147057544440031, Train accuracy 99.74689094387755, Test accuracy 92.685546875, Cost 61.722079038619995 s\n",
      "Epoch 858, Train loss 0.008263019807915897, Test loss 0.4492561064660549, Train accuracy 99.73493303571429, Test accuracy 92.529296875, Cost 61.76080560684204 s\n",
      "Epoch 859, Train loss 0.008720551649962638, Test loss 0.44062814190983773, Train accuracy 99.69268176020408, Test accuracy 92.958984375, Cost 61.736836671829224 s\n",
      "Epoch 860, Train loss 0.005962140886312022, Test loss 0.4360955201089382, Train accuracy 99.78874362244898, Test accuracy 92.9296875, Cost 61.747583866119385 s\n",
      "Model saved in epoch 860\n",
      "Epoch 861, Train loss 0.005071696495383085, Test loss 0.4605321459472179, Train accuracy 99.84016262755102, Test accuracy 92.451171875, Cost 61.75396728515625 s\n",
      "Epoch 862, Train loss 0.007927971669251209, Test loss 0.42123143225908277, Train accuracy 99.75884885204081, Test accuracy 92.734375, Cost 61.72778511047363 s\n",
      "Epoch 863, Train loss 0.00758401202219087, Test loss 0.42423833347857, Train accuracy 99.77479272959184, Test accuracy 92.802734375, Cost 61.74527096748352 s\n",
      "Epoch 864, Train loss 0.006159384928632418, Test loss 0.4561334513127804, Train accuracy 99.81226084183673, Test accuracy 92.841796875, Cost 61.73683404922485 s\n",
      "Epoch 865, Train loss 0.005537970690075243, Test loss 0.42382700704038145, Train accuracy 99.81664540816327, Test accuracy 92.783203125, Cost 61.7940411567688 s\n",
      "Model saved in epoch 865\n",
      "Epoch 866, Train loss 0.004624000363130145, Test loss 0.42839883975684645, Train accuracy 99.83458227040816, Test accuracy 92.8515625, Cost 61.74178957939148 s\n",
      "Epoch 867, Train loss 0.00574421285848669, Test loss 0.42026204951107504, Train accuracy 99.81664540816327, Test accuracy 93.056640625, Cost 61.79302763938904 s\n",
      "Epoch 868, Train loss 0.004506768480756104, Test loss 0.4108564041554928, Train accuracy 99.84016262755102, Test accuracy 93.0078125, Cost 61.6992461681366 s\n",
      "Epoch 869, Train loss 0.0047314641957497345, Test loss 0.41130694672465323, Train accuracy 99.81026785714286, Test accuracy 92.900390625, Cost 61.755186319351196 s\n",
      "Epoch 870, Train loss 0.003914489473739808, Test loss 0.42192528024315834, Train accuracy 99.8780293367347, Test accuracy 92.91015625, Cost 61.74590444564819 s\n",
      "Model saved in epoch 870\n",
      "Epoch 871, Train loss 0.005184538426039246, Test loss 0.43757540062069894, Train accuracy 99.8305963010204, Test accuracy 92.861328125, Cost 61.773261070251465 s\n",
      "Epoch 872, Train loss 0.003038603107727665, Test loss 0.4506686612963676, Train accuracy 99.90832270408163, Test accuracy 92.529296875, Cost 61.77749752998352 s\n",
      "Epoch 873, Train loss 0.0026873919875600094, Test loss 0.4454855524003506, Train accuracy 99.91230867346938, Test accuracy 92.96875, Cost 61.80400061607361 s\n",
      "Epoch 874, Train loss 0.003229238208943422, Test loss 0.4486719273030758, Train accuracy 99.90035076530613, Test accuracy 93.056640625, Cost 61.77145862579346 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 875, Train loss 0.0034791707736187573, Test loss 0.4457151424139738, Train accuracy 99.8959661989796, Test accuracy 92.6953125, Cost 61.74311971664429 s\n",
      "Model saved in epoch 875\n",
      "Epoch 876, Train loss 0.003926369035794704, Test loss 0.4126616630703211, Train accuracy 99.87603635204081, Test accuracy 93.037109375, Cost 61.81883239746094 s\n",
      "Epoch 877, Train loss 0.003290567203795054, Test loss 0.4215470362454653, Train accuracy 99.89198022959184, Test accuracy 93.14453125, Cost 61.78453850746155 s\n",
      "Epoch 878, Train loss 0.0026986482625572386, Test loss 0.42355023212730886, Train accuracy 99.90632971938776, Test accuracy 93.28125, Cost 61.789676904678345 s\n",
      "Epoch 879, Train loss 0.001680433276036712, Test loss 0.431026803702116, Train accuracy 99.95216836734694, Test accuracy 93.203125, Cost 61.76526236534119 s\n",
      "Epoch 880, Train loss 0.002919888609577189, Test loss 0.4477574624121189, Train accuracy 99.90433673469387, Test accuracy 93.056640625, Cost 61.74298810958862 s\n",
      "Model saved in epoch 880\n",
      "Epoch 881, Train loss 0.0020913579996607837, Test loss 0.4261691328138113, Train accuracy 99.92386798469387, Test accuracy 92.978515625, Cost 61.75048565864563 s\n",
      "Epoch 882, Train loss 0.0017421742982615073, Test loss 0.42369367368519306, Train accuracy 99.95416135204081, Test accuracy 93.26171875, Cost 61.70533013343811 s\n",
      "Epoch 883, Train loss 0.0031436409556831954, Test loss 0.44205164574086664, Train accuracy 99.90832270408163, Test accuracy 92.83203125, Cost 61.7621910572052 s\n",
      "Epoch 884, Train loss 0.0022177084591726735, Test loss 0.43300964422523974, Train accuracy 99.92625956632654, Test accuracy 93.22265625, Cost 61.761884450912476 s\n",
      "Epoch 885, Train loss 0.0022060016596548607, Test loss 0.4453841485083103, Train accuracy 99.93423150510205, Test accuracy 93.06640625, Cost 61.748135805130005 s\n",
      "Model saved in epoch 885\n",
      "Epoch 886, Train loss 0.0020769090898117, Test loss 0.42363283075392244, Train accuracy 99.9282525510204, Test accuracy 93.349609375, Cost 61.75166320800781 s\n",
      "Epoch 887, Train loss 0.00132526912825504, Test loss 0.4202693458646536, Train accuracy 99.96213329081633, Test accuracy 93.330078125, Cost 61.750813245773315 s\n",
      "Epoch 888, Train loss 0.0011134492714314102, Test loss 0.41097907312214377, Train accuracy 99.97209821428571, Test accuracy 93.388671875, Cost 61.6989848613739 s\n",
      "Epoch 889, Train loss 0.0009396703829071733, Test loss 0.4085842866450548, Train accuracy 99.98007015306122, Test accuracy 93.41796875, Cost 61.751725912094116 s\n",
      "Epoch 890, Train loss 0.0012895708559510092, Test loss 0.4407485846430063, Train accuracy 99.96213329081633, Test accuracy 93.271484375, Cost 61.738972663879395 s\n",
      "Model saved in epoch 890\n",
      "Epoch 891, Train loss 0.001171158723263015, Test loss 0.4143745400011539, Train accuracy 99.95814732142857, Test accuracy 93.466796875, Cost 61.74473261833191 s\n",
      "Epoch 892, Train loss 0.002163934443271909, Test loss 0.444173564016819, Train accuracy 99.90991709183673, Test accuracy 93.18359375, Cost 61.73422336578369 s\n",
      "Epoch 893, Train loss 0.004974776627375609, Test loss 0.45344165451824664, Train accuracy 99.83856823979592, Test accuracy 92.734375, Cost 61.744290351867676 s\n",
      "Epoch 894, Train loss 0.0037272341718822383, Test loss 0.4591220609843731, Train accuracy 99.87244897959184, Test accuracy 93.037109375, Cost 61.75613260269165 s\n",
      "Epoch 895, Train loss 0.004161818248873288, Test loss 0.47229439243674276, Train accuracy 99.84654017857143, Test accuracy 92.94921875, Cost 61.804375886917114 s\n",
      "Model saved in epoch 895\n",
      "Epoch 896, Train loss 0.0029003742512421532, Test loss 0.4311902061104774, Train accuracy 99.90832270408163, Test accuracy 93.046875, Cost 61.76327109336853 s\n",
      "Epoch 897, Train loss 0.0016584094972187109, Test loss 0.4444569520652294, Train accuracy 99.95216836734694, Test accuracy 93.06640625, Cost 61.764466762542725 s\n",
      "Epoch 898, Train loss 0.001387303186155415, Test loss 0.4346841614693403, Train accuracy 99.96811224489795, Test accuracy 93.408203125, Cost 61.81793451309204 s\n",
      "Epoch 899, Train loss 0.0013579452632498312, Test loss 0.4254047155380249, Train accuracy 99.97010522959184, Test accuracy 93.369140625, Cost 61.73439931869507 s\n",
      "Epoch 900, Train loss 0.0007295005325570911, Test loss 0.42160833440721035, Train accuracy 99.98007015306122, Test accuracy 93.45703125, Cost 61.753456115722656 s\n",
      "Model saved in epoch 900\n",
      "Epoch 901, Train loss 0.0014601148047395142, Test loss 0.4383835669606924, Train accuracy 99.9461894132653, Test accuracy 93.359375, Cost 61.70083498954773 s\n",
      "Epoch 902, Train loss 0.0020991727762650824, Test loss 0.43629602938890455, Train accuracy 99.93223852040816, Test accuracy 92.96875, Cost 61.726155042648315 s\n",
      "Epoch 903, Train loss 0.0018997665711882588, Test loss 0.43856202736496924, Train accuracy 99.93423150510205, Test accuracy 93.408203125, Cost 61.77585530281067 s\n",
      "Epoch 904, Train loss 0.0019728657970128033, Test loss 0.44523619338870046, Train accuracy 99.92625956632654, Test accuracy 93.154296875, Cost 61.75869154930115 s\n",
      "Epoch 905, Train loss 0.0018129570435863867, Test loss 0.424833819642663, Train accuracy 99.95176977040816, Test accuracy 93.369140625, Cost 61.75590205192566 s\n",
      "Model saved in epoch 905\n",
      "Epoch 906, Train loss 0.0015426773774778462, Test loss 0.4328349731862545, Train accuracy 99.94818239795919, Test accuracy 93.30078125, Cost 61.75411629676819 s\n",
      "Epoch 907, Train loss 0.0022167756743950735, Test loss 0.451046160236001, Train accuracy 99.91629464285714, Test accuracy 93.0078125, Cost 61.751808643341064 s\n",
      "Epoch 908, Train loss 0.0010726792714157623, Test loss 0.4342957783490419, Train accuracy 99.97010522959184, Test accuracy 93.447265625, Cost 61.79405069351196 s\n",
      "Epoch 909, Train loss 0.001391822305668122, Test loss 0.4425043761730194, Train accuracy 99.9461894132653, Test accuracy 93.45703125, Cost 61.789703607559204 s\n",
      "Epoch 910, Train loss 0.000816892050728043, Test loss 0.43822428658604623, Train accuracy 99.97807716836735, Test accuracy 93.466796875, Cost 61.754884243011475 s\n",
      "Model saved in epoch 910\n",
      "Epoch 911, Train loss 0.0005807501728928141, Test loss 0.45430794470012187, Train accuracy 99.98804209183673, Test accuracy 93.408203125, Cost 61.812339067459106 s\n",
      "Epoch 912, Train loss 0.000565957023224785, Test loss 0.44876628927886486, Train accuracy 99.9820631377551, Test accuracy 93.3984375, Cost 61.746280670166016 s\n",
      "Epoch 913, Train loss 0.0005999018397126432, Test loss 0.4430737543851137, Train accuracy 99.98604910714286, Test accuracy 93.61328125, Cost 61.78510022163391 s\n",
      "Epoch 914, Train loss 0.0005600537419111008, Test loss 0.445701165497303, Train accuracy 99.98604910714286, Test accuracy 93.564453125, Cost 61.849684953689575 s\n",
      "Epoch 915, Train loss 0.0005766790198957987, Test loss 0.4399579741060734, Train accuracy 99.98565051020408, Test accuracy 93.525390625, Cost 61.80055522918701 s\n",
      "Model saved in epoch 915\n",
      "Epoch 916, Train loss 0.0015769914042331429, Test loss 0.48180528432130815, Train accuracy 99.95416135204081, Test accuracy 93.046875, Cost 61.78193259239197 s\n",
      "Epoch 917, Train loss 0.0014351009694184207, Test loss 0.4650769308209419, Train accuracy 99.95416135204081, Test accuracy 93.056640625, Cost 61.798778772354126 s\n",
      "Epoch 918, Train loss 0.0009835301389706061, Test loss 0.46807636097073557, Train accuracy 99.97209821428571, Test accuracy 93.154296875, Cost 61.763468742370605 s\n",
      "Epoch 919, Train loss 0.0005381772222038734, Test loss 0.4366121251136065, Train accuracy 99.99202806122449, Test accuracy 93.4375, Cost 62.01815056800842 s\n",
      "Epoch 920, Train loss 0.001254060717813872, Test loss 0.4549758270382881, Train accuracy 99.95416135204081, Test accuracy 93.125, Cost 61.72038149833679 s\n",
      "Model saved in epoch 920\n",
      "Epoch 921, Train loss 0.0022524004032707773, Test loss 0.4654463242739439, Train accuracy 99.92586096938776, Test accuracy 92.998046875, Cost 61.69831037521362 s\n",
      "Epoch 922, Train loss 0.005102134665711284, Test loss 0.46790544018149377, Train accuracy 99.83258928571429, Test accuracy 93.193359375, Cost 61.72735619544983 s\n",
      "Epoch 923, Train loss 0.0045425545332939375, Test loss 0.4765991307795048, Train accuracy 99.86607142857143, Test accuracy 92.548828125, Cost 61.751535415649414 s\n",
      "Epoch 924, Train loss 0.008102889567045185, Test loss 0.473857956379652, Train accuracy 99.72895408163265, Test accuracy 92.59765625, Cost 61.71727991104126 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 925, Train loss 0.005293697361278701, Test loss 0.4785851400345564, Train accuracy 99.80867346938776, Test accuracy 92.666015625, Cost 61.739810943603516 s\n",
      "Model saved in epoch 925\n",
      "Epoch 926, Train loss 0.005265621251575274, Test loss 0.48184472844004633, Train accuracy 99.81465242346938, Test accuracy 92.626953125, Cost 61.710102796554565 s\n",
      "Epoch 927, Train loss 0.0037308200646887653, Test loss 0.4378505893051624, Train accuracy 99.89437181122449, Test accuracy 93.076171875, Cost 61.670817613601685 s\n",
      "Epoch 928, Train loss 0.0026396907959846134, Test loss 0.44719945155084134, Train accuracy 99.90234375, Test accuracy 92.998046875, Cost 61.725303411483765 s\n",
      "Epoch 929, Train loss 0.0037279408168206848, Test loss 0.44148302897810937, Train accuracy 99.88639987244898, Test accuracy 93.017578125, Cost 61.67959952354431 s\n",
      "Epoch 930, Train loss 0.002496117956348937, Test loss 0.4573473583906889, Train accuracy 99.91629464285714, Test accuracy 92.802734375, Cost 61.73923063278198 s\n",
      "Model saved in epoch 930\n",
      "Epoch 931, Train loss 0.001890529196056637, Test loss 0.42770026326179506, Train accuracy 99.94021045918367, Test accuracy 93.203125, Cost 62.102447748184204 s\n",
      "Epoch 932, Train loss 0.001497691795502389, Test loss 0.41942530162632463, Train accuracy 99.95416135204081, Test accuracy 93.37890625, Cost 61.86931896209717 s\n",
      "Epoch 933, Train loss 0.0012992672463998153, Test loss 0.41601559668779375, Train accuracy 99.96014030612245, Test accuracy 93.388671875, Cost 61.80123543739319 s\n",
      "Epoch 934, Train loss 0.0016158105978431603, Test loss 0.43368229269981384, Train accuracy 99.94818239795919, Test accuracy 93.22265625, Cost 61.864428758621216 s\n",
      "Epoch 935, Train loss 0.0014978109005434298, Test loss 0.4111083891242743, Train accuracy 99.96412627551021, Test accuracy 93.75, Cost 61.83037257194519 s\n",
      "Model saved in epoch 935\n",
      "Epoch 936, Train loss 0.00126354352346425, Test loss 0.4449292756617069, Train accuracy 99.96412627551021, Test accuracy 93.388671875, Cost 61.815282344818115 s\n",
      "Epoch 937, Train loss 0.0015718232985558903, Test loss 0.4200551327317953, Train accuracy 99.95735012755102, Test accuracy 93.7109375, Cost 61.800785303115845 s\n",
      "Epoch 938, Train loss 0.004301408511922518, Test loss 0.4522318698465824, Train accuracy 99.87444196428571, Test accuracy 93.10546875, Cost 61.80759119987488 s\n",
      "Epoch 939, Train loss 0.0023374796295943918, Test loss 0.4444537445902824, Train accuracy 99.92625956632654, Test accuracy 93.154296875, Cost 61.77529978752136 s\n",
      "Epoch 940, Train loss 0.0026159680648227233, Test loss 0.4611444488167763, Train accuracy 99.91828762755102, Test accuracy 93.02734375, Cost 61.76860427856445 s\n",
      "Model saved in epoch 940\n",
      "Epoch 941, Train loss 0.002877267163039134, Test loss 0.4284073732793331, Train accuracy 99.89198022959184, Test accuracy 93.212890625, Cost 61.80453681945801 s\n",
      "Epoch 942, Train loss 0.004497891808531843, Test loss 0.4410885863006115, Train accuracy 99.8584980867347, Test accuracy 93.0859375, Cost 61.793230056762695 s\n",
      "Epoch 943, Train loss 0.003302658403615113, Test loss 0.44690795093774793, Train accuracy 99.89835778061224, Test accuracy 93.017578125, Cost 61.79538011550903 s\n",
      "Epoch 944, Train loss 0.002037284939684023, Test loss 0.44385508447885513, Train accuracy 99.9282525510204, Test accuracy 93.095703125, Cost 61.797353982925415 s\n",
      "Epoch 945, Train loss 0.0013490725646264838, Test loss 0.4463571712374687, Train accuracy 99.96014030612245, Test accuracy 92.98828125, Cost 61.786741971969604 s\n",
      "Model saved in epoch 945\n",
      "Epoch 946, Train loss 0.0015002186602190222, Test loss 0.4500487711280584, Train accuracy 99.95814732142857, Test accuracy 93.359375, Cost 61.72711157798767 s\n",
      "Epoch 947, Train loss 0.0017874359715018987, Test loss 0.44098007678985596, Train accuracy 99.94419642857143, Test accuracy 93.14453125, Cost 61.8064980506897 s\n",
      "Epoch 948, Train loss 0.0020877717900252813, Test loss 0.45419257916510103, Train accuracy 99.94021045918367, Test accuracy 92.861328125, Cost 61.81280589103699 s\n",
      "Epoch 949, Train loss 0.001929501482747434, Test loss 0.44087700061500074, Train accuracy 99.94021045918367, Test accuracy 93.369140625, Cost 61.747211933135986 s\n",
      "Epoch 950, Train loss 0.0017785407553859915, Test loss 0.46342221833765507, Train accuracy 99.94220344387755, Test accuracy 93.154296875, Cost 61.745484352111816 s\n",
      "Model saved in epoch 950\n",
      "Epoch 951, Train loss 0.0012483502524557888, Test loss 0.46604532226920126, Train accuracy 99.96811224489795, Test accuracy 92.978515625, Cost 61.79661965370178 s\n",
      "Epoch 952, Train loss 0.0023316505426102634, Test loss 0.45515507124364374, Train accuracy 99.91430165816327, Test accuracy 93.173828125, Cost 61.77755403518677 s\n",
      "Epoch 953, Train loss 0.0007538238502807612, Test loss 0.4497362066060305, Train accuracy 99.98007015306122, Test accuracy 93.115234375, Cost 61.77657723426819 s\n",
      "Epoch 954, Train loss 0.00046242274535583124, Test loss 0.43000649474561214, Train accuracy 99.99202806122449, Test accuracy 93.408203125, Cost 61.827595710754395 s\n",
      "Epoch 955, Train loss 0.0005943658382604127, Test loss 0.42794025912880895, Train accuracy 99.98405612244898, Test accuracy 93.359375, Cost 61.807595014572144 s\n",
      "Model saved in epoch 955\n",
      "Epoch 956, Train loss 0.0013431537817203726, Test loss 0.4395884245634079, Train accuracy 99.96412627551021, Test accuracy 93.115234375, Cost 61.79090189933777 s\n",
      "Epoch 957, Train loss 0.001460692789689755, Test loss 0.45313870906829834, Train accuracy 99.95017538265306, Test accuracy 92.67578125, Cost 61.817869901657104 s\n",
      "Epoch 958, Train loss 0.0006565124208371307, Test loss 0.43927069678902625, Train accuracy 99.98007015306122, Test accuracy 93.232421875, Cost 61.841596364974976 s\n",
      "Epoch 959, Train loss 0.000615591893673512, Test loss 0.46066160276532175, Train accuracy 99.9820631377551, Test accuracy 92.822265625, Cost 61.826878786087036 s\n",
      "Epoch 960, Train loss 0.0009502877183025499, Test loss 0.462558413669467, Train accuracy 99.96811224489795, Test accuracy 92.958984375, Cost 61.794357776641846 s\n",
      "Model saved in epoch 960\n",
      "Epoch 961, Train loss 0.000996232014224043, Test loss 0.4726432077586651, Train accuracy 99.96611926020408, Test accuracy 92.94921875, Cost 61.82307720184326 s\n",
      "Epoch 962, Train loss 0.001580444590171264, Test loss 0.4405011884868145, Train accuracy 99.9461894132653, Test accuracy 93.291015625, Cost 61.845458984375 s\n",
      "Epoch 963, Train loss 0.001066815493881482, Test loss 0.4424007602035999, Train accuracy 99.96811224489795, Test accuracy 93.28125, Cost 61.813612937927246 s\n",
      "Epoch 964, Train loss 0.0008753085192958159, Test loss 0.43128912933170793, Train accuracy 99.9820631377551, Test accuracy 93.359375, Cost 61.818262577056885 s\n",
      "Epoch 965, Train loss 0.0013215240170578056, Test loss 0.44388907551765444, Train accuracy 99.9561543367347, Test accuracy 93.18359375, Cost 61.83592343330383 s\n",
      "Model saved in epoch 965\n",
      "Epoch 966, Train loss 0.000547538776744455, Test loss 0.41153573580086233, Train accuracy 99.99402104591837, Test accuracy 93.603515625, Cost 61.804654598236084 s\n",
      "Epoch 967, Train loss 0.0004573881108125515, Test loss 0.4402026228606701, Train accuracy 99.99003507653062, Test accuracy 93.45703125, Cost 61.827388763427734 s\n",
      "Epoch 968, Train loss 0.00034675998396166077, Test loss 0.43709270320832727, Train accuracy 99.99402104591837, Test accuracy 93.603515625, Cost 61.83239006996155 s\n",
      "Epoch 969, Train loss 0.0005330348832771683, Test loss 0.44116410575807097, Train accuracy 99.9820631377551, Test accuracy 93.544921875, Cost 61.795573234558105 s\n",
      "Epoch 970, Train loss 0.00023256692327090512, Test loss 0.43222752064466474, Train accuracy 100.0, Test accuracy 93.7890625, Cost 61.795228242874146 s\n",
      "Model saved in epoch 970\n",
      "Epoch 971, Train loss 0.0003100297551833248, Test loss 0.43761596344411374, Train accuracy 99.99402104591837, Test accuracy 93.76953125, Cost 61.824589014053345 s\n",
      "Epoch 972, Train loss 0.0013072015648752276, Test loss 0.4673896670341492, Train accuracy 99.96213329081633, Test accuracy 93.45703125, Cost 61.82102727890015 s\n",
      "Epoch 973, Train loss 0.0012675935924878047, Test loss 0.4418064564466476, Train accuracy 99.96412627551021, Test accuracy 93.45703125, Cost 61.79024004936218 s\n",
      "Epoch 974, Train loss 0.000542912853889596, Test loss 0.4616647005081177, Train accuracy 99.98405612244898, Test accuracy 93.359375, Cost 61.78653049468994 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 975, Train loss 0.0003170601285138237, Test loss 0.44607062488794325, Train accuracy 99.99402104591837, Test accuracy 93.603515625, Cost 61.78898620605469 s\n",
      "Model saved in epoch 975\n",
      "Epoch 976, Train loss 0.00028620493822888084, Test loss 0.4337254326790571, Train accuracy 99.99202806122449, Test accuracy 93.57421875, Cost 61.77198052406311 s\n",
      "Epoch 977, Train loss 0.0015752936245017012, Test loss 0.4707080975174904, Train accuracy 99.9461894132653, Test accuracy 93.369140625, Cost 61.72491192817688 s\n",
      "Epoch 978, Train loss 0.0010809005952978623, Test loss 0.4602498099207878, Train accuracy 99.96811224489795, Test accuracy 93.3203125, Cost 61.71686410903931 s\n",
      "Epoch 979, Train loss 0.0006711789905498985, Test loss 0.458647757396102, Train accuracy 99.98007015306122, Test accuracy 93.603515625, Cost 61.81921982765198 s\n",
      "Epoch 980, Train loss 0.0013626513981395817, Test loss 0.4486233711242676, Train accuracy 99.96014030612245, Test accuracy 93.53515625, Cost 61.74045968055725 s\n",
      "Model saved in epoch 980\n",
      "Epoch 981, Train loss 0.0014777945402412876, Test loss 0.4687723994255066, Train accuracy 99.94220344387755, Test accuracy 93.310546875, Cost 61.81753921508789 s\n",
      "Epoch 982, Train loss 0.001295565725210592, Test loss 0.45332749262452127, Train accuracy 99.96412627551021, Test accuracy 93.125, Cost 61.7634482383728 s\n",
      "Epoch 983, Train loss 0.0012090750002587403, Test loss 0.448678095638752, Train accuracy 99.96412627551021, Test accuracy 93.232421875, Cost 61.77800464630127 s\n",
      "Epoch 984, Train loss 0.0008499316206617939, Test loss 0.46592323407530783, Train accuracy 99.97807716836735, Test accuracy 93.14453125, Cost 61.8026762008667 s\n",
      "Epoch 985, Train loss 0.0009244745458058137, Test loss 0.4673839394003153, Train accuracy 99.97209821428571, Test accuracy 93.349609375, Cost 61.743783712387085 s\n",
      "Model saved in epoch 985\n",
      "Epoch 986, Train loss 0.0009232816537196784, Test loss 0.47086858563125134, Train accuracy 99.98007015306122, Test accuracy 93.115234375, Cost 61.73464775085449 s\n",
      "Epoch 987, Train loss 0.0009258531386802467, Test loss 0.44447744116187093, Train accuracy 99.96811224489795, Test accuracy 93.33984375, Cost 61.80097985267639 s\n",
      "Epoch 988, Train loss 0.0013585725733134626, Test loss 0.45029101260006427, Train accuracy 99.96611926020408, Test accuracy 93.18359375, Cost 61.733970403671265 s\n",
      "Epoch 989, Train loss 0.0017401627931725003, Test loss 0.4911781411617994, Train accuracy 99.9461894132653, Test accuracy 92.9296875, Cost 61.78272891044617 s\n",
      "Epoch 990, Train loss 0.0008113367962973175, Test loss 0.45241574198007584, Train accuracy 99.97209821428571, Test accuracy 93.22265625, Cost 61.75398254394531 s\n",
      "Model saved in epoch 990\n",
      "Epoch 991, Train loss 0.0005340396620185021, Test loss 0.44052109532058237, Train accuracy 99.98804209183673, Test accuracy 93.466796875, Cost 61.829840660095215 s\n",
      "Epoch 992, Train loss 0.0012096473051175906, Test loss 0.45071732960641386, Train accuracy 99.96014030612245, Test accuracy 93.291015625, Cost 61.78577733039856 s\n",
      "Epoch 993, Train loss 0.0017379269574984372, Test loss 0.45099726840853693, Train accuracy 99.94818239795919, Test accuracy 93.408203125, Cost 61.756428718566895 s\n",
      "Epoch 994, Train loss 0.0012451947071969365, Test loss 0.43963507004082203, Train accuracy 99.96213329081633, Test accuracy 93.603515625, Cost 61.7526695728302 s\n",
      "Epoch 995, Train loss 0.0009056374378072791, Test loss 0.4239979512989521, Train accuracy 99.9740911989796, Test accuracy 93.45703125, Cost 61.75100302696228 s\n",
      "Model saved in epoch 995\n",
      "Epoch 996, Train loss 0.0010466691389123001, Test loss 0.447232897952199, Train accuracy 99.96412627551021, Test accuracy 93.49609375, Cost 61.796034812927246 s\n",
      "Epoch 997, Train loss 0.0006516192904330507, Test loss 0.4292336255311966, Train accuracy 99.98604910714286, Test accuracy 93.61328125, Cost 61.819265842437744 s\n",
      "Epoch 998, Train loss 0.0011020150970721817, Test loss 0.47453984096646307, Train accuracy 99.97209821428571, Test accuracy 92.98828125, Cost 61.73944878578186 s\n",
      "Epoch 999, Train loss 0.0012533207750354393, Test loss 0.46645066440105437, Train accuracy 99.95017538265306, Test accuracy 93.095703125, Cost 61.760777711868286 s\n",
      "Epoch 1000, Train loss 0.00126628422468197, Test loss 0.47198735997080804, Train accuracy 99.96811224489795, Test accuracy 93.408203125, Cost 61.756232500076294 s\n",
      "Model saved in epoch 1000\n",
      "Epoch 1001, Train loss 0.0010758321462102389, Test loss 0.4573672406375408, Train accuracy 99.96213329081633, Test accuracy 93.41796875, Cost 61.79107093811035 s\n",
      "Epoch 1002, Train loss 0.0007259300373612971, Test loss 0.4685242723673582, Train accuracy 99.9820631377551, Test accuracy 93.37890625, Cost 61.8123722076416 s\n",
      "Epoch 1003, Train loss 0.0009049464888982343, Test loss 0.4803179658949375, Train accuracy 99.97010522959184, Test accuracy 93.0078125, Cost 61.78056335449219 s\n",
      "Epoch 1004, Train loss 0.0010834559155051577, Test loss 0.47713630869984625, Train accuracy 99.96611926020408, Test accuracy 93.349609375, Cost 61.81357288360596 s\n",
      "Epoch 1005, Train loss 0.0015971180717672593, Test loss 0.4685512185096741, Train accuracy 99.95017538265306, Test accuracy 93.291015625, Cost 61.790581464767456 s\n",
      "Model saved in epoch 1005\n",
      "Epoch 1006, Train loss 0.0008422468561882257, Test loss 0.47391065359115603, Train accuracy 99.97807716836735, Test accuracy 93.203125, Cost 61.62426447868347 s\n",
      "Epoch 1007, Train loss 0.0009358886157452171, Test loss 0.48371468782424926, Train accuracy 99.9740911989796, Test accuracy 93.0078125, Cost 61.607914209365845 s\n",
      "Epoch 1008, Train loss 0.0007038012759967758, Test loss 0.45051012113690375, Train accuracy 99.9820631377551, Test accuracy 93.388671875, Cost 61.581077337265015 s\n",
      "Epoch 1009, Train loss 0.0008523612424531686, Test loss 0.48180577903985977, Train accuracy 99.97010522959184, Test accuracy 93.193359375, Cost 61.59757447242737 s\n",
      "Epoch 1010, Train loss 0.001987313139937084, Test loss 0.45125065855681895, Train accuracy 99.94818239795919, Test accuracy 93.212890625, Cost 61.62226867675781 s\n",
      "Model saved in epoch 1010\n",
      "Epoch 1011, Train loss 0.0009247421992336522, Test loss 0.4511196259409189, Train accuracy 99.97010522959184, Test accuracy 93.525390625, Cost 61.16905641555786 s\n",
      "Epoch 1012, Train loss 0.0007082274037550318, Test loss 0.4634357701987028, Train accuracy 99.97369260204081, Test accuracy 93.10546875, Cost 61.15241074562073 s\n",
      "Epoch 1013, Train loss 0.003750012946098576, Test loss 0.45840620025992396, Train accuracy 99.8764349489796, Test accuracy 93.427734375, Cost 61.0894558429718 s\n",
      "Epoch 1014, Train loss 0.0018942240143940358, Test loss 0.4418716598302126, Train accuracy 99.93223852040816, Test accuracy 93.33984375, Cost 61.07867741584778 s\n",
      "Epoch 1015, Train loss 0.0009395105682777247, Test loss 0.45720574595034125, Train accuracy 99.96611926020408, Test accuracy 93.2421875, Cost 61.10519003868103 s\n",
      "Model saved in epoch 1015\n",
      "Epoch 1016, Train loss 0.0008664681003331365, Test loss 0.4595385678112507, Train accuracy 99.97209821428571, Test accuracy 93.3984375, Cost 61.1966290473938 s\n",
      "Epoch 1017, Train loss 0.001232213754352712, Test loss 0.43798154667019845, Train accuracy 99.94818239795919, Test accuracy 93.486328125, Cost 61.2506890296936 s\n",
      "Epoch 1018, Train loss 0.0010547148094956912, Test loss 0.4339510556310415, Train accuracy 99.96372767857143, Test accuracy 93.30078125, Cost 61.24224305152893 s\n",
      "Epoch 1019, Train loss 0.0008388822274986412, Test loss 0.4243715889751911, Train accuracy 99.9740911989796, Test accuracy 93.515625, Cost 61.25647163391113 s\n",
      "Epoch 1020, Train loss 0.0012441540293204006, Test loss 0.4562658168375492, Train accuracy 99.96412627551021, Test accuracy 93.18359375, Cost 61.28385901451111 s\n",
      "Model saved in epoch 1020\n",
      "Epoch 1021, Train loss 0.0013671785823320608, Test loss 0.4368422418832779, Train accuracy 99.95416135204081, Test accuracy 93.4765625, Cost 61.26446557044983 s\n",
      "Epoch 1022, Train loss 0.0006379911899283779, Test loss 0.4356262534856796, Train accuracy 99.98007015306122, Test accuracy 93.603515625, Cost 61.288750886917114 s\n",
      "Epoch 1023, Train loss 0.0015110644377547052, Test loss 0.4728629544377327, Train accuracy 99.95814732142857, Test accuracy 93.037109375, Cost 61.301602602005005 s\n",
      "Epoch 1024, Train loss 0.0017035812830792046, Test loss 0.4551339767873287, Train accuracy 99.95017538265306, Test accuracy 93.3984375, Cost 61.28157901763916 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1025, Train loss 0.0010071074400550097, Test loss 0.42698721773922443, Train accuracy 99.96412627551021, Test accuracy 93.37890625, Cost 61.33443784713745 s\n",
      "Model saved in epoch 1025\n",
      "Epoch 1026, Train loss 0.0008329489882345691, Test loss 0.42474738545715807, Train accuracy 99.97209821428571, Test accuracy 93.73046875, Cost 61.285597801208496 s\n",
      "Epoch 1027, Train loss 0.0010396379815382048, Test loss 0.433287338539958, Train accuracy 99.96771364795919, Test accuracy 93.49609375, Cost 61.30008387565613 s\n",
      "Epoch 1028, Train loss 0.0017520430454781917, Test loss 0.45775817409157754, Train accuracy 99.9461894132653, Test accuracy 93.154296875, Cost 61.477134704589844 s\n",
      "Epoch 1029, Train loss 0.0015491052924809473, Test loss 0.45774784609675406, Train accuracy 99.95216836734694, Test accuracy 93.330078125, Cost 61.256112813949585 s\n",
      "Epoch 1030, Train loss 0.0008552084394292409, Test loss 0.4402174510061741, Train accuracy 99.97807716836735, Test accuracy 93.427734375, Cost 61.242098331451416 s\n",
      "Model saved in epoch 1030\n",
      "Epoch 1031, Train loss 0.0009664969970660367, Test loss 0.46805456951260566, Train accuracy 99.96611926020408, Test accuracy 93.203125, Cost 61.31369686126709 s\n",
      "Epoch 1032, Train loss 0.0013656685920643806, Test loss 0.45036913827061653, Train accuracy 99.95017538265306, Test accuracy 93.37890625, Cost 61.22269606590271 s\n",
      "Epoch 1033, Train loss 0.0011072067798097022, Test loss 0.4882688861340284, Train accuracy 99.96811224489795, Test accuracy 93.30078125, Cost 61.42593479156494 s\n",
      "Epoch 1034, Train loss 0.0007650915358890045, Test loss 0.47762366756796837, Train accuracy 99.97807716836735, Test accuracy 93.466796875, Cost 61.355345249176025 s\n",
      "Epoch 1035, Train loss 0.0008728028278316129, Test loss 0.4749152231961489, Train accuracy 99.9740911989796, Test accuracy 93.45703125, Cost 61.29402685165405 s\n",
      "Model saved in epoch 1035\n",
      "Epoch 1036, Train loss 0.00067967751596259, Test loss 0.4523486774414778, Train accuracy 99.98007015306122, Test accuracy 93.45703125, Cost 61.253546714782715 s\n",
      "Epoch 1037, Train loss 0.0006906007995091701, Test loss 0.46957119926810265, Train accuracy 99.98007015306122, Test accuracy 93.212890625, Cost 61.1583194732666 s\n",
      "Epoch 1038, Train loss 0.0006454751122020047, Test loss 0.4557266656309366, Train accuracy 99.98604910714286, Test accuracy 93.271484375, Cost 61.210602045059204 s\n",
      "Epoch 1039, Train loss 0.00028068817675598346, Test loss 0.43727648071944714, Train accuracy 99.99402104591837, Test accuracy 93.69140625, Cost 61.194804191589355 s\n",
      "Epoch 1040, Train loss 0.000357984661307302, Test loss 0.44397217221558094, Train accuracy 99.98604910714286, Test accuracy 93.75, Cost 61.225871562957764 s\n",
      "Model saved in epoch 1040\n",
      "Epoch 1041, Train loss 0.0003009409597035412, Test loss 0.4430688083171844, Train accuracy 99.99202806122449, Test accuracy 93.80859375, Cost 61.253819704055786 s\n",
      "Epoch 1042, Train loss 0.00020402479082795068, Test loss 0.4423700049519539, Train accuracy 99.99800701530613, Test accuracy 93.8671875, Cost 61.308433055877686 s\n",
      "Epoch 1043, Train loss 0.0002455017008289861, Test loss 0.43941323086619377, Train accuracy 99.99202806122449, Test accuracy 93.662109375, Cost 61.38539695739746 s\n",
      "Epoch 1044, Train loss 0.00012936579106589567, Test loss 0.42819865942001345, Train accuracy 100.0, Test accuracy 93.701171875, Cost 61.26056718826294 s\n",
      "Epoch 1045, Train loss 0.0001526395278757746, Test loss 0.43283606953918935, Train accuracy 99.99601403061224, Test accuracy 93.583984375, Cost 61.27920126914978 s\n",
      "Model saved in epoch 1045\n",
      "Epoch 1046, Train loss 0.0002884724970125977, Test loss 0.4238607451319695, Train accuracy 99.99402104591837, Test accuracy 93.740234375, Cost 61.210264682769775 s\n",
      "Epoch 1047, Train loss 0.00017592591155344238, Test loss 0.42820863500237466, Train accuracy 99.99601403061224, Test accuracy 93.740234375, Cost 61.27066707611084 s\n",
      "Epoch 1048, Train loss 0.00018544537438081496, Test loss 0.4260344680398703, Train accuracy 99.99601403061224, Test accuracy 93.740234375, Cost 61.48391819000244 s\n",
      "Epoch 1049, Train loss 0.00026764675458055686, Test loss 0.43306027837097644, Train accuracy 99.99402104591837, Test accuracy 93.6328125, Cost 61.24924898147583 s\n",
      "Epoch 1050, Train loss 0.00025281988517430624, Test loss 0.4254410840570927, Train accuracy 99.99601403061224, Test accuracy 93.90625, Cost 61.182910203933716 s\n",
      "Model saved in epoch 1050\n",
      "Epoch 1051, Train loss 0.00021685819932054537, Test loss 0.42116262279450895, Train accuracy 99.99800701530613, Test accuracy 94.0625, Cost 61.2436842918396 s\n",
      "Epoch 1052, Train loss 0.00018455881904721574, Test loss 0.42139256522059443, Train accuracy 99.99800701530613, Test accuracy 93.974609375, Cost 61.26005983352661 s\n",
      "Epoch 1053, Train loss 0.00013521810345892214, Test loss 0.42248064242303374, Train accuracy 99.99800701530613, Test accuracy 93.8671875, Cost 61.2510552406311 s\n",
      "Epoch 1054, Train loss 0.0002510959268147649, Test loss 0.4380019064992666, Train accuracy 99.99202806122449, Test accuracy 93.681640625, Cost 61.32679629325867 s\n",
      "Epoch 1055, Train loss 0.00023577471743079997, Test loss 0.4288244068622589, Train accuracy 99.99202806122449, Test accuracy 93.720703125, Cost 61.3773398399353 s\n",
      "Model saved in epoch 1055\n",
      "Epoch 1056, Train loss 0.00023341909064985273, Test loss 0.43403762169182303, Train accuracy 99.98804209183673, Test accuracy 93.88671875, Cost 61.21845579147339 s\n",
      "Epoch 1057, Train loss 0.0003998252703534221, Test loss 0.43400065824389455, Train accuracy 99.99202806122449, Test accuracy 93.623046875, Cost 61.22225499153137 s\n",
      "Epoch 1058, Train loss 0.0003360242800228003, Test loss 0.437346182949841, Train accuracy 99.99402104591837, Test accuracy 93.5546875, Cost 61.27929878234863 s\n",
      "Epoch 1059, Train loss 0.0005111762749149828, Test loss 0.44335834234952926, Train accuracy 99.9820631377551, Test accuracy 93.3984375, Cost 61.72237420082092 s\n",
      "Epoch 1060, Train loss 0.00031393763654064894, Test loss 0.43883753530681135, Train accuracy 99.99202806122449, Test accuracy 93.427734375, Cost 61.67954754829407 s\n",
      "Model saved in epoch 1060\n",
      "Epoch 1061, Train loss 0.00020571006142016215, Test loss 0.4319361537694931, Train accuracy 99.99601403061224, Test accuracy 93.80859375, Cost 61.73521614074707 s\n",
      "Epoch 1062, Train loss 0.00016427373789005455, Test loss 0.44835795611143114, Train accuracy 100.0, Test accuracy 93.828125, Cost 61.43266987800598 s\n",
      "Epoch 1063, Train loss 0.00010086141706055133, Test loss 0.44545568376779554, Train accuracy 100.0, Test accuracy 93.798828125, Cost 61.42933440208435 s\n",
      "Epoch 1064, Train loss 8.744896022641782e-05, Test loss 0.44118068739771843, Train accuracy 100.0, Test accuracy 93.7109375, Cost 61.297263622283936 s\n",
      "Epoch 1065, Train loss 8.599443904641907e-05, Test loss 0.439165710285306, Train accuracy 100.0, Test accuracy 93.80859375, Cost 61.30718421936035 s\n",
      "Model saved in epoch 1065\n",
      "Epoch 1066, Train loss 0.0002053988549840128, Test loss 0.4411322470754385, Train accuracy 99.99601403061224, Test accuracy 93.818359375, Cost 61.32188701629639 s\n",
      "Epoch 1067, Train loss 0.00030633467510793886, Test loss 0.44558348432183265, Train accuracy 99.99202806122449, Test accuracy 93.90625, Cost 61.31899619102478 s\n",
      "Epoch 1068, Train loss 0.00012559104500756542, Test loss 0.44203921742737295, Train accuracy 99.99800701530613, Test accuracy 93.53515625, Cost 61.305499792099 s\n",
      "Epoch 1069, Train loss 0.00036960698551292715, Test loss 0.45451297648251054, Train accuracy 99.99003507653062, Test accuracy 93.3203125, Cost 61.26296663284302 s\n",
      "Epoch 1070, Train loss 0.00015914171533506992, Test loss 0.4471093945205212, Train accuracy 99.99800701530613, Test accuracy 93.69140625, Cost 61.23815727233887 s\n",
      "Model saved in epoch 1070\n",
      "Epoch 1071, Train loss 0.00010599672615700576, Test loss 0.4477995663881302, Train accuracy 99.99800701530613, Test accuracy 93.61328125, Cost 61.73040461540222 s\n",
      "Epoch 1072, Train loss 0.000157763858080601, Test loss 0.44093098007142545, Train accuracy 99.99601403061224, Test accuracy 93.642578125, Cost 61.62889218330383 s\n",
      "Epoch 1073, Train loss 0.00011429355193550525, Test loss 0.43577196821570396, Train accuracy 99.99800701530613, Test accuracy 93.80859375, Cost 61.28188681602478 s\n",
      "Epoch 1074, Train loss 0.0002643453061239723, Test loss 0.4434284843504429, Train accuracy 99.99003507653062, Test accuracy 93.73046875, Cost 61.255157470703125 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1075, Train loss 0.00015356024552320424, Test loss 0.4519182175397873, Train accuracy 99.99800701530613, Test accuracy 93.740234375, Cost 61.27235555648804 s\n",
      "Model saved in epoch 1075\n",
      "Epoch 1076, Train loss 0.00015535581337992565, Test loss 0.44591194950044155, Train accuracy 99.99402104591837, Test accuracy 93.798828125, Cost 61.44617176055908 s\n",
      "Epoch 1077, Train loss 8.324204316010059e-05, Test loss 0.44228102155029775, Train accuracy 100.0, Test accuracy 93.876953125, Cost 61.484243631362915 s\n",
      "Epoch 1078, Train loss 0.00018264151017772246, Test loss 0.43915244527161124, Train accuracy 99.9936224489796, Test accuracy 94.033203125, Cost 61.32813096046448 s\n",
      "Epoch 1079, Train loss 0.0011624861749194736, Test loss 0.45177604258060455, Train accuracy 99.96412627551021, Test accuracy 93.515625, Cost 61.27308940887451 s\n",
      "Epoch 1080, Train loss 0.0010206188050069752, Test loss 0.47269925139844415, Train accuracy 99.96811224489795, Test accuracy 93.37890625, Cost 61.25423336029053 s\n",
      "Model saved in epoch 1080\n",
      "Epoch 1081, Train loss 0.0007070497840825793, Test loss 0.4663613669574261, Train accuracy 99.97209821428571, Test accuracy 93.544921875, Cost 61.47127032279968 s\n",
      "Epoch 1082, Train loss 0.0006461211014939228, Test loss 0.4754689738154411, Train accuracy 99.97807716836735, Test accuracy 93.388671875, Cost 61.49923896789551 s\n",
      "Epoch 1083, Train loss 0.0006758553096627724, Test loss 0.4601369433104992, Train accuracy 99.98007015306122, Test accuracy 93.5546875, Cost 61.41899752616882 s\n",
      "Epoch 1084, Train loss 0.0006537378935660148, Test loss 0.45752860233187675, Train accuracy 99.9820631377551, Test accuracy 93.466796875, Cost 61.44790172576904 s\n",
      "Epoch 1085, Train loss 0.00041870453900725934, Test loss 0.4547451637685299, Train accuracy 99.98565051020408, Test accuracy 93.564453125, Cost 61.329395055770874 s\n",
      "Model saved in epoch 1085\n",
      "Epoch 1086, Train loss 0.0010028841111005356, Test loss 0.45874027982354165, Train accuracy 99.97010522959184, Test accuracy 93.61328125, Cost 61.36809277534485 s\n",
      "Epoch 1087, Train loss 0.0006922895848890443, Test loss 0.4647429037839174, Train accuracy 99.98007015306122, Test accuracy 93.388671875, Cost 61.4837384223938 s\n",
      "Epoch 1088, Train loss 0.0004654344953469634, Test loss 0.47046274691820145, Train accuracy 99.98604910714286, Test accuracy 93.49609375, Cost 61.41587686538696 s\n",
      "Epoch 1089, Train loss 0.0004305862323145002, Test loss 0.47125132121145724, Train accuracy 99.98604910714286, Test accuracy 93.37890625, Cost 61.59557056427002 s\n",
      "Epoch 1090, Train loss 0.00025570643978651284, Test loss 0.4670551124960184, Train accuracy 99.99402104591837, Test accuracy 93.349609375, Cost 61.60287523269653 s\n",
      "Model saved in epoch 1090\n",
      "Epoch 1091, Train loss 0.0012115059977519168, Test loss 0.46671396866440773, Train accuracy 99.9561543367347, Test accuracy 93.134765625, Cost 61.60614991188049 s\n",
      "Epoch 1092, Train loss 0.0008377846766945497, Test loss 0.5018623307347297, Train accuracy 99.9740911989796, Test accuracy 92.67578125, Cost 61.66333889961243 s\n",
      "Epoch 1093, Train loss 0.0010910730423171228, Test loss 0.4841257855296135, Train accuracy 99.96970663265306, Test accuracy 93.37890625, Cost 61.806392669677734 s\n",
      "Epoch 1094, Train loss 0.002558064033031101, Test loss 0.5238349452614784, Train accuracy 99.9282525510204, Test accuracy 92.939453125, Cost 61.83729815483093 s\n",
      "Epoch 1095, Train loss 0.0016056396288919984, Test loss 0.49195790067315104, Train accuracy 99.94419642857143, Test accuracy 93.125, Cost 61.793816566467285 s\n",
      "Model saved in epoch 1095\n",
      "Epoch 1096, Train loss 0.0012080997270672645, Test loss 0.4624492581933737, Train accuracy 99.96412627551021, Test accuracy 93.30078125, Cost 61.81777501106262 s\n",
      "Epoch 1097, Train loss 0.0008988384423905792, Test loss 0.46123540624976156, Train accuracy 99.97010522959184, Test accuracy 93.37890625, Cost 61.78175401687622 s\n",
      "Epoch 1098, Train loss 0.0006317304168210656, Test loss 0.4621095277369022, Train accuracy 99.9820631377551, Test accuracy 93.505859375, Cost 61.80342769622803 s\n",
      "Epoch 1099, Train loss 0.0005027296743134814, Test loss 0.48965910971164706, Train accuracy 99.98405612244898, Test accuracy 93.26171875, Cost 61.83224177360535 s\n",
      "Epoch 1100, Train loss 0.0015509429527260552, Test loss 0.4768222451210022, Train accuracy 99.96014030612245, Test accuracy 93.134765625, Cost 61.80248475074768 s\n",
      "Model saved in epoch 1100\n",
      "Epoch 1101, Train loss 0.0011881745956729066, Test loss 0.4524646904319525, Train accuracy 99.96412627551021, Test accuracy 93.447265625, Cost 61.872411251068115 s\n",
      "Epoch 1102, Train loss 0.0003857991353990136, Test loss 0.4536387983709574, Train accuracy 99.99202806122449, Test accuracy 93.49609375, Cost 61.87187910079956 s\n",
      "Epoch 1103, Train loss 0.0002781630361547676, Test loss 0.4535216424614191, Train accuracy 99.99003507653062, Test accuracy 93.53515625, Cost 62.17583513259888 s\n",
      "Epoch 1104, Train loss 0.0002385409089927226, Test loss 0.4517326485365629, Train accuracy 99.99402104591837, Test accuracy 93.486328125, Cost 62.252225399017334 s\n",
      "Epoch 1105, Train loss 0.00014673829721278725, Test loss 0.44737872779369353, Train accuracy 99.99800701530613, Test accuracy 93.662109375, Cost 62.37623333930969 s\n",
      "Model saved in epoch 1105\n",
      "Epoch 1106, Train loss 0.00017392774895037228, Test loss 0.4514843538403511, Train accuracy 99.99601403061224, Test accuracy 93.564453125, Cost 62.22176146507263 s\n",
      "Epoch 1107, Train loss 0.000311941222191438, Test loss 0.45103275738656523, Train accuracy 99.98804209183673, Test accuracy 93.4375, Cost 62.23265099525452 s\n",
      "Epoch 1108, Train loss 0.0002464483856217658, Test loss 0.4522289678454399, Train accuracy 99.99202806122449, Test accuracy 93.486328125, Cost 62.08930563926697 s\n",
      "Epoch 1109, Train loss 0.0002036703203861625, Test loss 0.4481555886566639, Train accuracy 99.99202806122449, Test accuracy 93.69140625, Cost 62.062500953674316 s\n",
      "Epoch 1110, Train loss 0.00021411628743776975, Test loss 0.4549564801156521, Train accuracy 99.99402104591837, Test accuracy 93.623046875, Cost 62.052375078201294 s\n",
      "Model saved in epoch 1110\n",
      "Epoch 1111, Train loss 0.0005446307758892989, Test loss 0.4517909370362759, Train accuracy 99.98804209183673, Test accuracy 93.740234375, Cost 62.065911293029785 s\n",
      "Epoch 1112, Train loss 0.000287112788332219, Test loss 0.44792829379439353, Train accuracy 99.99003507653062, Test accuracy 93.720703125, Cost 62.006341218948364 s\n",
      "Epoch 1113, Train loss 0.0004633800714486244, Test loss 0.44508229196071625, Train accuracy 99.98804209183673, Test accuracy 93.7109375, Cost 62.006715059280396 s\n",
      "Epoch 1114, Train loss 0.00031035543221772673, Test loss 0.4466068744659424, Train accuracy 99.98804209183673, Test accuracy 93.59375, Cost 62.10627269744873 s\n",
      "Epoch 1115, Train loss 0.00033382131105401305, Test loss 0.45752093344926836, Train accuracy 99.98604910714286, Test accuracy 93.388671875, Cost 62.28524327278137 s\n",
      "Model saved in epoch 1115\n",
      "Epoch 1116, Train loss 0.0003848603856516891, Test loss 0.46333210691809656, Train accuracy 99.98405612244898, Test accuracy 93.662109375, Cost 62.282034158706665 s\n",
      "Epoch 1117, Train loss 0.0004938628506024821, Test loss 0.4741977762430906, Train accuracy 99.99003507653062, Test accuracy 93.28125, Cost 62.21726202964783 s\n",
      "Epoch 1118, Train loss 0.0005543039575901294, Test loss 0.48842314146459104, Train accuracy 99.98804209183673, Test accuracy 93.33984375, Cost 62.208500146865845 s\n",
      "Epoch 1119, Train loss 0.00040868875715910244, Test loss 0.48852403536438943, Train accuracy 99.99003507653062, Test accuracy 93.232421875, Cost 62.19819903373718 s\n",
      "Epoch 1120, Train loss 0.0006441174909691561, Test loss 0.48717342168092725, Train accuracy 99.98804209183673, Test accuracy 93.388671875, Cost 62.19274044036865 s\n",
      "Model saved in epoch 1120\n",
      "Epoch 1121, Train loss 0.0005660109948781629, Test loss 0.48213028609752656, Train accuracy 99.98405612244898, Test accuracy 93.486328125, Cost 62.209588050842285 s\n",
      "Epoch 1122, Train loss 0.0002518848548055646, Test loss 0.47692279033362867, Train accuracy 99.99202806122449, Test accuracy 93.544921875, Cost 62.17930293083191 s\n",
      "Epoch 1123, Train loss 0.0004966423828333824, Test loss 0.46553260311484335, Train accuracy 99.97767857142857, Test accuracy 93.80859375, Cost 62.14067625999451 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1124, Train loss 0.0011435914837337044, Test loss 0.4890370063483715, Train accuracy 99.96213329081633, Test accuracy 93.359375, Cost 62.148489236831665 s\n",
      "Epoch 1125, Train loss 0.0007540333831167229, Test loss 0.49385725855827334, Train accuracy 99.9820631377551, Test accuracy 93.0859375, Cost 62.134833574295044 s\n",
      "Model saved in epoch 1125\n",
      "Epoch 1126, Train loss 0.0006957018983678618, Test loss 0.4877146080136299, Train accuracy 99.98405612244898, Test accuracy 93.57421875, Cost 62.16406607627869 s\n",
      "Epoch 1127, Train loss 0.0008356275641649888, Test loss 0.49876069873571394, Train accuracy 99.9740911989796, Test accuracy 93.662109375, Cost 62.14831256866455 s\n",
      "Epoch 1128, Train loss 0.0007557450831320833, Test loss 0.4762453086674213, Train accuracy 99.97608418367346, Test accuracy 93.59375, Cost 62.144354820251465 s\n",
      "Epoch 1129, Train loss 0.00026742858568956754, Test loss 0.46626203805208205, Train accuracy 99.99402104591837, Test accuracy 93.65234375, Cost 62.138829469680786 s\n",
      "Epoch 1130, Train loss 0.00039305640643470834, Test loss 0.46779038906097414, Train accuracy 99.98604910714286, Test accuracy 93.603515625, Cost 62.163379192352295 s\n",
      "Model saved in epoch 1130\n",
      "Epoch 1131, Train loss 0.0005310633746294766, Test loss 0.48715474270284176, Train accuracy 99.98604910714286, Test accuracy 93.3984375, Cost 62.12335562705994 s\n",
      "Epoch 1132, Train loss 0.00030644794156378153, Test loss 0.4777374569326639, Train accuracy 99.99402104591837, Test accuracy 93.49609375, Cost 62.12822437286377 s\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5000 # param\n",
    "epoch_start = 0\n",
    "# path = 'adam_rotate_center_crop1.pt'\n",
    "# path = 'block_3.pt'\n",
    "path = 'lr_0.1-0.0003_decay_channel_80_avg_8.pt'\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "test_accuracy_history = []\n",
    "train_accuracy_history = []\n",
    "\n",
    "Loss = torch.nn.CrossEntropyLoss()\n",
    "lr = 0.1 # param\n",
    "lr_min=0.0003\n",
    "# optimizer = torch.optim.SGD(model1.parameters(),lr=lr,momentum=0.9,weight_decay=5e-4) # changable optimizer\n",
    "# optimizer = torch.optim.SGD(model1.parameters(),lr=lr,momentum=0.9) # changable optimizer\n",
    "# optimizer = torch.optim.Adam(model1.parameters(),lr=lr, betas=(0.9,0.999), eps=1e-08, amsgrad=False) # changable optimizer\n",
    "momentum = 0.9\n",
    "nesterov = True\n",
    "optimizer = torch.optim.SGD(model1.parameters(),lr=lr,momentum=momentum,nesterov=nesterov)\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "if os.path.exists(path):\n",
    "  checkpoint = torch.load(path)\n",
    "  print('Read model from checkpoint')\n",
    "  model1.cuda().load_state_dict(checkpoint['model_state_dict'])\n",
    "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "  epoch_start = checkpoint['epoch']\n",
    "  Loss = checkpoint['Loss']\n",
    "  train_loss_history = checkpoint['train_loss_history']\n",
    "  test_loss_history = checkpoint['test_loss_history']\n",
    "  test_accuracy_history = checkpoint['test_accuracy_history']\n",
    "  train_accuracy_history = checkpoint['train_accuracy_history']\n",
    "  print('Restart from epoch',epoch_start)\n",
    "    \n",
    "\n",
    "for epoch in range(epoch_start+1, num_epochs + 1):\n",
    "  timestart = time.time()\n",
    "\n",
    "  train_loss = 0.0\n",
    "  test_loss = 0.0\n",
    "  test_accuracy = 0.0\n",
    "  train_accuracy = 0.0\n",
    "\n",
    "  for i, data in enumerate(trainDataLoader):\n",
    "    images, labels = data\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    optimizer.zero_grad()\n",
    "    predicted_output = model1.cuda()(images)\n",
    "    fit = Loss(predicted_output,labels)\n",
    "    fit.backward()\n",
    "    adjust_learning_rate(optimizer=optimizer,current_epoch=epoch,max_epoch=num_epochs,lr_min=lr_min,lr_max=lr,warmup=True)\n",
    "    optimizer.step()\n",
    "    train_loss += fit.item()\n",
    "    train_accuracy += (torch.eq(torch.max(predicted_output,1)[1],labels).sum()/len(labels)*100).data.cpu().numpy()\n",
    "\n",
    "  for i, data in enumerate(testDataLoader):\n",
    "    with torch.no_grad():\n",
    "      images, labels = data\n",
    "      images = images.cuda()\n",
    "      labels = labels.cuda()\n",
    "      predicted_output = model1.cuda()(images)\n",
    "      fit = Loss(predicted_output,labels)\n",
    "      test_loss += fit.item()\n",
    "      test_accuracy += (torch.eq(torch.max(predicted_output,1)[1],labels).sum()/len(labels)*100).data.cpu().numpy()\n",
    "\n",
    "\n",
    "  train_loss = train_loss/len(trainDataLoader)\n",
    "  test_loss = test_loss/len(testDataLoader)\n",
    "  test_accu = test_accuracy/len(testDataLoader)\n",
    "  train_accu = train_accuracy/len(trainDataLoader)\n",
    "  train_loss_history.append(train_loss)\n",
    "  test_loss_history.append(test_loss)\n",
    "  test_accuracy_history.append(test_accu)\n",
    "  train_accuracy_history.append(train_accu)\n",
    "  print('Epoch %s, Train loss %s, Test loss %s, Train accuracy %s, Test accuracy %s, Cost %s s'%(epoch,\n",
    "                                                                                                   train_loss,test_loss,\n",
    "                                                                                                   train_accu,test_accu,\n",
    "                                                                                                   time.time()-timestart))\n",
    "  \n",
    "  if epoch % 5 == 0 and epoch != 0:\n",
    "    torch.save({'epoch':epoch,\n",
    "          'model_state_dict':model1.cuda().state_dict(),\n",
    "          'optimizer_state_dict':optimizer.state_dict(),\n",
    "          'Loss':Loss,\n",
    "          'train_loss_history':train_loss_history,\n",
    "          'test_loss_history':test_loss_history,\n",
    "          'test_accuracy_history':test_accuracy_history,\n",
    "          'train_accuracy_history':train_accuracy_history},path)\n",
    "    print('Model saved in epoch %s'%(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RUy08Iyn7tUl",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# num_epochs = 637\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(num_epochs),train_loss_history,'-',linewidth=3,label='Train error')\n",
    "plt.plot(range(num_epochs),test_loss_history,'-',linewidth=3,label='Test error')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(num_epochs),train_accuracy_history,'-',linewidth=3,label='Test accuracy')\n",
    "plt.plot(range(num_epochs),test_accuracy_history,'-',linewidth=3,label='Test accuracy')\n",
    "# plt.plot(range(num_epochs),test_accuracy_history,'-',linewidth=3,label='Test accuracy')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVQJgMts7vcg"
   },
   "outputs": [],
   "source": [
    "print('Accuracy:',sum(test_accuracy_history[-5:])/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LaMUB4p_Ucip"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "“ResNet.ipynb”的副本",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0130588af6254c76a2c8c382288cfcea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4aa5668c8eaa49f88148d499240b6ea5",
      "placeholder": "​",
      "style": "IPY_MODEL_a66b114e4595419f84ac44a676a1ca61",
      "value": " 170499072/? [00:03&lt;00:00, 56047078.45it/s]"
     }
    },
    "1121692d91114d58b3db79e41b0a24c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d40f4bf0c0e48709cdec5f80069ed2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "321ea7fa0b4d4c9dab9ed5231954e54c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3983cfe844f847899487b2745a203a9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8148f05b38d94ec19351ac920b70acba",
       "IPY_MODEL_af7b660f147d4d1d8796d3419673c9b7",
       "IPY_MODEL_0130588af6254c76a2c8c382288cfcea"
      ],
      "layout": "IPY_MODEL_1121692d91114d58b3db79e41b0a24c9"
     }
    },
    "4aa5668c8eaa49f88148d499240b6ea5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8148f05b38d94ec19351ac920b70acba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_accf52fe298b4716af9d9c351e7326dc",
      "placeholder": "​",
      "style": "IPY_MODEL_fb3e769eb8324af3b77041879c9b54cf",
      "value": ""
     }
    },
    "a66b114e4595419f84ac44a676a1ca61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "accf52fe298b4716af9d9c351e7326dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af7b660f147d4d1d8796d3419673c9b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_321ea7fa0b4d4c9dab9ed5231954e54c",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d40f4bf0c0e48709cdec5f80069ed2f",
      "value": 170498071
     }
    },
    "fb3e769eb8324af3b77041879c9b54cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
