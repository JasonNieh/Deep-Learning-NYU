{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "azOQDGfMLFN8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import math\n",
    "import torchvision\n",
    "from torchvision import transforms as transforms\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from math import cos,pi\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nnaef49GOhPH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Vb_Gr3w9vzx8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x14a160546970>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(17)\n",
    "\n",
    "class HaS(object): \n",
    "#     def __init__(self):\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        # get width and height of the image\n",
    "        img_= np.array(img).copy()\n",
    "        s = img_.shape\n",
    "        wd = s[0]\n",
    "        ht = s[1]\n",
    "\n",
    "        # possible grid size, 0 means no hiding\n",
    "        grid_size=3\n",
    "\n",
    "        # hiding probability\n",
    "        hide_prob = 0.1\n",
    " \n",
    "        # randomly choose one grid size\n",
    "#         grid_size= grid_sizes[random.randint(0,len(grid_sizes)-1)]\n",
    "\n",
    "        # hide the patches\n",
    "        if(grid_size>0):\n",
    "             for x in range(0,wd,grid_size):\n",
    "                 for y in range(0,ht,grid_size):\n",
    "                     x_end = min(wd, x+grid_size)  \n",
    "                     y_end = min(ht, y+grid_size)\n",
    "                     if(random.random() <=  hide_prob):\n",
    "                           img_[x:x_end,y:y_end,:]=0\n",
    "\n",
    "        return img_\n",
    "    \n",
    "torch.manual_seed(17)\n",
    "\n",
    "        \n",
    "# class HideEdge(object): \n",
    "#     def __init__(self,hide_size):\n",
    "#         self.hide_size=hide_size\n",
    "        \n",
    "#     def __call__(self, img):\n",
    "#         # get width and height of the image\n",
    "#         img_= np.array(img).copy()\n",
    "#         s = img_.shape\n",
    "#         wd = s[0]\n",
    "#         ht = s[1]\n",
    "\n",
    "#         hide_size=self.hide_size\n",
    "        \n",
    "# #         img_[:,:,:] = img()\n",
    "   \n",
    "#         x_end = wd - hide_size \n",
    "#         y_end = ht - hide_size\n",
    "\n",
    "#         img_[x_end:,y_end:,:]=0\n",
    "# #         img_[x_end:,:hide_size,:]=0\n",
    "# #         img_[:hide_size,y_end:,:]=0\n",
    "#         img_[:hide_size,:hide_size,:]=0\n",
    "# #         img_[x_end:,:,:]=0\n",
    "# #         img_[:,y_end:,:]=0\n",
    "# #         img_[:hide_size,:,:]=0\n",
    "# #         img_[:,:hide_size,:]=0\n",
    "# #         print(img_[x_end,y_end,:])\n",
    "# #         print(img_[hide_size,hide_size,:])\n",
    "# #         print(x_end,y_end,hide_size)\n",
    "        \n",
    "# #         mean = img_[hide_size:x_end-1,hide_size:y_end,:].mean()\n",
    "# #         std = img_[hide_size:x_end-1,hide_size:y_end,:].std()\n",
    "# #         print(mean, std)\n",
    "# #         img_[hide_size:x_end-1,hide_size:y_end,:] = (img_[hide_size:x_end-1,hide_size:y_end,:] - mean) / std\n",
    "# #         print(img_[hide_size:x_end-1,hide_size:y_end,:])\n",
    "        \n",
    "#         return img_\n",
    "\n",
    "   \n",
    "# class Hide_after_Norm(object): \n",
    "#     def __init__(self,hide_size):\n",
    "#         self.hide_size=hide_size\n",
    "        \n",
    "#     def __call__(self, img_):\n",
    "#         # get width and height of the image\n",
    "# #         img_= np.array(img).copy()\n",
    "#         s = img_.shape\n",
    "#         wd = s[1]\n",
    "#         ht = s[2]\n",
    "\n",
    "#         hide_size=self.hide_size\n",
    "        \n",
    "# #         img_[:,:,:] = img()\n",
    "   \n",
    "#         x_end = wd - hide_size \n",
    "#         y_end = ht - hide_size\n",
    "        \n",
    "#         x_end = wd - hide_size \n",
    "#         y_end = ht - hide_size\n",
    "\n",
    "#         img_[:,x_end:,y_end:]=0\n",
    "# #         img_[x_end:,:hide_size,:]=0\n",
    "# #         img_[:hide_size,y_end:,:]=0\n",
    "#         img_[:,:hide_size,:hide_size]=0\n",
    "# #         print(img_[x_end,y_end,:])\n",
    "# #         print(img_[hide_size,hide_size,:])\n",
    "# #         print(x_end,y_end,hide_size)\n",
    "        \n",
    "# #         mean = img_[hide_size:x_end-1,hide_size:y_end,:].mean()\n",
    "# #         std = img_[hide_size:x_end-1,hide_size:y_end,:].std()\n",
    "# #         print(mean, std)\n",
    "# #         img_[hide_size:x_end-1,hide_size:y_end,:] = (img_[hide_size:x_end-1,hide_size:y_end,:] - mean) / std\n",
    "# #         print(img_[hide_size:x_end-1,hide_size:y_end,:])\n",
    "        \n",
    "#         return img_\n",
    "    \n",
    "    \n",
    "\n",
    "# # torch.cuda.manual_seed(17) # for GPU\n",
    "# aug_train = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(), # 水平翻转\n",
    "# #     torchvision.transforms.CenterCrop(26),\n",
    "# #     HideEdge(),\n",
    "#     torchvision.transforms.RandomRotation(15),\n",
    "# #     torchvision.transforms.CenterCrop(28),\n",
    "#     # transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5), # color aug\n",
    "# #     transforms.RandomCrop(32, padding=4), # 裁剪\n",
    "#     # transforms.RandomResizedCrop((32,32),scale=(0.1,1),ratio=(0.5,2))\n",
    "# #     hide_patch(),\n",
    "# #     HaS(),\n",
    "# #     HideEdge(2),\n",
    "#     transforms.ToTensor(),\n",
    "# #     Norm(2),\n",
    "#     transforms.Normalize((0.4649, 0.4553, 0.4214), (0.2271, 0.2234, 0.2208)),# normalization\n",
    "#     Hide_after_Norm(2)\n",
    "#     ])\n",
    "\n",
    "# aug_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4649, 0.4553, 0.4214), (0.2271, 0.2234, 0.2208)), # normalization\n",
    "#     Hide_after_Norm(2)\n",
    "#     ])\n",
    "\n",
    "# trainingdata = torchvision.datasets.CIFAR10('./CIFAR10',train=True,download=True,transform=aug_train)\n",
    "# # testdata = torchvision.datasets.CIFAR10('./CIFAR10',train=False,download=True,transform=transforms.ToTensor())\n",
    "# # print(len(trainingdata),len(testdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(17)\n",
    "torch.cuda.manual_seed_all(17)\n",
    "\n",
    "aug_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32,padding=4,padding_mode='reflect'),\n",
    "    transforms.RandomHorizontalFlip(), # 水平翻转\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4244, 0.4146, 0.3836), (0.2539, 0.2491, 0.2420)) # normalization\n",
    "    ])\n",
    "\n",
    "aug_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4244, 0.4146, 0.3836), (0.2539, 0.2491, 0.2420)) # normalization\n",
    "    ])\n",
    "\n",
    "trainingdata = torchvision.datasets.CIFAR10('./CIFAR10',train=True,download=True,transform=aug_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "3983cfe844f847899487b2745a203a9b",
      "1121692d91114d58b3db79e41b0a24c9",
      "8148f05b38d94ec19351ac920b70acba",
      "af7b660f147d4d1d8796d3419673c9b7",
      "0130588af6254c76a2c8c382288cfcea",
      "fb3e769eb8324af3b77041879c9b54cf",
      "accf52fe298b4716af9d9c351e7326dc",
      "1d40f4bf0c0e48709cdec5f80069ed2f",
      "321ea7fa0b4d4c9dab9ed5231954e54c",
      "a66b114e4595419f84ac44a676a1ca61",
      "4aa5668c8eaa49f88148d499240b6ea5"
     ]
    },
    "id": "1lqsbqYCMja7",
    "outputId": "3b4aa629-06a0-480a-afec-dcdb971e4bf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def get_mean_and_std(dataset):\n",
    "  '''Compute the mean and std value of dataset.'''\n",
    "  dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "  mean = torch.zeros(3)\n",
    "  std = torch.zeros(3)\n",
    "  print('==> Computing mean and std..')\n",
    "  for inputs, targets in dataloader:\n",
    "      for i in range(3):\n",
    "          mean[i] += inputs[:,i,:,:].mean()\n",
    "          std[i] += inputs[:,i,:,:].std()\n",
    "  mean.div_(len(dataset))\n",
    "  std.div_(len(dataset))\n",
    "  return mean, std\n",
    "\n",
    "def load_data(is_train,aug,batch_size):\n",
    "  dataset = torchvision.datasets.CIFAR10('./CIFAR10',train=is_train,download=True,transform=aug)\n",
    "#   mean, std = get_mean_and_std(dataset)\n",
    "#   print(mean, std)\n",
    "  dataloader = torch.utils.data.DataLoader(dataset,batch_size=batch_size,shuffle=is_train)\n",
    "  return dataloader\n",
    "\n",
    "batch_size = 128 # param\n",
    "trainDataLoader = load_data(is_train=True,aug=aug_train,batch_size=batch_size)\n",
    "testDataLoader = load_data(is_train=False,aug=aug_test,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-TD4UKtgzXbh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32]) 6\n",
      "[[[-0.9147032  -0.38956204  0.0274618  ...  0.01201648  0.18191507\n",
      "    0.15102442]\n",
      "  [-0.32778072 -0.03431951  0.10468844 ... -0.21966343  0.1973604\n",
      "    0.2591417 ]\n",
      "  [-0.09610081  0.29003236  0.24369638 ... -0.6366873  -0.51312464\n",
      "   -0.32778072]\n",
      "  ...\n",
      "  [ 1.0931895   1.2321974   1.448432   ...  0.22825105  0.66072035\n",
      "    1.6646665 ]\n",
      "  [ 1.2013068   1.3248694   1.3866507  ... -0.38956204 -0.17332745\n",
      "    1.1704161 ]\n",
      "  [ 1.3866507   1.2785335   1.1549708  ... -0.8529219  -0.8065859\n",
      "    0.7997283 ]]\n",
      "\n",
      " [[-1.2393323  -0.8772444  -0.53089947 ... -0.5151565  -0.3419841\n",
      "   -0.3419841 ]\n",
      "  [-0.8142726  -0.6725861  -0.5623854  ... -0.68832904 -0.32624117\n",
      "   -0.29475525]\n",
      "  [-0.6411001  -0.42069885 -0.45218474 ... -1.003188   -0.9244732\n",
      "   -0.76704377]\n",
      "  ...\n",
      "  [ 0.57110703  0.6813077   0.9804237  ... -0.21604052  0.19327614\n",
      "    1.2323109 ]\n",
      "  [ 0.6025929   0.74427944  0.8229942  ... -0.83001554 -0.68832904\n",
      "    0.6655647 ]\n",
      "  [ 0.87022305  0.8072512   0.6340788  ... -1.1291317  -1.1763605\n",
      "    0.42942047]]\n",
      "\n",
      " [[-1.4554853  -1.212413   -0.92072594 ... -0.9045211  -0.7748825\n",
      "   -0.7748825 ]\n",
      "  [-1.1800033  -1.1313888  -1.0503646  ... -1.017955   -0.80729216\n",
      "   -0.7748825 ]\n",
      "  [-1.0341598  -0.9531356  -1.0017501  ... -1.1800033  -1.212413\n",
      "   -1.1475936 ]\n",
      "  ...\n",
      "  [-0.17530379 -0.49940035 -0.4831955  ... -0.4183762  -0.22391827\n",
      "    0.6835522 ]\n",
      "  [-1.0989791  -1.1800033  -1.0341598  ... -1.0341598  -1.0341598\n",
      "   -0.06186999]\n",
      "  [-1.1637985  -1.1475936  -1.0341598  ... -1.2610275  -1.4716902\n",
      "   -0.45078588]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAavElEQVR4nO2deZRV1ZXGvy2DpRSxAigQMJZBG4NGCakWunHWGIcV0TbRGFtZq03IIJp0Bts2K8Y2dpbabYy2xnQ5rBAbZzEYY4wGDQ6JaIEFgkiLWLQQBoeUMogK7v7jPlYX9t1fVd16dR/mfL+1atWr89W+Z9d9d9d97+y39zF3hxDiL58dau2AEKIcFOxCJIKCXYhEULALkQgKdiESQcEuRCIo2BPEzEabWauZrTOzc2vtjyiHvrV2QNSE8wA84u5ja+2IKA/d2dNkDwCL8gQz61OyL6IkFOyJYWYPAzgcwDVmtt7MbjGz68zsfjPbAOBwM/u4mf3ezNrNbJGZndDBfrCZ/crM3jSzp83sEjN7vGZ/kOgyCvbEcPcjADwGYKq71wN4B8AXAfwrgIEA5gD4FYAHAewG4BwA081sdOUQ1wLYAGAYgMmVL/EBQMEuAGCmuz/h7u8BGAugHsCl7v6Ouz8M4D4Ap1Ve4p8M4AfuvtHdnwMwrWZei26hYBcA8HKHxx8B8HIl8LeyHMAIALsiW9R9ObAV2zEKdgEAHUsf/wRgdzPreG18FMBKAK8A2AxgZAdt9953T1QDBbt4P3MAbARwnpn1M7PDAHwWwG3uvgXADAAXmdnOZrYPgDNr5qnoFgp2sQ3u/g6y4D4WwKsAfgrgTHd/vvIrUwHsAmA1gJsB3Arg7Rq4KrqJqXmF6AlmdhmAYe6uVfntHN3ZRbcws33MbH/LOBDAWQDuqbVfonP0cVnRXQYie+n+EQBrAFwBYGZNPRJdQi/jhUgEvYwXIhFKfRlvZoVeRlgwvksBG4AvHTOtiPPvdf4rubC/bQvR+hWw2Uy0d4nGLp66YJw9L/2JtpFoRWDVPjsR7S2iMR/ZXTU6JvMjuq7eBbDFPfc09yjYzewYAFchO3c3uPulPTleRHQRHE5s2B/2ItHaiMaCIuLNAjYAcAjR3iDa0GB8PbF5jWgriDaEaKODcfa8NBKtlWjsH1kU1PXEZmxBP+YTLfrnBwTlhwD2JjabgvHlxKbwy/jK56SvRZaPHYPss9Njih5PCNG79OQ9+4EAlrr7ssoHMW4DMKk6bgkhqk1Pgn0Eti2CWFEZ2wYzm2JmLWbW0oO5hBA9pNcX6Ny9GUAzUHyBTgjRc3pyZ1+JbSueRlbGhBDbIT25sz8NYG8z2xNZkH8BWceTqjM4GGern2z1eW1BP8YF4w3EZjbRWHrtM0SbS7TVwTjLQLAswwFEY6v40eozW8Fnz1kD0dgdJspOsNVxloFgjCRaO9GibAILzmiuVcSmcLC7+2Yzmwrgt8gyHDe5e5RFEELUmB69Z3f3+wHcXyVfhBC9iD4uK0QiKNiFSAQFuxCJoGAXIhG2m+YVxxJtQzDOUjWs0IHB0nINwXjRCrXXiXYH0djfPY9oETsWsAH4OY5SW/Wk7G0p+cjVPmSuBqK1BeMsFRkVmQDAc0SrNkWeS4bu7EIkgoJdiERQsAuRCAp2IRJBwS5EIpTbgw5xiylWmLBXMP4qsWErqqzwg63GR6vgbK6isOL/avdjY333lhU85oJIKFjk/FdEO5Vo0QXOimfKXHEvE93ZhUgEBbsQiaBgFyIRFOxCJIKCXYhEULALkQilpt52RtzTrIgjzIalVliajxXk7BeMzyE2+xMtTE+h+um1DwLnEI2dY5ZKnRgU3qwgKUD2vHyQ0Z1diERQsAuRCAp2IRJBwS5EIijYhUgEBbsQiVBq6q0/crZ5rcB6jEXb8bCqt0OJxlI10fZJbL7RxOZ6opUJLTb7fCwdeWesPVzUmQC2rdXzRPsUO2jwhzcSk92IVnTrsKOJ9mAVbRg9CnYzawOwDllfxc3u3tST4wkheo9q3NkPd3d2kxVCbAfoPbsQidDTYHcAD5rZXDObkvcLZjbFzFrMrIV1RBFC9C49fRl/kLuvNLPdADxkZs+7+6Mdf8HdmwE0A8Ags4JNiYQQPaVHd3Z3X1n5vhbAPQAOrIZTQojqY+7FbrZmNgDADu6+rvL4IQAXu/sDkc1gMz8+0NrJXNFWPQ3EZjDRWNUb2xYoSuexdN2tRCsTJ9susX2cFq6LtU8U9qY8vlbAhj2frLnocqINI9qoYJxdi5GPywC85fnPdk9exg8FcI+ZbT3OLSzQhRC1pXCwu/syxOXpQojtDKXehEgEBbsQiaBgFyIRFOxCJEKpVW9D+gOTg7K32S/Fdq8F4yyFxj6tx6re2IpjVACwvaTXGHeTDGs7Sa+xxp3jiDavM4dKosgFPoRo7Nphdu0FjjmA2ESVfixtqDu7EImgYBciERTsQiSCgl2IRFCwC5EIpa7Gow/CoosRO8Vmo9/KH28gU7GVetZWZ+SusTbzFWJYIv9ItOjvbic2bGulBqKx3m9RwdPFZ+wZ2vzo5jgl8z0yFyNa6W4nNuzaYSvurEiGaVEQMj8aunksQHd2IZJBwS5EIijYhUgEBbsQiaBgFyIRFOxCJEKpqbe33gaeb8vXFgXpNSD+cH87mWs+0ZYR7fMkvRalcXYmx7ucaEuI9vWPx9owUo0x64X88VHkeFgcS2cdHGutC2Nt7M8PyReOGhPaXHDUz0Jt1uR4LrYNVZQqK5qaZSm09URj80VPJ7OJ5tpCbHRnFyIRFOxCJIKCXYhEULALkQgKdiESQcEuRCIU3v6pCB8x8y8F2i7Erv7D+ePNf45tivZA60O0KK3xXWJz+UwiXkO0qUT77Fmxdue0/PHD9o9tNpFSvzqyN9Rdd8faQcH4itik9dJY+9FjsbYmlhC0PKS95Fg+mpwNase0KI3G5or8vwvA2mD7p07v7GZ2k5mtNbOFHcYGmdlDZvZC5XsQjkKI7YWuvIz/OYBj3jd2PoBZ7r43gFmVn4UQ2zGdBntlv/XX3zc8CcDW14vTAJxYXbeEENWm6Mdlh7r7qsrj1ch2dM3FzKYAmALw9+VCiN6lx6vxnq3what87t7s7k3u3sQ+Qy6E6F2KBvsaMxsOAJXva6vnkhCiN+hS6s3MGgHc5+77VX7+NwCvufulZnY+gEHufl5nxxmxg/nZwRuHPu/GdouC8Zs7m7AkXspNdGQ0vkcMLyTa50g6bH/2vzUqRbud2JC9t6jGCOrDnCS9XibtHG/4Yyi13heXTN7xTP44q2xbTrTBRNuPaGxbpqi6jVXYDQvGrwWwsgept1sB/BHAaDNbYWZnAbgUwKfN7AUAR1V+FkJsx3S6QOfupwXSkVX2RQjRi+jjskIkgoJdiERQsAuRCAp2IRKh1IaTfQEMjmYkqbeGXvClCCcF440PBM0VAeCOVaF01Q+D7pAAvvGl47ro1fuJEkAsMVSUR4gWJLeM/F0fHRBrF8fS2IvfCLXXxjXkjl8VpOQAgHhBWUo0luorknqLKuXeJja6swuRCAp2IRJBwS5EIijYhUgEBbsQiaBgFyIRSk29uQObggKlIvta9QaDiDZj2rh84ejZoc15FpfEnckcWR2n5dDQHGsfmsKOWmUOL3EuRtwWpW5C/vgGknpjQfEa0Yo2nIwShywmosq8d4iN7uxCJIKCXYhEULALkQgKdiESQcEuRCKUuxqPeNuaBmLHtuopwoeI9sTBRDxzbiBsCE2i7YcAYL9ziNiXlEF86FRiuL3Qljs6/cIxocXpF7N+d2G3csrgffLHT/h8bLOJLINvIM3k2snWVk8sjrXIbGRsgokfzx9fSE6h7uxCJIKCXYhEULALkQgKdiESQcEuRCIo2IVIhFJTb1sQf+i/gdjVV9kPtuvSPo/O6P4Bbzk5lL7x18Tu6ouI+IPu+9Eb/OnWWHv1uVjbf8/c4Uknki2eNpKTtfP/xBphc9AYrm+0SxaADSTXu5lEzCiSKxtGLuInn84fn0BOx4CG/PEdSfqvK9s/3WRma81sYYexi8xspZm1Vr6KdkcUQpREV17G/xzAMTnjV7r72MrX/dV1SwhRbToNdnd/FMDrJfgihOhFerJAN9XMFlRe5n84+iUzm2JmLWbWsrEHkwkhekbRYL8OwCgAYwGsAnBF9Ivu3uzuTe7etHPByYQQPadQsLv7Gnff4u7vAbgewIHVdUsIUW0Kpd7MbLi7b93X6CQAJJHxf7wC4D8DbS9iF2Ut2H+Yp4j27dm3EDXa5ClmfcuCUKtvYpYF02v+m1h74dnc4RVPPhyazLzmt6FWTxoANjbG2qGX5Pfrqx93bWyETxCtGA1t+eNLSBUa23apnWit5JhB8R0A4PTT8sfnkKzn48F4vBFWF4LdzG4FcBiAIWa2AtkVepiZjUVWtdoG4CudHUcIUVs6DXZ3z/u/c2Mv+CKE6EX0cVkhEkHBLkQiKNiFSAQFuxCJUGrV2wAA4wON1EKFDSdHEZvZNwZbNQHAIUGuoyD1de2h1t4S2zWA5FZ8XShN3CFOfhwQjLfFM2FyfoEaAGA8SR1eeGesra6blzt+6gx2yTUSrRhL2vLHZxEb5mFwOADAm0QjyVJ8P6hUu5LYFEF3diESQcEuRCIo2IVIBAW7EImgYBciERTsQiRCqak3IxO2E7vIppHY1P1DtC9bT8jvXrhixVuhxdzH4qNN+sUXY3Hz7qE0OLYKU2/jLbY5+ahYu/G/Yq2d+LEkSjnee0lsdMKx5Igkh0l2A2wPmkA+l18cCADoQ2YaTTSyRRzyE5EZ7azMLiBKLD9PbHRnFyIRFOxCJIKCXYhEULALkQgKdiESodTV+B0Qr1iSVmdYE4yfTlqW3TguXn7+zN/H2zWN/NL58UGffzR3eMiQ+DQesDfZS6iOnP4hu4bS5J1eDrWlQWJgL4+n+vVdsfZanGgAa6+3OnDx3El/CG0O+HD8nK1sJ5ORKqr1wQVHOx3Hpx51ZIunPciq+pFkusuD81+XtzVLhWBXKyx7KbbRnV2IRFCwC5EICnYhEkHBLkQiKNiFSAQFuxCJ0JUdYXYH8AsAQ5HtANPs7leZ2SAAtyOrR2kDcIq7/5kdqz+KdRmLklebVsc2M1+JtfnP3B1qV78ap4aijajqjpoUWjR+lZRHrI9TaK/+LD/NB7Cyjzi1SU4V6ttjbd9wf15ewDGApOwi1pOrZ0diN4c811Hatons8rWQ7EU2j/zNbWQTtOMnxBo+mn+SR58Yn5Abn8wfXxf0swO6dmffDODb7j4GwAQAZ5vZGADnA5jl7nsj699HEtRCiFrTabC7+yp3n1d5vA7AYgAjAEwCMK3ya9MAnNhLPgohqkC33rObWSOATwKYA2Boh51cVyN7mS+E2E7pcrCbWT2AuwF80923aZHt7o7s/Xye3RQzazGzlo09clUI0RO6FOxm1g9ZoE939xmV4TVmNryiDwewNs/W3Zvdvcndm+jnkYUQvUqnwW5mhmyL5sXu/uMO0r0AJlceTwYws/ruCSGqRVeq3iYCOAPAs2bWWhm7AMClAO4ws7MALAdwSmcHcsRpo32J3b4D88eXvBrbHE+O10C09sdXhdqmIK81bAjJxxx3Way9G881pPk7sR/3nRBqa4KUF+tb9yKpiBtPyhGHNcRafXBlzY93tcIPY6nqnHFYrK0muc3Xf0m0tljbdyrzJv+k7EvKCl+PegOSS7HTYHf3x5H1isyDVe4JIbYj9Ak6IRJBwS5EIijYhUgEBbsQiaBgFyIRSm046YgzA2wHnCVBuqY+SMkBwMj8AjUAwGDSoLBhH+LIhL1zh1fc9ULsxzmkJKvft8hkraEyeeFVsdld1+QOX/vV2MdFJPXW8G6sTSRXTyTdGJv0CkcHTUn7tsU2fR+ItUGLY+3sg2NtwmGx9uuv5+f6jic7ZX2/MX/8BlI5qDu7EImgYBciERTsQiSCgl2IRFCwC5EICnYhEsGyvhPlsJuZfy7QWA4wKkJqIDbjd4q10aShYD1J2Y08LP+gKx6IuyvObouPd/oN40Jt1k/mhVod6WE5OtiLjO3nNodUopHCwrC5JQC0B+OsWWYj0fYg2hvkuV7fkD++NC44DJtUAsB4ov10ERHHHBFK5/Z/OHf86ndiGzyXb9N0CtCy0HML13RnFyIRFOxCJIKCXYhEULALkQgKdiESodTV+FFm/qNAm07sotXRA4hNI9H2iJpsIdrgKePV4FTNJTZtRPsKKeT51NhYm/5YrEW+sEKj08lqdl9iOIsV0ATjh5LtpIaSk7+S7V9FCpsWBqvu7DljWYbmLxO75j1j8Q8vhdKoifnjLz5BHPnb/LmamlaipeVtrcYLkTIKdiESQcEuRCIo2IVIBAW7EImgYBciETrtQWdmuwP4BbItmR1As7tfZWYXAfgygK1N1i5w9/vZsQYOBI6MtrRZGNvNDNq4LSdzNRBtR5IyepvYRUUhLEPCtrVqIwUoS0l6jRVqRLs1bSE28+M6HlpQNJ7YvRiMzyQ90g4gGrtQ+7bH2rAgvTmSnPuh/WKt7ickd0jKfA4N0msAsKyAzWyP5oov7q40nNwM4NvuPs/MBgKYa2YPVbQr3f3fu3AMIUSN6cpeb6sArKo8XmdmiwGM6G3HhBDVpVvv2c2sEcAnAcypDE01swVmdpOZsdc3Qoga0+VgN7N6AHcD+Ka7vwngOgCjAIxFdue/IrCbYmYtZtby2js9d1gIUYwuBbuZ9UMW6NPdfQYAuPsad9/i7u8BuB7AgXm27t7s7k3u3jS4f7XcFkJ0l06D3cwM2UYei939xx3Gh3f4tZNA19OFELWmK6vxEwGcAeBZM2utjF0A4DQzG4tsrb8NwFc6nWxXYMhX87WTl8Z2Q+7LH5/zx85mzGcv1rOMpJOitNYwMhcpyKIVdiuJxgrAohRbH2LD+sKx88H+tojZRIvSdUB2EUbsQv6Auob88edJ6m062fLqn1pJfnBhrD0aWxWzaX45f5zsNtaV1fjHAeSVzNGcuhBi+0KfoBMiERTsQiSCgl2IRFCwC5EICnYhEqErqbfqsTOAoOqtL9mS6chgS6OJB8U2rU/G2nymxVJY9fYpYsO2LWon2i5EK5LqY0/0aKLVkeac7aR6cFjw4enxJHP1W+JHC9EmkFTZkqDh5G/I8RjfIjnAL55T8KAFaAk+1bKRNAjVnV2IRFCwC5EICnYhEkHBLkQiKNiFSAQFuxCJUG7q7U0Avws0knrD2PzhumNikwmk4HbC72NtVlBhBwCznskfZ9VrbI+1DURjsL3Ioid0ALFh1WabSXptMLFrD1JsUeVgZxqrlmMNOJ8iWhFYxWETSQXjP6rrRzTXzr+ObXRnFyIRFOxCJIKCXYhEULALkQgKdiESQcEuRCKUm3pzxLmodmJ3cDBO9uTCEcW0I4OGmABw5C/zx1eQNN/6duIHaZS4idgtJ805hwYlcfUNsc3ctlh7cXGssYaTUSUgS0VGVYUAEBQ+AuCVhdF8C4gNo/my4bF4yrWhdNulfxdqVwcp3XM/SRw5ZUb++OXfDU10ZxciERTsQiSCgl2IRFCwC5EICnYhEsHcSaUDADOrQ7YTzY7IVu/vcvcfmNmeAG5DVg8xF8AZ7k73aW3aw7zle4HICmGiZV/WjI3tPPf7WKp2IQwrQHmDaAy2ol2kEIb5wbaGYoUw0TlZRGxYDzq2Ur8P0apdCHMa0W65Pdbs1Or64cFcTf8MtLzouZ0Du3JnfxvAEe5+ALL6s2PMbAKAywBc6e57AfgzgLMK+CyEKIlOg90ztlYf9qt8ObJs9V2V8WkATuwNB4UQ1aGr+7P3qezguhbAQ8hKoNvdfeurvBUARvSKh0KIqtClYHf3Le4+FtkHmQ4Ef5u0DWY2xcxazKzlFdadQAjRq3RrNd7d2wE8AuBvADSY2db1oJEIthR392Z3b3L3pl3ZSpYQolfpNNjNbFcza6g83gnApwEsRhb0n6v82mQAM3vJRyFEFehKIcxwANPMrA+yfw53uPt9ZvYcgNvM7BIAzwC4sdMjfQjAUYHWTuxa84c3kfRa4e2fyFZCUfqHZQ1ZeoqltdgT017gmOwd1L5EayDbP20iWdshwfZPy8n2T+yFH/NxAtGigpzriA2DZXtbHi940AJEc20kT3Snwe7uCwD8v/obd1+G7P27EOIDgD5BJ0QiKNiFSAQFuxCJoGAXIhEU7EIkQqdVb1WdzOwVAMsrPw4BL2YqC/mxLfJjWz5ofuzh7rvmCaUG+zYTm7W4e1NNJpcf8iNBP/QyXohEULALkQi1DPbmGs7dEfmxLfJjW/5i/KjZe3YhRLnoZbwQiaBgFyIRahLsZnaMmS0xs6Vmdn4tfKj40WZmz5pZq5m1lDjvTWa21swWdhgbZGYPmdkLle9BkWiv+3GRma2snJNWMzuuBD92N7NHzOw5M1tkZt+ojJd6TogfpZ4TM6szs6fMbH7Fj3+pjO9pZnMqcXO7mfXv1oHdvdQvAH2Q9bD7GID+AOYDGFO2HxVf2gAMqcG8hwAYB2Bhh7HLAZxfeXw+gMtq5MdFAL5T8vkYDmBc5fFAAP8NYEzZ54T4Ueo5AWAA6iuP+wGYg6xs/w4AX6iM/wzA17pz3Frc2Q8EsNTdl3nWZ/42AJNq4EfNcPdHAbz+vuFJyLr0AiV16w38KB13X+Xu8yqP1yHrhDQCJZ8T4kepeEbVOzrXIthHAHi5w8+17EzrAB40s7lmNqVGPmxlqLuvqjxeDWBoDX2ZamYLKi/ze/3tREfMrBFZs5Q5qOE5eZ8fQMnnpDc6Oqe+QHeQu48DcCyAs83skFo7BGT/2ZH9I6oF1wEYhWxDkFUArihrYjOrB3A3gG+6+5sdtTLPSY4fpZ8T70FH54haBPtKALt3+DnsTNvbuPvKyve1AO5BbdtsrTGz4QBQ+b62Fk64+5rKhfYegOtR0jkxs37IAmy6u8+oDJd+TvL8qNU5qczdjm52dI6oRbA/DWDvyspifwBfAHBv2U6Y2QAzG7j1MYCjwXeI623uRdalF6hht96twVXhJJRwTszMkDUsXezuP+4glXpOIj/KPie91tG5rBXG9602HodspfNFAN+rkQ8fQ5YJmI9sv8HS/ABwK7KXg+8ie+91FrJGtLMAvADgdwAG1ciPmwE8C2ABsmAbXoIfByF7ib4AWS/h1so1Uuo5IX6Uek4A7I+sY/MCZP9YLuxwzT4FYCmAOwHs2J3j6uOyQiRC6gt0QiSDgl2IRFCwC5EICnYhEkHBLkQiKNiFSAQFuxCJ8L92Im/+4hoGfgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "image,label = trainingdata[0]\n",
    "image_= np.array(image).copy()\n",
    "print(image.shape, label)\n",
    "print(image_)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.imshow(image.numpy().transpose(1,2,0))\n",
    "plt.title(str(classes[label]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jo4vcA1BwajW"
   },
   "outputs": [],
   "source": [
    "# trainDataLoader = torch.utils.data.DataLoader(trainingdata,batch_size=batch_size,shuffle=True)\n",
    "# testDataLoader = torch.utils.data.DataLoader(testdata,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "# images, labels = iter(trainDataLoader).next()\n",
    "# plt.figure(figsize=(17,8))\n",
    "# for index in np.arange(0,5):\n",
    "#   plt.subplot(1,5,index+1)\n",
    "#   plt.imshow(images[index].numpy().transpose(1,2,0))\n",
    "#   plt.title(str(classes[labels[index]]))\n",
    "\n",
    "def get_mean_and_std(dataset):\n",
    "  '''Compute the mean and std value of dataset.'''\n",
    "  dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "  mean = torch.zeros(3)\n",
    "  std = torch.zeros(3)\n",
    "  print('==> Computing mean and std..')\n",
    "  for inputs, targets in dataloader:\n",
    "      for i in range(3):\n",
    "          mean[i] += inputs[:,i,:,:].mean()\n",
    "          std[i] += inputs[:,i,:,:].std()\n",
    "  mean.div_(len(dataset))\n",
    "  std.div_(len(dataset))\n",
    "  return mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YDBTjSf2jDNm"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_planes, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = in_planes\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_planes)\n",
    "        self.layer1 = self._make_layer(block, in_planes, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, in_planes*2, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, in_planes*4, num_blocks[2], stride=2)\n",
    "#         self.layer4 = self._make_layer(block, in_planes*8, num_blocks[3], stride=2)\n",
    "#         self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "#         self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "#         self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "#         self.layer4 = self._make_layer(block, self.in_planes*8, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(x.shape)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "#         print(out.shape)\n",
    "        out = self.layer1(out)\n",
    "#         print(out.shape)\n",
    "        out = self.layer2(out)\n",
    "#         print(out.shape)\n",
    "        out = self.layer3(out)\n",
    "#         print(out.shape)\n",
    "#         out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "#         print(out.shape)\n",
    "        out = out.view(out.size(0), -1)\n",
    "#         print(out.shape)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu') # weight initialization\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)\n",
    "            elif isinstance(m,nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "            elif isinstance(m,nn.Linear):\n",
    "                nn.init.normal_(m.weight,std=1e-3)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)\n",
    "\n",
    "def project1_model():\n",
    "#     return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "#     return ResNet(BasicBlock, [2, 2, 2])\n",
    "    return ResNet(64, BasicBlock, [3, 3, 3])\n",
    "\n",
    "# model1 = nn.Sequential(project1_model(), nn.AdaptiveAvgPool2d((1,1)), nn.Flatten(), nn.Linear(512, 10)).cuda()\n",
    "model1 = project1_model().cuda()\n",
    "model1.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FDnI9zbyLK6B",
    "outputId": "4a1b7b4e-5d52-42d6-8563-500023c3acae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4335434\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    # torch.numel() returns number of elements in a tensor\n",
    "\n",
    "print(count_parameters(model1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, current_epoch,max_epoch,lr_min=0,lr_max=0.1,warmup=True):\n",
    "    warmup_epoch = 10 if warmup else 0\n",
    "    if current_epoch < warmup_epoch:\n",
    "        lr = lr_max * current_epoch / warmup_epoch\n",
    "    else:\n",
    "        lr = lr_min + (lr_max-lr_min)*(1 + cos(pi * (current_epoch - warmup_epoch) / (max_epoch - warmup_epoch))) / 2\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbLtFYydjoIx",
    "outputId": "0321ff7b-c60c-4099-f5fb-4a9536f10244"
   },
   "outputs": [],
   "source": [
    "# X = torch.rand(size=(1, 3, 32, 32)).cuda()\n",
    "# for layer in model1:\n",
    "#   X = layer(X)\n",
    "#   print(layer.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "j5xklXYe6gRe",
    "outputId": "b846ff14-cc67-4bdc-d6bb-f727fa580bcc",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read model from checkpoint\n",
      "Restart from epoch 500\n",
      "Epoch 501, Train loss 1.5871391956411695e-05, Test loss 0.46993549363805526, Train accuracy 100.0, Test accuracy 94.03678797468355, Cost 70.38088822364807 s\n",
      "Epoch 502, Train loss 1.6447927019012416e-05, Test loss 0.46884004465198215, Train accuracy 100.0, Test accuracy 94.03678797468355, Cost 69.68887448310852 s\n",
      "Epoch 503, Train loss 1.598956839101967e-05, Test loss 0.4697809291036823, Train accuracy 100.0, Test accuracy 94.06645569620254, Cost 69.6357524394989 s\n",
      "Epoch 504, Train loss 1.7212922008577085e-05, Test loss 0.4673157896893688, Train accuracy 100.0, Test accuracy 94.07634493670886, Cost 69.56810975074768 s\n",
      "Epoch 505, Train loss 1.6825974035258326e-05, Test loss 0.46770284273013285, Train accuracy 100.0, Test accuracy 94.09612341772151, Cost 69.96002650260925 s\n",
      "Model saved in epoch 505\n",
      "Epoch 506, Train loss 1.4656667233234213e-05, Test loss 0.4685265900260663, Train accuracy 100.0, Test accuracy 94.04667721518987, Cost 69.8748950958252 s\n",
      "Epoch 507, Train loss 1.0536467907349446e-05, Test loss 0.4688447644769014, Train accuracy 100.0, Test accuracy 94.08623417721519, Cost 70.02505159378052 s\n",
      "Epoch 508, Train loss 8.25701631669026e-06, Test loss 0.46908302300998683, Train accuracy 100.0, Test accuracy 94.09612341772151, Cost 70.07799506187439 s\n",
      "Epoch 509, Train loss 2.3798299233704165e-05, Test loss 0.47774349138895167, Train accuracy 100.0, Test accuracy 94.06645569620254, Cost 70.20272850990295 s\n",
      "Epoch 510, Train loss 1.3442240187131534e-05, Test loss 0.477481810493937, Train accuracy 100.0, Test accuracy 94.10601265822785, Cost 69.96638345718384 s\n",
      "Model saved in epoch 510\n",
      "Epoch 511, Train loss 1.8695821624041128e-05, Test loss 0.4734854034230679, Train accuracy 100.0, Test accuracy 94.06645569620254, Cost 70.03202080726624 s\n",
      "Epoch 512, Train loss 1.0858734808282628e-05, Test loss 0.4722758011680238, Train accuracy 100.0, Test accuracy 94.06645569620254, Cost 70.01405334472656 s\n",
      "Epoch 513, Train loss 9.62206644174467e-06, Test loss 0.47258108590222614, Train accuracy 100.0, Test accuracy 94.08623417721519, Cost 70.17746305465698 s\n",
      "Epoch 514, Train loss 6.370056596410495e-06, Test loss 0.47231158706112, Train accuracy 100.0, Test accuracy 94.07634493670886, Cost 70.1648600101471 s\n",
      "Epoch 515, Train loss 2.9008152381811363e-05, Test loss 0.4826302261952358, Train accuracy 100.0, Test accuracy 93.96756329113924, Cost 70.01524829864502 s\n",
      "Model saved in epoch 515\n",
      "Epoch 516, Train loss 1.230503738468788e-05, Test loss 0.4787426354670072, Train accuracy 100.0, Test accuracy 93.96756329113924, Cost 69.82168436050415 s\n",
      "Epoch 517, Train loss 0.0001967263742999088, Test loss 0.47851088942511927, Train accuracy 99.99600383631713, Test accuracy 94.02689873417721, Cost 70.06825661659241 s\n",
      "Epoch 518, Train loss 0.000288081956473539, Test loss 0.5078336558528717, Train accuracy 99.98601342710998, Test accuracy 93.78955696202532, Cost 70.10166430473328 s\n",
      "Epoch 519, Train loss 0.0001277687306144274, Test loss 0.5006602451535342, Train accuracy 99.99600383631713, Test accuracy 93.86867088607595, Cost 69.97174787521362 s\n",
      "Epoch 520, Train loss 4.261230594690462e-05, Test loss 0.4965225604798975, Train accuracy 100.0, Test accuracy 93.94778481012658, Cost 69.95490527153015 s\n",
      "Model saved in epoch 520\n",
      "Epoch 521, Train loss 3.7575141315069596e-05, Test loss 0.4986641205422863, Train accuracy 100.0, Test accuracy 93.9181170886076, Cost 70.00465369224548 s\n",
      "Epoch 522, Train loss 6.773419798943249e-05, Test loss 0.5029360655742355, Train accuracy 100.0, Test accuracy 93.8488924050633, Cost 69.97776317596436 s\n",
      "Epoch 523, Train loss 0.00011283202760851285, Test loss 0.501607442463312, Train accuracy 99.99800191815856, Test accuracy 93.80933544303798, Cost 69.70381760597229 s\n",
      "Epoch 524, Train loss 9.542709507814145e-05, Test loss 0.4928417665105832, Train accuracy 99.99800191815856, Test accuracy 93.85878164556962, Cost 69.98047518730164 s\n",
      "Epoch 525, Train loss 0.00010850749812735899, Test loss 0.5177933637382863, Train accuracy 99.99600383631713, Test accuracy 93.62143987341773, Cost 70.06387305259705 s\n",
      "Model saved in epoch 525\n",
      "Epoch 526, Train loss 0.000178918424417945, Test loss 0.49676727390364755, Train accuracy 99.99600383631713, Test accuracy 93.8488924050633, Cost 69.85160207748413 s\n",
      "Epoch 527, Train loss 0.00011288303052225066, Test loss 0.49555223972737034, Train accuracy 99.99800191815856, Test accuracy 93.92800632911393, Cost 70.0517725944519 s\n",
      "Epoch 528, Train loss 0.0005788245619658384, Test loss 0.5776228849080545, Train accuracy 99.98201726342711, Test accuracy 93.28520569620254, Cost 70.02944374084473 s\n",
      "Epoch 529, Train loss 0.005432563925401236, Test loss 0.5584257712847069, Train accuracy 99.83615728900256, Test accuracy 93.14675632911393, Cost 69.8199074268341 s\n",
      "Epoch 530, Train loss 0.013336358829926731, Test loss 0.5641173762799818, Train accuracy 99.59119245524296, Test accuracy 92.02927215189874, Cost 70.02169442176819 s\n",
      "Model saved in epoch 530\n",
      "Epoch 531, Train loss 0.013517572154562884, Test loss 0.5076574883129024, Train accuracy 99.57640664961637, Test accuracy 92.57318037974683, Cost 70.06216669082642 s\n",
      "Epoch 532, Train loss 0.007067225387018575, Test loss 0.46705452135846587, Train accuracy 99.76222826086956, Test accuracy 92.79074367088607, Cost 69.76081919670105 s\n",
      "Epoch 533, Train loss 0.010902103300153626, Test loss 0.475367389336417, Train accuracy 99.65033567774935, Test accuracy 92.71162974683544, Cost 69.84148097038269 s\n",
      "Epoch 534, Train loss 0.008096706685665197, Test loss 0.4595852760197241, Train accuracy 99.74904092071611, Test accuracy 92.65229430379746, Cost 69.93526077270508 s\n",
      "Epoch 535, Train loss 0.00837570936707782, Test loss 0.4115766845171965, Train accuracy 99.73225703324808, Test accuracy 93.1368670886076, Cost 70.00050163269043 s\n",
      "Model saved in epoch 535\n",
      "Epoch 536, Train loss 0.0066975312019471895, Test loss 0.4042994510618192, Train accuracy 99.78220907928389, Test accuracy 93.16653481012658, Cost 70.07573199272156 s\n",
      "Epoch 537, Train loss 0.003197179803650764, Test loss 0.4426358512873891, Train accuracy 99.89609974424552, Test accuracy 93.09731012658227, Cost 70.14548659324646 s\n",
      "Epoch 538, Train loss 0.0031990414543268536, Test loss 0.4265837886288196, Train accuracy 99.89609974424552, Test accuracy 93.45332278481013, Cost 70.07787346839905 s\n",
      "Epoch 539, Train loss 0.0038376296204281173, Test loss 0.4203867850047124, Train accuracy 99.8701246803069, Test accuracy 93.40387658227849, Cost 70.05004835128784 s\n",
      "Epoch 540, Train loss 0.004500155751384343, Test loss 0.4138527486143233, Train accuracy 99.85414002557545, Test accuracy 93.45332278481013, Cost 69.89470982551575 s\n",
      "Model saved in epoch 540\n",
      "Epoch 541, Train loss 0.005436269934303858, Test loss 0.4082579658944396, Train accuracy 99.8261668797954, Test accuracy 93.42365506329114, Cost 69.96290397644043 s\n",
      "Epoch 542, Train loss 0.003463094341016811, Test loss 0.4325432782591898, Train accuracy 99.88810741687979, Test accuracy 93.19620253164557, Cost 70.13518810272217 s\n",
      "Epoch 543, Train loss 0.0037289955813470154, Test loss 0.42626809262776677, Train accuracy 99.8701246803069, Test accuracy 93.30498417721519, Cost 70.0840675830841 s\n",
      "Epoch 544, Train loss 0.005812904102424134, Test loss 0.44138164252420015, Train accuracy 99.8261668797954, Test accuracy 92.7314082278481, Cost 70.0428318977356 s\n",
      "Epoch 545, Train loss 0.004018420657747348, Test loss 0.4098163537115236, Train accuracy 99.84614769820972, Test accuracy 93.28520569620254, Cost 70.00444722175598 s\n",
      "Model saved in epoch 545\n",
      "Epoch 546, Train loss 0.003009598444733198, Test loss 0.41727654607612874, Train accuracy 99.90009590792839, Test accuracy 93.30498417721519, Cost 69.93201947212219 s\n",
      "Epoch 547, Train loss 0.0037013279257453666, Test loss 0.4230111135240597, Train accuracy 99.87412084398977, Test accuracy 93.18631329113924, Cost 70.05807042121887 s\n",
      "Epoch 548, Train loss 0.004571321475080779, Test loss 0.4316431795588777, Train accuracy 99.85414002557545, Test accuracy 93.21598101265823, Cost 60.89346742630005 s\n",
      "Epoch 549, Train loss 0.004786509155558022, Test loss 0.45299272531572776, Train accuracy 99.83615728900256, Test accuracy 93.1368670886076, Cost 51.05644488334656 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550, Train loss 0.003506708560572962, Test loss 0.44052395054811166, Train accuracy 99.89010549872123, Test accuracy 93.3742088607595, Cost 51.01417136192322 s\n",
      "Model saved in epoch 550\n",
      "Epoch 551, Train loss 0.003816871741776867, Test loss 0.42612699174051044, Train accuracy 99.86413043478261, Test accuracy 93.33465189873418, Cost 51.069217681884766 s\n",
      "Epoch 552, Train loss 0.002975075284641958, Test loss 0.4504792028212849, Train accuracy 99.90009590792839, Test accuracy 93.30498417721519, Cost 51.07393431663513 s\n",
      "Epoch 553, Train loss 0.005226236013381671, Test loss 0.49134179492351376, Train accuracy 99.81897378516624, Test accuracy 92.8698575949367, Cost 51.06756043434143 s\n",
      "Epoch 554, Train loss 0.005595977154161866, Test loss 0.4564750416416533, Train accuracy 99.82416879795396, Test accuracy 93.35443037974683, Cost 51.021522998809814 s\n",
      "Epoch 555, Train loss 0.005699441939139577, Test loss 0.4490422781415378, Train accuracy 99.78820332480818, Test accuracy 93.12697784810126, Cost 50.75727438926697 s\n",
      "Model saved in epoch 555\n",
      "Epoch 556, Train loss 0.0044098993248134905, Test loss 0.4246253052467032, Train accuracy 99.85813618925832, Test accuracy 93.43354430379746, Cost 50.96455383300781 s\n",
      "Epoch 557, Train loss 0.0039441901657462025, Test loss 0.44660737440933157, Train accuracy 99.87212276214834, Test accuracy 93.47310126582279, Cost 50.94231677055359 s\n",
      "Epoch 558, Train loss 0.0035566146486330917, Test loss 0.4260924263279649, Train accuracy 99.87412084398977, Test accuracy 93.15664556962025, Cost 50.97664451599121 s\n",
      "Epoch 559, Train loss 0.0033527450774363155, Test loss 0.4204114874989926, Train accuracy 99.90009590792839, Test accuracy 93.47310126582279, Cost 50.867758989334106 s\n",
      "Epoch 560, Train loss 0.0020763612201672773, Test loss 0.4060387419937532, Train accuracy 99.92487212276215, Test accuracy 93.39398734177215, Cost 50.87184453010559 s\n",
      "Model saved in epoch 560\n",
      "Epoch 561, Train loss 0.0039124680848484335, Test loss 0.4378447618476952, Train accuracy 99.86413043478261, Test accuracy 93.21598101265823, Cost 50.884963035583496 s\n",
      "Epoch 562, Train loss 0.0039028818767308533, Test loss 0.46539217007311084, Train accuracy 99.88610933503837, Test accuracy 93.05775316455696, Cost 50.89617848396301 s\n",
      "Epoch 563, Train loss 0.003644236723221067, Test loss 0.4252678999512256, Train accuracy 99.87811700767263, Test accuracy 93.5818829113924, Cost 50.869755029678345 s\n",
      "Epoch 564, Train loss 0.0034412730333995643, Test loss 0.45054030107169213, Train accuracy 99.88610933503837, Test accuracy 93.00830696202532, Cost 50.990413665771484 s\n",
      "Epoch 565, Train loss 0.004628952893707559, Test loss 0.46508778773153886, Train accuracy 99.83016304347827, Test accuracy 92.99841772151899, Cost 51.02305793762207 s\n",
      "Model saved in epoch 565\n",
      "Epoch 566, Train loss 0.003213984993833393, Test loss 0.4402765585934814, Train accuracy 99.88011508951406, Test accuracy 93.43354430379746, Cost 51.02345108985901 s\n",
      "Epoch 567, Train loss 0.0022052094904294857, Test loss 0.43864042823544785, Train accuracy 99.92806905370844, Test accuracy 93.38409810126582, Cost 51.02293372154236 s\n",
      "Epoch 568, Train loss 0.002539625053490305, Test loss 0.4639153381503081, Train accuracy 99.92806905370844, Test accuracy 93.29509493670886, Cost 51.01507115364075 s\n",
      "Epoch 569, Train loss 0.0031205234605025294, Test loss 0.45135290435032, Train accuracy 99.88810741687979, Test accuracy 93.02808544303798, Cost 51.061073303222656 s\n",
      "Epoch 570, Train loss 0.003422689906162474, Test loss 0.4445010025903017, Train accuracy 99.8941016624041, Test accuracy 93.3445411392405, Cost 51.02973532676697 s\n",
      "Model saved in epoch 570\n",
      "Epoch 571, Train loss 0.003656268034006653, Test loss 0.4392678829122193, Train accuracy 99.8821131713555, Test accuracy 93.29509493670886, Cost 51.04780578613281 s\n",
      "Epoch 572, Train loss 0.0022448533868520497, Test loss 0.4454312419778184, Train accuracy 99.92806905370844, Test accuracy 93.5818829113924, Cost 50.63105773925781 s\n",
      "Epoch 573, Train loss 0.0032209076220334814, Test loss 0.4282701583225516, Train accuracy 99.8941016624041, Test accuracy 93.45332278481013, Cost 50.74882698059082 s\n",
      "Epoch 574, Train loss 0.0031987577290598364, Test loss 0.42854967293671414, Train accuracy 99.8968989769821, Test accuracy 93.54232594936708, Cost 50.91343331336975 s\n",
      "Epoch 575, Train loss 0.002858576085270059, Test loss 0.4381967733932447, Train accuracy 99.91408248081841, Test accuracy 93.61155063291139, Cost 50.9150013923645 s\n",
      "Model saved in epoch 575\n",
      "Epoch 576, Train loss 0.002743314525209907, Test loss 0.4564335739499406, Train accuracy 99.90808823529412, Test accuracy 93.32476265822785, Cost 50.995895862579346 s\n",
      "Epoch 577, Train loss 0.001905221948634701, Test loss 0.4555231906190703, Train accuracy 99.93006713554988, Test accuracy 93.30498417721519, Cost 51.03221154212952 s\n",
      "Epoch 578, Train loss 0.0034815378739513525, Test loss 0.45048409007206747, Train accuracy 99.90808823529412, Test accuracy 93.26542721518987, Cost 51.023993253707886 s\n",
      "Epoch 579, Train loss 0.0021447055847762814, Test loss 0.4397002090758915, Train accuracy 99.9380594629156, Test accuracy 93.3445411392405, Cost 51.01038837432861 s\n",
      "Epoch 580, Train loss 0.002224565177741746, Test loss 0.44057394851800763, Train accuracy 99.9380594629156, Test accuracy 93.39398734177215, Cost 50.99834895133972 s\n",
      "Model saved in epoch 580\n",
      "Epoch 581, Train loss 0.0028550219826919557, Test loss 0.4343648388321641, Train accuracy 99.91008631713555, Test accuracy 93.3445411392405, Cost 51.0298068523407 s\n",
      "Epoch 582, Train loss 0.0018182427361131915, Test loss 0.4616960987825937, Train accuracy 99.94605179028133, Test accuracy 93.48299050632912, Cost 51.05548453330994 s\n",
      "Epoch 583, Train loss 0.0026306663146867097, Test loss 0.4505431181456469, Train accuracy 99.91408248081841, Test accuracy 92.95886075949367, Cost 51.04100513458252 s\n",
      "Epoch 584, Train loss 0.0040900031385682845, Test loss 0.46706862592055826, Train accuracy 99.85613810741688, Test accuracy 93.05775316455696, Cost 51.01734685897827 s\n",
      "Epoch 585, Train loss 0.0031524685484416465, Test loss 0.48845431972530823, Train accuracy 99.90409207161126, Test accuracy 93.07753164556962, Cost 51.05364799499512 s\n",
      "Model saved in epoch 585\n",
      "Epoch 586, Train loss 0.003459218565063226, Test loss 0.44689921223664586, Train accuracy 99.86812659846548, Test accuracy 93.15664556962025, Cost 51.00569272041321 s\n",
      "Epoch 587, Train loss 0.00272027437476401, Test loss 0.46627892789584174, Train accuracy 99.90409207161126, Test accuracy 93.21598101265823, Cost 50.92099690437317 s\n",
      "Epoch 588, Train loss 0.005171406966962848, Test loss 0.45793494091758247, Train accuracy 99.84814578005115, Test accuracy 93.10719936708861, Cost 50.856043100357056 s\n",
      "Epoch 589, Train loss 0.005314147958720276, Test loss 0.4526484984951683, Train accuracy 99.82776534526855, Test accuracy 93.31487341772151, Cost 50.58580684661865 s\n",
      "Epoch 590, Train loss 0.0033182078792609168, Test loss 0.42001682831139503, Train accuracy 99.89889705882354, Test accuracy 93.62143987341773, Cost 50.79956936836243 s\n",
      "Model saved in epoch 590\n",
      "Epoch 591, Train loss 0.003066771182548016, Test loss 0.45512657725735556, Train accuracy 99.90409207161126, Test accuracy 93.26542721518987, Cost 51.04798078536987 s\n",
      "Epoch 592, Train loss 0.002537519530924654, Test loss 0.4389687009108595, Train accuracy 99.93006713554988, Test accuracy 93.5126582278481, Cost 51.0289568901062 s\n",
      "Epoch 593, Train loss 0.0019586165378571068, Test loss 0.44090665419456326, Train accuracy 99.9320652173913, Test accuracy 93.5818829113924, Cost 50.87281107902527 s\n",
      "Epoch 594, Train loss 0.002620722221120994, Test loss 0.4422771606264235, Train accuracy 99.91208439897699, Test accuracy 93.54232594936708, Cost 50.86462354660034 s\n",
      "Epoch 595, Train loss 0.0014328068366440882, Test loss 0.4510683316643102, Train accuracy 99.96403452685422, Test accuracy 93.35443037974683, Cost 50.86902928352356 s\n",
      "Model saved in epoch 595\n",
      "Epoch 596, Train loss 0.0017610228200311512, Test loss 0.43787141653555856, Train accuracy 99.94605179028133, Test accuracy 93.60166139240506, Cost 50.85032606124878 s\n",
      "Epoch 597, Train loss 0.002184744390511403, Test loss 0.45090780529794816, Train accuracy 99.92806905370844, Test accuracy 93.41376582278481, Cost 50.83652091026306 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 598, Train loss 0.0038464234004529302, Test loss 0.45855521321108067, Train accuracy 99.86812659846548, Test accuracy 93.31487341772151, Cost 50.838311195373535 s\n",
      "Epoch 599, Train loss 0.0032185050606614793, Test loss 0.435100772170515, Train accuracy 99.8821131713555, Test accuracy 93.72033227848101, Cost 50.860477924346924 s\n",
      "Epoch 600, Train loss 0.0019200328191860986, Test loss 0.4443324937756303, Train accuracy 99.93006713554988, Test accuracy 93.56210443037975, Cost 50.98402166366577 s\n",
      "Model saved in epoch 600\n",
      "Epoch 601, Train loss 0.002034644473224732, Test loss 0.44211919002140626, Train accuracy 99.93086636828644, Test accuracy 93.62143987341773, Cost 50.963438987731934 s\n",
      "Epoch 602, Train loss 0.002871016671890147, Test loss 0.4374759681994402, Train accuracy 99.90808823529412, Test accuracy 93.57199367088607, Cost 50.98600673675537 s\n",
      "Epoch 603, Train loss 0.0016900318244219552, Test loss 0.43255761077132404, Train accuracy 99.95204603580562, Test accuracy 93.72033227848101, Cost 50.95947599411011 s\n",
      "Epoch 604, Train loss 0.0010901488996833716, Test loss 0.4320634944906718, Train accuracy 99.97202685421995, Test accuracy 93.63132911392405, Cost 50.966978788375854 s\n",
      "Epoch 605, Train loss 0.0013728654896012255, Test loss 0.43868043712234195, Train accuracy 99.94804987212277, Test accuracy 93.82911392405063, Cost 50.957956314086914 s\n",
      "Model saved in epoch 605\n",
      "Epoch 606, Train loss 0.000939686693458564, Test loss 0.4470746215385727, Train accuracy 99.96403452685422, Test accuracy 93.73022151898734, Cost 50.830814361572266 s\n",
      "Epoch 607, Train loss 0.0008818547736896887, Test loss 0.4587872126434423, Train accuracy 99.97402493606138, Test accuracy 93.71044303797468, Cost 50.86873722076416 s\n",
      "Epoch 608, Train loss 0.0014849963954629345, Test loss 0.4496354121314008, Train accuracy 99.95004795396419, Test accuracy 93.59177215189874, Cost 51.006144285202026 s\n",
      "Epoch 609, Train loss 0.002771996094591898, Test loss 0.4682760050496723, Train accuracy 99.90209398976982, Test accuracy 93.55221518987342, Cost 50.989492416381836 s\n",
      "Epoch 610, Train loss 0.0028826981954876325, Test loss 0.4670479014704499, Train accuracy 99.90409207161126, Test accuracy 93.3445411392405, Cost 50.94638180732727 s\n",
      "Model saved in epoch 610\n",
      "Epoch 611, Train loss 0.003613377355025098, Test loss 0.4661650848398103, Train accuracy 99.88690856777494, Test accuracy 93.23575949367088, Cost 50.951847314834595 s\n",
      "Epoch 612, Train loss 0.0038304745446212088, Test loss 0.4725996913223327, Train accuracy 99.89609974424552, Test accuracy 93.19620253164557, Cost 50.94144058227539 s\n",
      "Epoch 613, Train loss 0.002912748328710264, Test loss 0.4465050494793472, Train accuracy 99.90009590792839, Test accuracy 93.28520569620254, Cost 50.943528175354004 s\n",
      "Epoch 614, Train loss 0.0024811386596297487, Test loss 0.44079971539823315, Train accuracy 99.92087595907928, Test accuracy 93.74011075949367, Cost 50.925899267196655 s\n",
      "Epoch 615, Train loss 0.0024286580622045273, Test loss 0.4605701558669157, Train accuracy 99.91288363171356, Test accuracy 93.32476265822785, Cost 50.97797727584839 s\n",
      "Model saved in epoch 615\n",
      "Epoch 616, Train loss 0.002102864524068848, Test loss 0.46237315268173246, Train accuracy 99.9320652173913, Test accuracy 93.50276898734177, Cost 51.02751421928406 s\n",
      "Epoch 617, Train loss 0.0022384199944315564, Test loss 0.45879723662156846, Train accuracy 99.93606138107417, Test accuracy 93.42365506329114, Cost 50.985026597976685 s\n",
      "Epoch 618, Train loss 0.0017846117501295522, Test loss 0.4638538956642151, Train accuracy 99.94285485933504, Test accuracy 93.45332278481013, Cost 50.950888872146606 s\n",
      "Epoch 619, Train loss 0.001505644843124043, Test loss 0.47926835154619396, Train accuracy 99.9560421994885, Test accuracy 93.3742088607595, Cost 50.93775200843811 s\n",
      "Epoch 620, Train loss 0.003040918067407711, Test loss 0.4566707941172998, Train accuracy 99.90009590792839, Test accuracy 93.47310126582279, Cost 50.90455174446106 s\n",
      "Model saved in epoch 620\n",
      "Epoch 621, Train loss 0.002521765605861289, Test loss 0.4837563519802275, Train accuracy 99.92007672634271, Test accuracy 93.60166139240506, Cost 50.89605355262756 s\n",
      "Epoch 622, Train loss 0.0043625750558651906, Test loss 0.4546715265399293, Train accuracy 99.85214194373401, Test accuracy 93.56210443037975, Cost 50.84816384315491 s\n",
      "Epoch 623, Train loss 0.0031283309962234812, Test loss 0.46429716635353957, Train accuracy 99.89010549872123, Test accuracy 93.25553797468355, Cost 50.820647954940796 s\n",
      "Epoch 624, Train loss 0.004518345671950996, Test loss 0.4751830823436568, Train accuracy 99.84215153452685, Test accuracy 93.5126582278481, Cost 50.81216526031494 s\n",
      "Epoch 625, Train loss 0.0041801706402000965, Test loss 0.4681863338698315, Train accuracy 99.8701246803069, Test accuracy 93.23575949367088, Cost 50.99348211288452 s\n",
      "Model saved in epoch 625\n",
      "Epoch 626, Train loss 0.003708688267499169, Test loss 0.4621618656040747, Train accuracy 99.86413043478261, Test accuracy 93.54232594936708, Cost 50.99320983886719 s\n",
      "Epoch 627, Train loss 0.004034437196902995, Test loss 0.4524301978040345, Train accuracy 99.86413043478261, Test accuracy 93.6807753164557, Cost 51.00771141052246 s\n",
      "Epoch 628, Train loss 0.0026235289117749463, Test loss 0.4381811722547193, Train accuracy 99.91208439897699, Test accuracy 93.63132911392405, Cost 50.99352049827576 s\n",
      "Epoch 629, Train loss 0.0016750771356664304, Test loss 0.44245336138749425, Train accuracy 99.94205562659846, Test accuracy 93.8192246835443, Cost 51.001060009002686 s\n",
      "Epoch 630, Train loss 0.0026271132823719066, Test loss 0.45823313135512267, Train accuracy 99.92207480818415, Test accuracy 93.35443037974683, Cost 51.016457080841064 s\n",
      "Model saved in epoch 630\n",
      "Epoch 631, Train loss 0.002568634184392365, Test loss 0.4600538877369482, Train accuracy 99.926070971867, Test accuracy 93.4434335443038, Cost 50.960712909698486 s\n",
      "Epoch 632, Train loss 0.0037957216143181052, Test loss 0.4637319712039036, Train accuracy 99.88810741687979, Test accuracy 93.4434335443038, Cost 50.971850872039795 s\n",
      "Epoch 633, Train loss 0.0026523821871732626, Test loss 0.45885316532435294, Train accuracy 99.92806905370844, Test accuracy 93.80933544303798, Cost 50.978776693344116 s\n",
      "Epoch 634, Train loss 0.0018523544757125124, Test loss 0.4589904523395662, Train accuracy 99.94804987212277, Test accuracy 93.64121835443038, Cost 50.97864866256714 s\n",
      "Epoch 635, Train loss 0.0019441237723185623, Test loss 0.45543099312654023, Train accuracy 99.93606138107417, Test accuracy 93.55221518987342, Cost 50.99747180938721 s\n",
      "Model saved in epoch 635\n",
      "Epoch 636, Train loss 0.0024078521022005577, Test loss 0.4524405697667146, Train accuracy 99.91408248081841, Test accuracy 93.66099683544304, Cost 51.02441191673279 s\n",
      "Epoch 637, Train loss 0.003210139497306165, Test loss 0.4525206343188316, Train accuracy 99.90009590792839, Test accuracy 93.85878164556962, Cost 51.02602219581604 s\n",
      "Epoch 638, Train loss 0.002288652328105508, Test loss 0.46203858028107053, Train accuracy 99.92806905370844, Test accuracy 93.66099683544304, Cost 51.01910901069641 s\n",
      "Epoch 639, Train loss 0.0020046534458992298, Test loss 0.46380295045673847, Train accuracy 99.9320652173913, Test accuracy 93.42365506329114, Cost 50.82703256607056 s\n",
      "Epoch 640, Train loss 0.0020926130574338447, Test loss 0.4460118100330045, Train accuracy 99.93406329923273, Test accuracy 93.52254746835443, Cost 50.896517753601074 s\n",
      "Model saved in epoch 640\n",
      "Epoch 641, Train loss 0.0019499179451959625, Test loss 0.45504082116899613, Train accuracy 99.9320652173913, Test accuracy 93.57199367088607, Cost 50.840304136276245 s\n",
      "Epoch 642, Train loss 0.002504478901409062, Test loss 0.462544304660604, Train accuracy 99.92007672634271, Test accuracy 93.22587025316456, Cost 51.020145416259766 s\n",
      "Epoch 643, Train loss 0.002282688736786347, Test loss 0.4648969110242928, Train accuracy 99.92207480818415, Test accuracy 93.30498417721519, Cost 51.01937437057495 s\n",
      "Epoch 644, Train loss 0.0016158326216539295, Test loss 0.47477554001762895, Train accuracy 99.9440537084399, Test accuracy 93.42365506329114, Cost 51.02315926551819 s\n",
      "Epoch 645, Train loss 0.0019096001451317207, Test loss 0.45403176805452455, Train accuracy 99.9440537084399, Test accuracy 93.49287974683544, Cost 51.05773687362671 s\n",
      "Model saved in epoch 645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 646, Train loss 0.0023327959730689023, Test loss 0.45925108350436145, Train accuracy 99.92007672634271, Test accuracy 93.72033227848101, Cost 51.02600979804993 s\n",
      "Epoch 647, Train loss 0.0019382410376196243, Test loss 0.5003180676198835, Train accuracy 99.9320652173913, Test accuracy 93.24564873417721, Cost 51.029046058654785 s\n",
      "Epoch 648, Train loss 0.00435167696119476, Test loss 0.4927540912611198, Train accuracy 99.85414002557545, Test accuracy 92.99841772151899, Cost 50.9869327545166 s\n",
      "Epoch 649, Train loss 0.003538590919819296, Test loss 0.4895554412203499, Train accuracy 99.86692774936061, Test accuracy 93.10719936708861, Cost 50.92655086517334 s\n",
      "Epoch 650, Train loss 0.004307036828598092, Test loss 0.4706483002799221, Train accuracy 99.86413043478261, Test accuracy 93.22587025316456, Cost 50.8621723651886 s\n",
      "Model saved in epoch 650\n",
      "Epoch 651, Train loss 0.004543667105822014, Test loss 0.45209750705221785, Train accuracy 99.85414002557545, Test accuracy 93.56210443037975, Cost 50.915653228759766 s\n",
      "Epoch 652, Train loss 0.0037579407662714868, Test loss 0.4780561064806166, Train accuracy 99.87611892583121, Test accuracy 93.07753164556962, Cost 51.009323835372925 s\n",
      "Epoch 653, Train loss 0.0029416211431781097, Test loss 0.43839943069445936, Train accuracy 99.88610933503837, Test accuracy 93.53243670886076, Cost 50.99774742126465 s\n",
      "Epoch 654, Train loss 0.0027505476397311117, Test loss 0.44965476816213584, Train accuracy 99.91008631713555, Test accuracy 93.63132911392405, Cost 50.986308574676514 s\n",
      "Epoch 655, Train loss 0.0016675616665698817, Test loss 0.4496379514472394, Train accuracy 99.94804987212277, Test accuracy 93.70055379746836, Cost 50.99904942512512 s\n",
      "Model saved in epoch 655\n",
      "Epoch 656, Train loss 0.0014379205157954698, Test loss 0.45147458209267144, Train accuracy 99.95004795396419, Test accuracy 93.61155063291139, Cost 50.72817420959473 s\n",
      "Epoch 657, Train loss 0.0012397109370909348, Test loss 0.4487338926218733, Train accuracy 99.96603260869566, Test accuracy 93.75, Cost 50.92096161842346 s\n",
      "Epoch 658, Train loss 0.0015716039179015284, Test loss 0.4625487703877159, Train accuracy 99.94605179028133, Test accuracy 93.47310126582279, Cost 50.90332293510437 s\n",
      "Epoch 659, Train loss 0.0011664061256356838, Test loss 0.4633612754412844, Train accuracy 99.96403452685422, Test accuracy 93.53243670886076, Cost 51.02492046356201 s\n",
      "Epoch 660, Train loss 0.0013938588038346258, Test loss 0.4496322468960587, Train accuracy 99.9440537084399, Test accuracy 93.4434335443038, Cost 50.861274003982544 s\n",
      "Model saved in epoch 660\n",
      "Epoch 661, Train loss 0.001489812603703776, Test loss 0.48833887396922593, Train accuracy 99.95404411764706, Test accuracy 93.46321202531645, Cost 50.84620261192322 s\n",
      "Epoch 662, Train loss 0.0019000397407657509, Test loss 0.46086175513418415, Train accuracy 99.93606138107417, Test accuracy 93.54232594936708, Cost 50.87886428833008 s\n",
      "Epoch 663, Train loss 0.0019970782347593662, Test loss 0.47781551883944984, Train accuracy 99.93406329923273, Test accuracy 93.45332278481013, Cost 50.90849852561951 s\n",
      "Epoch 664, Train loss 0.001043726271893978, Test loss 0.4910462199226965, Train accuracy 99.96403452685422, Test accuracy 93.3445411392405, Cost 50.92713761329651 s\n",
      "Epoch 665, Train loss 0.0011414595789738366, Test loss 0.4750407441413101, Train accuracy 99.95204603580562, Test accuracy 93.52254746835443, Cost 50.911357164382935 s\n",
      "Model saved in epoch 665\n",
      "Epoch 666, Train loss 0.0017019667132174624, Test loss 0.46541907232773455, Train accuracy 99.95004795396419, Test accuracy 93.71044303797468, Cost 50.944706439971924 s\n",
      "Epoch 667, Train loss 0.0017879136989660271, Test loss 0.491961481922035, Train accuracy 99.95204603580562, Test accuracy 93.11708860759494, Cost 50.95026969909668 s\n",
      "Epoch 668, Train loss 0.0023844625070326047, Test loss 0.47776551195715045, Train accuracy 99.92407289002557, Test accuracy 93.49287974683544, Cost 51.02240562438965 s\n",
      "Epoch 669, Train loss 0.00329323223793058, Test loss 0.4875660116159463, Train accuracy 99.89010549872123, Test accuracy 93.36431962025317, Cost 50.96853542327881 s\n",
      "Epoch 670, Train loss 0.0026943861967941387, Test loss 0.4642135745173768, Train accuracy 99.90409207161126, Test accuracy 93.60166139240506, Cost 50.97071957588196 s\n",
      "Model saved in epoch 670\n",
      "Epoch 671, Train loss 0.0022880248657194905, Test loss 0.4632728371439101, Train accuracy 99.91008631713555, Test accuracy 93.57199367088607, Cost 50.9751935005188 s\n",
      "Epoch 672, Train loss 0.0017482983252585607, Test loss 0.4716892957310133, Train accuracy 99.93606138107417, Test accuracy 93.49287974683544, Cost 50.96473741531372 s\n",
      "Epoch 673, Train loss 0.0018136233379318187, Test loss 0.4640389255047599, Train accuracy 99.93406329923273, Test accuracy 93.52254746835443, Cost 50.70651984214783 s\n",
      "Epoch 674, Train loss 0.0019225604234940836, Test loss 0.4692787990162644, Train accuracy 99.94005754475704, Test accuracy 93.50276898734177, Cost 50.83333778381348 s\n",
      "Epoch 675, Train loss 0.0016729698817089741, Test loss 0.46418053798283204, Train accuracy 99.95004795396419, Test accuracy 93.6807753164557, Cost 51.005390644073486 s\n",
      "Model saved in epoch 675\n",
      "Epoch 676, Train loss 0.0014207711425371571, Test loss 0.4690399920638603, Train accuracy 99.95804028132993, Test accuracy 93.72033227848101, Cost 50.97768545150757 s\n",
      "Epoch 677, Train loss 0.0005354741895713457, Test loss 0.4586280198602737, Train accuracy 99.9880115089514, Test accuracy 93.60166139240506, Cost 50.989410161972046 s\n",
      "Epoch 678, Train loss 0.0005527048822934214, Test loss 0.4513994415255287, Train accuracy 99.9880115089514, Test accuracy 93.66099683544304, Cost 51.094308853149414 s\n",
      "Epoch 679, Train loss 0.0013129724562273362, Test loss 0.46213383104982253, Train accuracy 99.95804028132993, Test accuracy 93.52254746835443, Cost 51.044259786605835 s\n",
      "Epoch 680, Train loss 0.0017248530954891358, Test loss 0.48573554184617873, Train accuracy 99.9440537084399, Test accuracy 93.38409810126582, Cost 51.0474956035614 s\n",
      "Model saved in epoch 680\n",
      "Epoch 681, Train loss 0.002015152850064427, Test loss 0.47196118222384514, Train accuracy 99.9320652173913, Test accuracy 93.53243670886076, Cost 51.05073690414429 s\n",
      "Epoch 682, Train loss 0.0012210903771341915, Test loss 0.47033444230880916, Train accuracy 99.96203644501279, Test accuracy 93.62143987341773, Cost 51.04257273674011 s\n",
      "Epoch 683, Train loss 0.001386503172358972, Test loss 0.4655943573039921, Train accuracy 99.95404411764706, Test accuracy 93.79944620253164, Cost 51.035696268081665 s\n",
      "Epoch 684, Train loss 0.002096957100015063, Test loss 0.4791970004009295, Train accuracy 99.91608056265984, Test accuracy 93.63132911392405, Cost 51.04728841781616 s\n",
      "Epoch 685, Train loss 0.002715689821067473, Test loss 0.49699991309567343, Train accuracy 99.89809782608695, Test accuracy 93.45332278481013, Cost 51.05190658569336 s\n",
      "Model saved in epoch 685\n",
      "Epoch 686, Train loss 0.0029960314186735074, Test loss 0.4968159825458557, Train accuracy 99.89210358056266, Test accuracy 93.31487341772151, Cost 51.000617027282715 s\n",
      "Epoch 687, Train loss 0.002816086833098247, Test loss 0.49453244518630113, Train accuracy 99.91008631713555, Test accuracy 93.00830696202532, Cost 50.94849896430969 s\n",
      "Epoch 688, Train loss 0.0024895021453474916, Test loss 0.4744111868682541, Train accuracy 99.91008631713555, Test accuracy 93.54232594936708, Cost 50.920623779296875 s\n",
      "Epoch 689, Train loss 0.002314822467004378, Test loss 0.48135966903093874, Train accuracy 99.91408248081841, Test accuracy 93.5126582278481, Cost 50.780210971832275 s\n",
      "Epoch 690, Train loss 0.0019447428164773004, Test loss 0.4631625876962384, Train accuracy 99.92806905370844, Test accuracy 93.70055379746836, Cost 50.651469469070435 s\n",
      "Model saved in epoch 690\n",
      "Epoch 691, Train loss 0.002079642182084805, Test loss 0.46068557219792017, Train accuracy 99.92007672634271, Test accuracy 93.54232594936708, Cost 50.70326232910156 s\n",
      "Epoch 692, Train loss 0.0010494256863878369, Test loss 0.4547177825736094, Train accuracy 99.96403452685422, Test accuracy 93.79944620253164, Cost 50.87152886390686 s\n",
      "Epoch 693, Train loss 0.0025016947566539566, Test loss 0.47517898565606226, Train accuracy 99.92007672634271, Test accuracy 93.43354430379746, Cost 50.87669658660889 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 694, Train loss 0.001571019551380343, Test loss 0.49845656615835204, Train accuracy 99.94884910485933, Test accuracy 93.56210443037975, Cost 50.88686776161194 s\n",
      "Epoch 695, Train loss 0.0016605923448878893, Test loss 0.4871622657851328, Train accuracy 99.9560421994885, Test accuracy 93.5126582278481, Cost 50.92499828338623 s\n",
      "Model saved in epoch 695\n",
      "Epoch 696, Train loss 0.0009221416403401145, Test loss 0.4858215876583812, Train accuracy 99.96603260869566, Test accuracy 93.33465189873418, Cost 51.082834243774414 s\n",
      "Epoch 697, Train loss 0.001480999784435506, Test loss 0.4728187067033369, Train accuracy 99.94804987212277, Test accuracy 93.52254746835443, Cost 51.0669584274292 s\n",
      "Epoch 698, Train loss 0.0027542909518366017, Test loss 0.4752546359277979, Train accuracy 99.92007672634271, Test accuracy 93.4434335443038, Cost 51.021257638931274 s\n",
      "Epoch 699, Train loss 0.0012060975712056624, Test loss 0.5007250203361994, Train accuracy 99.9560421994885, Test accuracy 93.52254746835443, Cost 51.020432472229004 s\n",
      "Epoch 700, Train loss 0.00298350806559449, Test loss 0.450736889167677, Train accuracy 99.90409207161126, Test accuracy 93.54232594936708, Cost 51.01385951042175 s\n",
      "Model saved in epoch 700\n",
      "Epoch 701, Train loss 0.002846005762464006, Test loss 0.48167980169948144, Train accuracy 99.90609015345268, Test accuracy 93.35443037974683, Cost 51.01282286643982 s\n",
      "Epoch 702, Train loss 0.002297177455992122, Test loss 0.4657116817145408, Train accuracy 99.93606138107417, Test accuracy 93.41376582278481, Cost 51.0117027759552 s\n",
      "Epoch 703, Train loss 0.0013163122541006297, Test loss 0.4701881855726242, Train accuracy 99.96603260869566, Test accuracy 93.6807753164557, Cost 51.01919651031494 s\n",
      "Epoch 704, Train loss 0.0010122748415087024, Test loss 0.4581946674970132, Train accuracy 99.96203644501279, Test accuracy 93.73022151898734, Cost 51.00543975830078 s\n",
      "Epoch 705, Train loss 0.0009150507975643899, Test loss 0.4627363409233999, Train accuracy 99.97602301790282, Test accuracy 93.66099683544304, Cost 51.01815724372864 s\n",
      "Model saved in epoch 705\n",
      "Epoch 706, Train loss 0.0019775295212365426, Test loss 0.45500142636555657, Train accuracy 99.94005754475704, Test accuracy 93.57199367088607, Cost 50.843764781951904 s\n",
      "Epoch 707, Train loss 0.000946812092261598, Test loss 0.4701413982842542, Train accuracy 99.9560421994885, Test accuracy 93.59177215189874, Cost 50.94083285331726 s\n",
      "Epoch 708, Train loss 0.0014273686496429681, Test loss 0.45623859715989873, Train accuracy 99.95204603580562, Test accuracy 93.67088607594937, Cost 50.883705854415894 s\n",
      "Epoch 709, Train loss 0.001380549030998985, Test loss 0.4531160702905323, Train accuracy 99.96603260869566, Test accuracy 93.66099683544304, Cost 51.031676292419434 s\n",
      "Epoch 710, Train loss 0.0009835000153242289, Test loss 0.4562245141479033, Train accuracy 99.97002877237851, Test accuracy 93.8192246835443, Cost 51.02637267112732 s\n",
      "Model saved in epoch 710\n",
      "Epoch 711, Train loss 0.0017588925463221474, Test loss 0.47813279624981214, Train accuracy 99.94005754475704, Test accuracy 93.26542721518987, Cost 51.0507025718689 s\n",
      "Epoch 712, Train loss 0.0021837260001004435, Test loss 0.4477350847630561, Train accuracy 99.92207480818415, Test accuracy 93.54232594936708, Cost 51.054309606552124 s\n",
      "Epoch 713, Train loss 0.0014109821025292493, Test loss 0.4704403667003388, Train accuracy 99.95404411764706, Test accuracy 93.60166139240506, Cost 51.0572247505188 s\n",
      "Epoch 714, Train loss 0.0017288849471545982, Test loss 0.44572459270918297, Train accuracy 99.94205562659846, Test accuracy 93.75988924050633, Cost 51.02287983894348 s\n",
      "Epoch 715, Train loss 0.002336099493208669, Test loss 0.4547028567028951, Train accuracy 99.91807864450128, Test accuracy 93.6511075949367, Cost 51.03919458389282 s\n",
      "Model saved in epoch 715\n",
      "Epoch 716, Train loss 0.0016793178589434186, Test loss 0.4598378734781018, Train accuracy 99.94205562659846, Test accuracy 93.6807753164557, Cost 50.922428607940674 s\n",
      "Epoch 717, Train loss 0.002616416036700726, Test loss 0.45236017224909386, Train accuracy 99.91887787723785, Test accuracy 93.31487341772151, Cost 50.93115854263306 s\n",
      "Epoch 718, Train loss 0.0023814784533526755, Test loss 0.4798795496927032, Train accuracy 99.92407289002557, Test accuracy 93.14675632911393, Cost 50.92709994316101 s\n",
      "Epoch 719, Train loss 0.0021272119964285364, Test loss 0.4662978924527953, Train accuracy 99.92207480818415, Test accuracy 93.48299050632912, Cost 50.9318585395813 s\n",
      "Epoch 720, Train loss 0.002241970278325479, Test loss 0.4773445636788501, Train accuracy 99.9320652173913, Test accuracy 93.31487341772151, Cost 50.92408633232117 s\n",
      "Model saved in epoch 720\n",
      "Epoch 721, Train loss 0.0028546197647811586, Test loss 0.47139644698251654, Train accuracy 99.90609015345268, Test accuracy 93.32476265822785, Cost 50.96168303489685 s\n",
      "Epoch 722, Train loss 0.001491201517912659, Test loss 0.4852906512685969, Train accuracy 99.9560421994885, Test accuracy 93.23575949367088, Cost 50.95951557159424 s\n",
      "Epoch 723, Train loss 0.0008486293862354025, Test loss 0.4608498558496373, Train accuracy 99.97802109974424, Test accuracy 93.6807753164557, Cost 50.68136525154114 s\n",
      "Epoch 724, Train loss 0.0008029284813330757, Test loss 0.45870571314722675, Train accuracy 99.98001918158567, Test accuracy 93.6511075949367, Cost 50.78689098358154 s\n",
      "Epoch 725, Train loss 0.0008128649714717656, Test loss 0.468629451350698, Train accuracy 99.97202685421995, Test accuracy 93.56210443037975, Cost 50.81111121177673 s\n",
      "Model saved in epoch 725\n",
      "Epoch 726, Train loss 0.0012944814347679778, Test loss 0.4573333435043504, Train accuracy 99.97002877237851, Test accuracy 93.86867088607595, Cost 50.85073137283325 s\n",
      "Epoch 727, Train loss 0.0010517484122214381, Test loss 0.46301173937471607, Train accuracy 99.97402493606138, Test accuracy 93.57199367088607, Cost 50.861268520355225 s\n",
      "Epoch 728, Train loss 0.0008713376396664254, Test loss 0.4622299335425413, Train accuracy 99.97402493606138, Test accuracy 93.64121835443038, Cost 50.9163544178009 s\n",
      "Epoch 729, Train loss 0.0015260044650575273, Test loss 0.4638512599977511, Train accuracy 99.96203644501279, Test accuracy 93.38409810126582, Cost 50.88555026054382 s\n",
      "Epoch 730, Train loss 0.0012048328138074657, Test loss 0.4608872606407238, Train accuracy 99.96003836317135, Test accuracy 93.67088607594937, Cost 50.870216846466064 s\n",
      "Model saved in epoch 730\n",
      "Epoch 731, Train loss 0.001629766867348621, Test loss 0.472410002746914, Train accuracy 99.94005754475704, Test accuracy 93.4434335443038, Cost 50.9009850025177 s\n",
      "Epoch 732, Train loss 0.0012541118778165914, Test loss 0.49953588305772106, Train accuracy 99.94605179028133, Test accuracy 93.70055379746836, Cost 50.945061922073364 s\n",
      "Epoch 733, Train loss 0.0008933723354215361, Test loss 0.5086763510598412, Train accuracy 99.96003836317135, Test accuracy 93.40387658227849, Cost 50.96203374862671 s\n",
      "Epoch 734, Train loss 0.0007457385239876851, Test loss 0.48623424226158785, Train accuracy 99.97602301790282, Test accuracy 93.59177215189874, Cost 50.93711614608765 s\n",
      "Epoch 735, Train loss 0.0011311744299600537, Test loss 0.4831545457621164, Train accuracy 99.95204603580562, Test accuracy 93.53243670886076, Cost 50.88451099395752 s\n",
      "Model saved in epoch 735\n",
      "Epoch 736, Train loss 0.0009222167668925002, Test loss 0.47868769474421874, Train accuracy 99.96403452685422, Test accuracy 93.62143987341773, Cost 50.852585554122925 s\n",
      "Epoch 737, Train loss 0.0014013503989463963, Test loss 0.47431447366370433, Train accuracy 99.95004795396419, Test accuracy 93.64121835443038, Cost 50.855642795562744 s\n",
      "Epoch 738, Train loss 0.0013809650196166734, Test loss 0.4700724010980582, Train accuracy 99.95004795396419, Test accuracy 93.56210443037975, Cost 50.83081841468811 s\n",
      "Epoch 739, Train loss 0.002733972081856904, Test loss 0.4634756691093686, Train accuracy 99.91088554987212, Test accuracy 93.6807753164557, Cost 50.856053829193115 s\n",
      "Epoch 740, Train loss 0.001990993627745163, Test loss 0.4654471194253692, Train accuracy 99.92407289002557, Test accuracy 93.52254746835443, Cost 50.56642723083496 s\n",
      "Model saved in epoch 740\n",
      "Epoch 741, Train loss 0.001778770077451367, Test loss 0.4646421829356423, Train accuracy 99.926070971867, Test accuracy 93.75988924050633, Cost 50.69520711898804 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742, Train loss 0.001319740978914224, Test loss 0.45166973486731327, Train accuracy 99.9560421994885, Test accuracy 93.59177215189874, Cost 50.89432978630066 s\n",
      "Epoch 743, Train loss 0.0005973183866024814, Test loss 0.4470087811822378, Train accuracy 99.98201726342711, Test accuracy 93.67088607594937, Cost 50.88308882713318 s\n",
      "Epoch 744, Train loss 0.0006086934179780792, Test loss 0.45616456243810777, Train accuracy 99.98401534526855, Test accuracy 93.76977848101266, Cost 50.881020069122314 s\n",
      "Epoch 745, Train loss 0.0005861016550629315, Test loss 0.4586359301134001, Train accuracy 99.9880115089514, Test accuracy 93.72033227848101, Cost 50.903719425201416 s\n",
      "Model saved in epoch 745\n",
      "Epoch 746, Train loss 0.0009278555644412701, Test loss 0.48090141162842137, Train accuracy 99.97402493606138, Test accuracy 93.64121835443038, Cost 50.94269037246704 s\n",
      "Epoch 747, Train loss 0.001495300123041482, Test loss 0.48104994649751276, Train accuracy 99.95804028132993, Test accuracy 93.6511075949367, Cost 51.03288149833679 s\n",
      "Epoch 748, Train loss 0.0019499748955934108, Test loss 0.4839143239056008, Train accuracy 99.94804987212277, Test accuracy 93.49287974683544, Cost 51.02201199531555 s\n",
      "Epoch 749, Train loss 0.0013009920637579522, Test loss 0.46374606897559345, Train accuracy 99.96803069053709, Test accuracy 93.75, Cost 51.02451014518738 s\n",
      "Epoch 750, Train loss 0.0015194924865522342, Test loss 0.48100698703923556, Train accuracy 99.95204603580562, Test accuracy 93.56210443037975, Cost 51.042447328567505 s\n",
      "Model saved in epoch 750\n",
      "Epoch 751, Train loss 0.0032576321369148604, Test loss 0.4975497956517376, Train accuracy 99.8941016624041, Test accuracy 93.40387658227849, Cost 51.06466245651245 s\n",
      "Epoch 752, Train loss 0.0016766576607341033, Test loss 0.4999602229534825, Train accuracy 99.94205562659846, Test accuracy 93.53243670886076, Cost 51.03709530830383 s\n",
      "Epoch 753, Train loss 0.0025095615442521885, Test loss 0.4957029219198076, Train accuracy 99.92407289002557, Test accuracy 93.57199367088607, Cost 51.053109884262085 s\n",
      "Epoch 754, Train loss 0.001910496811958806, Test loss 0.4972284742737118, Train accuracy 99.9440537084399, Test accuracy 93.63132911392405, Cost 51.04158568382263 s\n",
      "Epoch 755, Train loss 0.001497126988856903, Test loss 0.47100410252055036, Train accuracy 99.94005754475704, Test accuracy 93.71044303797468, Cost 51.035576820373535 s\n",
      "Model saved in epoch 755\n",
      "Epoch 756, Train loss 0.001421973225049737, Test loss 0.4632325169594982, Train accuracy 99.95804028132993, Test accuracy 93.41376582278481, Cost 50.97572684288025 s\n",
      "Epoch 757, Train loss 0.0012904218299162496, Test loss 0.4641566304607859, Train accuracy 99.96003836317135, Test accuracy 93.69066455696202, Cost 50.88015794754028 s\n",
      "Epoch 758, Train loss 0.0013248634413962743, Test loss 0.4658309921527965, Train accuracy 99.95404411764706, Test accuracy 93.60166139240506, Cost 50.97355127334595 s\n",
      "Epoch 759, Train loss 0.0014688065451610385, Test loss 0.4710183003092114, Train accuracy 99.95004795396419, Test accuracy 93.57199367088607, Cost 51.149561405181885 s\n",
      "Epoch 760, Train loss 0.0009320432438554046, Test loss 0.46725455973344515, Train accuracy 99.96803069053709, Test accuracy 93.61155063291139, Cost 51.11037278175354 s\n",
      "Model saved in epoch 760\n",
      "Epoch 761, Train loss 0.0015078033841188251, Test loss 0.4654312481797194, Train accuracy 99.94804987212277, Test accuracy 93.64121835443038, Cost 51.04973316192627 s\n",
      "Epoch 762, Train loss 0.0012289580470899897, Test loss 0.47306122102692155, Train accuracy 99.95004795396419, Test accuracy 93.4434335443038, Cost 51.03505873680115 s\n",
      "Epoch 763, Train loss 0.001739855385772268, Test loss 0.4927361140711398, Train accuracy 99.9320652173913, Test accuracy 93.50276898734177, Cost 51.04860544204712 s\n",
      "Epoch 764, Train loss 0.0006129030998043005, Test loss 0.4786924321817446, Train accuracy 99.98201726342711, Test accuracy 93.74011075949367, Cost 51.047017335891724 s\n",
      "Epoch 765, Train loss 0.0008669191555123739, Test loss 0.4790573087579842, Train accuracy 99.96803069053709, Test accuracy 93.64121835443038, Cost 51.003517389297485 s\n",
      "Model saved in epoch 765\n",
      "Epoch 766, Train loss 0.0005864855145432993, Test loss 0.4738943025092535, Train accuracy 99.98601342710998, Test accuracy 93.69066455696202, Cost 51.0169632434845 s\n",
      "Epoch 767, Train loss 0.0011889421874180092, Test loss 0.4815327498260178, Train accuracy 99.95804028132993, Test accuracy 93.66099683544304, Cost 51.03098750114441 s\n",
      "Epoch 768, Train loss 0.0017267545837792444, Test loss 0.48122859359542025, Train accuracy 99.94005754475704, Test accuracy 93.64121835443038, Cost 51.0061092376709 s\n",
      "Epoch 769, Train loss 0.001062715900657746, Test loss 0.4769261299715012, Train accuracy 99.96403452685422, Test accuracy 93.86867088607595, Cost 51.00863027572632 s\n",
      "Epoch 770, Train loss 0.0005940219198571547, Test loss 0.4779041438728948, Train accuracy 99.98001918158567, Test accuracy 93.78955696202532, Cost 51.02920985221863 s\n",
      "Model saved in epoch 770\n",
      "Epoch 771, Train loss 0.0008312404843014075, Test loss 0.4889921257390252, Train accuracy 99.97802109974424, Test accuracy 93.64121835443038, Cost 51.02861976623535 s\n",
      "Epoch 772, Train loss 0.0005226768547815431, Test loss 0.46534549444913864, Train accuracy 99.9880115089514, Test accuracy 93.86867088607595, Cost 51.05542325973511 s\n",
      "Epoch 773, Train loss 0.00031651553189808885, Test loss 0.46119087694000593, Train accuracy 99.99200767263427, Test accuracy 93.9873417721519, Cost 50.875555753707886 s\n",
      "Epoch 774, Train loss 0.0010690620262514038, Test loss 0.4832310404015493, Train accuracy 99.96203644501279, Test accuracy 93.72033227848101, Cost 50.92626476287842 s\n",
      "Epoch 775, Train loss 0.0004473709488817479, Test loss 0.4697712304282792, Train accuracy 99.9880115089514, Test accuracy 93.69066455696202, Cost 50.86869239807129 s\n",
      "Model saved in epoch 775\n",
      "Epoch 776, Train loss 0.0007686489217003659, Test loss 0.5219516919194898, Train accuracy 99.97202685421995, Test accuracy 93.62143987341773, Cost 50.99874210357666 s\n",
      "Epoch 777, Train loss 0.0009587789356423698, Test loss 0.49662892746774456, Train accuracy 99.96203644501279, Test accuracy 93.59177215189874, Cost 51.004037380218506 s\n",
      "Epoch 778, Train loss 0.001214791393855238, Test loss 0.4978094135847273, Train accuracy 99.96803069053709, Test accuracy 93.66099683544304, Cost 51.01088905334473 s\n",
      "Epoch 779, Train loss 0.00048752092411460203, Test loss 0.486202474919301, Train accuracy 99.98401534526855, Test accuracy 93.76977848101266, Cost 51.017911434173584 s\n",
      "Epoch 780, Train loss 0.0008328581296692712, Test loss 0.48925516697802124, Train accuracy 99.97002877237851, Test accuracy 93.77966772151899, Cost 51.01109790802002 s\n",
      "Model saved in epoch 780\n",
      "Epoch 781, Train loss 0.0011156156271811908, Test loss 0.49920361838008787, Train accuracy 99.95404411764706, Test accuracy 93.66099683544304, Cost 51.018089056015015 s\n",
      "Epoch 782, Train loss 0.0005614756497516369, Test loss 0.4879601157352894, Train accuracy 99.98001918158567, Test accuracy 93.66099683544304, Cost 50.971970319747925 s\n",
      "Epoch 783, Train loss 0.0011468198698327144, Test loss 0.5064009083788606, Train accuracy 99.96603260869566, Test accuracy 93.71044303797468, Cost 50.95652151107788 s\n",
      "Epoch 784, Train loss 0.0011078659521910293, Test loss 0.4873815624019768, Train accuracy 99.96003836317135, Test accuracy 93.55221518987342, Cost 50.95834398269653 s\n",
      "Epoch 785, Train loss 0.0007141400830001342, Test loss 0.49320515735617165, Train accuracy 99.97202685421995, Test accuracy 93.50276898734177, Cost 50.966710567474365 s\n",
      "Model saved in epoch 785\n",
      "Epoch 786, Train loss 0.0006196138290059989, Test loss 0.5315664731249025, Train accuracy 99.98001918158567, Test accuracy 93.43354430379746, Cost 50.99633765220642 s\n",
      "Epoch 787, Train loss 0.0023899248031286984, Test loss 0.5167439529035665, Train accuracy 99.92367327365729, Test accuracy 93.2060917721519, Cost 50.9319007396698 s\n",
      "Epoch 788, Train loss 0.0021399281930501186, Test loss 0.5058999609532235, Train accuracy 99.94205562659846, Test accuracy 93.3742088607595, Cost 50.966129302978516 s\n",
      "Epoch 789, Train loss 0.002142388337847362, Test loss 0.4832929303940338, Train accuracy 99.9320652173913, Test accuracy 93.5818829113924, Cost 50.979180097579956 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 790, Train loss 0.0011174054466637198, Test loss 0.492383864578567, Train accuracy 99.9560421994885, Test accuracy 93.59177215189874, Cost 50.785825967788696 s\n",
      "Model saved in epoch 790\n",
      "Epoch 791, Train loss 0.0007704136888774939, Test loss 0.4681001033964036, Train accuracy 99.97202685421995, Test accuracy 93.8488924050633, Cost 54.076733112335205 s\n",
      "Epoch 792, Train loss 0.0010019409765917738, Test loss 0.4913654947959924, Train accuracy 99.97002877237851, Test accuracy 93.49287974683544, Cost 51.020567655563354 s\n",
      "Epoch 793, Train loss 0.001795758532205796, Test loss 0.4931619854856141, Train accuracy 99.93406329923273, Test accuracy 93.26542721518987, Cost 51.030715465545654 s\n",
      "Epoch 794, Train loss 0.0015025211376725781, Test loss 0.4740203453015678, Train accuracy 99.94605179028133, Test accuracy 93.83900316455696, Cost 51.05928421020508 s\n",
      "Epoch 795, Train loss 0.0006130258203940464, Test loss 0.4698456818638723, Train accuracy 99.98001918158567, Test accuracy 93.82911392405063, Cost 51.05180835723877 s\n",
      "Model saved in epoch 795\n",
      "Epoch 796, Train loss 0.0010264870598003003, Test loss 0.4517025808933415, Train accuracy 99.95804028132993, Test accuracy 93.73022151898734, Cost 51.011664152145386 s\n",
      "Epoch 797, Train loss 0.001344232709264668, Test loss 0.4597027029229116, Train accuracy 99.96003836317135, Test accuracy 93.80933544303798, Cost 50.91036891937256 s\n",
      "Epoch 798, Train loss 0.0005825972754431914, Test loss 0.4626989205945519, Train accuracy 99.98201726342711, Test accuracy 93.8192246835443, Cost 50.94337821006775 s\n",
      "Epoch 799, Train loss 0.000917618981907893, Test loss 0.4532630913242509, Train accuracy 99.97002877237851, Test accuracy 93.82911392405063, Cost 51.01710319519043 s\n",
      "Epoch 800, Train loss 0.0009882634326355136, Test loss 0.476599259419909, Train accuracy 99.96403452685422, Test accuracy 93.75, Cost 50.96479630470276 s\n",
      "Model saved in epoch 800\n",
      "Epoch 801, Train loss 0.0008177021050666785, Test loss 0.45837266243334057, Train accuracy 99.96803069053709, Test accuracy 93.67088607594937, Cost 50.951910972595215 s\n",
      "Epoch 802, Train loss 0.0010282284541231767, Test loss 0.45797930945512616, Train accuracy 99.96803069053709, Test accuracy 93.94778481012658, Cost 50.955318212509155 s\n",
      "Epoch 803, Train loss 0.0010258984618252483, Test loss 0.4628042006228544, Train accuracy 99.96403452685422, Test accuracy 93.57199367088607, Cost 50.95569944381714 s\n",
      "Epoch 804, Train loss 0.0009317833130050275, Test loss 0.49737525514409514, Train accuracy 99.97202685421995, Test accuracy 93.52254746835443, Cost 50.97866249084473 s\n",
      "Epoch 805, Train loss 0.0011503563627611726, Test loss 0.4796283308275138, Train accuracy 99.95004795396419, Test accuracy 93.6807753164557, Cost 50.881463050842285 s\n",
      "Model saved in epoch 805\n",
      "Epoch 806, Train loss 0.0017027464207409427, Test loss 0.47983066096336024, Train accuracy 99.94605179028133, Test accuracy 93.79944620253164, Cost 50.88736271858215 s\n",
      "Epoch 807, Train loss 0.0005630110021403722, Test loss 0.4604827723454071, Train accuracy 99.98601342710998, Test accuracy 93.90822784810126, Cost 50.75146198272705 s\n",
      "Epoch 808, Train loss 0.0005660612589670771, Test loss 0.44786826092042503, Train accuracy 99.98201726342711, Test accuracy 94.04667721518987, Cost 50.840449810028076 s\n",
      "Epoch 809, Train loss 0.001137684623369722, Test loss 0.45417044321192973, Train accuracy 99.97002877237851, Test accuracy 93.93789556962025, Cost 51.02064108848572 s\n",
      "Epoch 810, Train loss 0.0003904812597825211, Test loss 0.4623930538191071, Train accuracy 99.9880115089514, Test accuracy 93.75, Cost 51.0394184589386 s\n",
      "Model saved in epoch 810\n",
      "Epoch 811, Train loss 0.0004452319644933075, Test loss 0.45874617899520487, Train accuracy 99.9880115089514, Test accuracy 93.90822784810126, Cost 51.021320819854736 s\n",
      "Epoch 812, Train loss 0.0007198998766500492, Test loss 0.47425948168280757, Train accuracy 99.97802109974424, Test accuracy 93.86867088607595, Cost 50.878830909729004 s\n",
      "Epoch 813, Train loss 0.0020583475946994788, Test loss 0.48613345377807377, Train accuracy 99.94205562659846, Test accuracy 93.73022151898734, Cost 51.032111167907715 s\n",
      "Epoch 814, Train loss 0.0013634643815807592, Test loss 0.4667936412004542, Train accuracy 99.94804987212277, Test accuracy 93.79944620253164, Cost 51.019765853881836 s\n",
      "Epoch 815, Train loss 0.0005907195465455024, Test loss 0.45745904347564603, Train accuracy 99.97802109974424, Test accuracy 93.75988924050633, Cost 50.98342990875244 s\n",
      "Model saved in epoch 815\n",
      "Epoch 816, Train loss 0.0006719561410831581, Test loss 0.48331613324676886, Train accuracy 99.97802109974424, Test accuracy 93.83900316455696, Cost 51.05634546279907 s\n",
      "Epoch 817, Train loss 0.000595035200623442, Test loss 0.4755207891988603, Train accuracy 99.97602301790282, Test accuracy 93.63132911392405, Cost 51.02747178077698 s\n",
      "Epoch 818, Train loss 0.0006949548218324994, Test loss 0.48331677036572107, Train accuracy 99.96803069053709, Test accuracy 93.59177215189874, Cost 50.905447483062744 s\n",
      "Epoch 819, Train loss 0.001162179772539117, Test loss 0.48531790605828734, Train accuracy 99.94804987212277, Test accuracy 93.61155063291139, Cost 50.8971643447876 s\n",
      "Epoch 820, Train loss 0.0011916917642396528, Test loss 0.4733068720920931, Train accuracy 99.95804028132993, Test accuracy 93.6511075949367, Cost 50.911498069763184 s\n",
      "Model saved in epoch 820\n",
      "Epoch 821, Train loss 0.0013982238212695934, Test loss 0.4812794844560985, Train accuracy 99.96603260869566, Test accuracy 93.42365506329114, Cost 50.855812072753906 s\n",
      "Epoch 822, Train loss 0.000846171620869363, Test loss 0.46601773062838786, Train accuracy 99.97202685421995, Test accuracy 93.85878164556962, Cost 50.91237759590149 s\n",
      "Epoch 823, Train loss 0.0006673620764320596, Test loss 0.45987897526614274, Train accuracy 99.98201726342711, Test accuracy 93.79944620253164, Cost 50.89029335975647 s\n",
      "Epoch 824, Train loss 0.0004006545257360111, Test loss 0.4742441475391388, Train accuracy 99.9880115089514, Test accuracy 93.78955696202532, Cost 50.828665018081665 s\n",
      "Epoch 825, Train loss 0.00037828478447193256, Test loss 0.4904084525342229, Train accuracy 99.98601342710998, Test accuracy 93.72033227848101, Cost 50.84984493255615 s\n",
      "Model saved in epoch 825\n",
      "Epoch 826, Train loss 0.0009206085106364559, Test loss 0.4687250466380693, Train accuracy 99.97002877237851, Test accuracy 93.75988924050633, Cost 51.05314517021179 s\n",
      "Epoch 827, Train loss 0.0004467706281760518, Test loss 0.4872668576957304, Train accuracy 99.98201726342711, Test accuracy 93.61155063291139, Cost 51.05337882041931 s\n",
      "Epoch 828, Train loss 0.0011643389684848618, Test loss 0.500738693566262, Train accuracy 99.9560421994885, Test accuracy 93.30498417721519, Cost 51.05555558204651 s\n",
      "Epoch 829, Train loss 0.0010829468634554655, Test loss 0.46528460104254227, Train accuracy 99.96803069053709, Test accuracy 93.76977848101266, Cost 51.04778504371643 s\n",
      "Epoch 830, Train loss 0.0006914039106980179, Test loss 0.46935174689639975, Train accuracy 99.97802109974424, Test accuracy 93.93789556962025, Cost 51.034257888793945 s\n",
      "Model saved in epoch 830\n",
      "Epoch 831, Train loss 0.0002650437896295763, Test loss 0.4674093361142315, Train accuracy 99.99600383631713, Test accuracy 93.85878164556962, Cost 50.915274143218994 s\n",
      "Epoch 832, Train loss 0.00023818147332267333, Test loss 0.45950925218153604, Train accuracy 99.99400575447571, Test accuracy 93.80933544303798, Cost 50.85378694534302 s\n",
      "Epoch 833, Train loss 0.00039683080545695225, Test loss 0.46382656061573874, Train accuracy 99.9880115089514, Test accuracy 93.99723101265823, Cost 50.93293762207031 s\n",
      "Epoch 834, Train loss 0.00018086466138186243, Test loss 0.45924341659757156, Train accuracy 99.99400575447571, Test accuracy 94.02689873417721, Cost 51.03497648239136 s\n",
      "Epoch 835, Train loss 0.00014840204518453402, Test loss 0.47375929949781564, Train accuracy 99.99800191815856, Test accuracy 94.0565664556962, Cost 51.02215385437012 s\n",
      "Model saved in epoch 835\n",
      "Epoch 836, Train loss 0.000252979039652333, Test loss 0.47421793899015535, Train accuracy 99.99600383631713, Test accuracy 93.90822784810126, Cost 51.041528940200806 s\n",
      "Epoch 837, Train loss 0.0003004657136442766, Test loss 0.48734570615276507, Train accuracy 99.99000959079284, Test accuracy 93.75, Cost 51.04613733291626 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 838, Train loss 0.00030656870177628423, Test loss 0.484214118245659, Train accuracy 99.99000959079284, Test accuracy 93.50276898734177, Cost 51.024405002593994 s\n",
      "Epoch 839, Train loss 0.00037203352885491534, Test loss 0.4964851664402817, Train accuracy 99.99000959079284, Test accuracy 93.79944620253164, Cost 51.02354335784912 s\n",
      "Epoch 840, Train loss 0.00042772228737571693, Test loss 0.5278494459918782, Train accuracy 99.97802109974424, Test accuracy 93.55221518987342, Cost 50.81657147407532 s\n",
      "Model saved in epoch 840\n",
      "Epoch 841, Train loss 0.000629747492390499, Test loss 0.5034401129129566, Train accuracy 99.97802109974424, Test accuracy 93.78955696202532, Cost 50.936068296432495 s\n",
      "Epoch 842, Train loss 0.0009336040675015477, Test loss 0.5169655604264404, Train accuracy 99.96603260869566, Test accuracy 93.75, Cost 50.89151573181152 s\n",
      "Epoch 843, Train loss 0.0006707127814264338, Test loss 0.5104030860187132, Train accuracy 99.97602301790282, Test accuracy 93.73022151898734, Cost 50.956762075424194 s\n",
      "Epoch 844, Train loss 0.0010142901219628083, Test loss 0.48932218617653545, Train accuracy 99.96003836317135, Test accuracy 93.76977848101266, Cost 50.96270537376404 s\n",
      "Epoch 845, Train loss 0.0014851861382546433, Test loss 0.5237828648731678, Train accuracy 99.9560421994885, Test accuracy 93.47310126582279, Cost 50.946364641189575 s\n",
      "Model saved in epoch 845\n",
      "Epoch 846, Train loss 0.0006794273664272339, Test loss 0.48604538216243814, Train accuracy 99.97802109974424, Test accuracy 93.8192246835443, Cost 50.92916917800903 s\n",
      "Epoch 847, Train loss 0.0018929380886621781, Test loss 0.5068359495718268, Train accuracy 99.94005754475704, Test accuracy 93.59177215189874, Cost 50.90344023704529 s\n",
      "Epoch 848, Train loss 0.001175365668603247, Test loss 0.5070351728155643, Train accuracy 99.96203644501279, Test accuracy 93.41376582278481, Cost 51.00908875465393 s\n",
      "Epoch 849, Train loss 0.001473669227572061, Test loss 0.4980616520477247, Train accuracy 99.95804028132993, Test accuracy 93.56210443037975, Cost 51.04761457443237 s\n",
      "Epoch 850, Train loss 0.0011802016143465787, Test loss 0.500434252091601, Train accuracy 99.95004795396419, Test accuracy 93.48299050632912, Cost 50.99614214897156 s\n",
      "Model saved in epoch 850\n",
      "Epoch 851, Train loss 0.0008059861841527794, Test loss 0.49011600144867656, Train accuracy 99.97682225063939, Test accuracy 93.76977848101266, Cost 50.986390829086304 s\n",
      "Epoch 852, Train loss 0.0009194710690061902, Test loss 0.5098517067565382, Train accuracy 99.97402493606138, Test accuracy 93.61155063291139, Cost 51.00501084327698 s\n",
      "Epoch 853, Train loss 0.0006871152608663151, Test loss 0.514508080822003, Train accuracy 99.97602301790282, Test accuracy 93.43354430379746, Cost 51.03144192695618 s\n",
      "Epoch 854, Train loss 0.0006155786537828052, Test loss 0.5119520245662218, Train accuracy 99.96803069053709, Test accuracy 93.77966772151899, Cost 51.0087456703186 s\n",
      "Epoch 855, Train loss 0.0005543913818817154, Test loss 0.5127848014235497, Train accuracy 99.98601342710998, Test accuracy 93.5818829113924, Cost 50.90168309211731 s\n",
      "Model saved in epoch 855\n",
      "Epoch 856, Train loss 0.0012520952062241187, Test loss 0.49296047198998777, Train accuracy 99.96403452685422, Test accuracy 93.73022151898734, Cost 50.930201292037964 s\n",
      "Epoch 857, Train loss 0.0009043525637074806, Test loss 0.5067470554686799, Train accuracy 99.96403452685422, Test accuracy 93.75988924050633, Cost 50.697887659072876 s\n",
      "Epoch 858, Train loss 0.001013254197484888, Test loss 0.49744238317767275, Train accuracy 99.96403452685422, Test accuracy 93.67088607594937, Cost 50.82101488113403 s\n",
      "Epoch 859, Train loss 0.0007501882004507576, Test loss 0.49083290329273743, Train accuracy 99.97402493606138, Test accuracy 93.64121835443038, Cost 50.92483639717102 s\n",
      "Epoch 860, Train loss 0.000999324543983793, Test loss 0.5029078427749344, Train accuracy 99.96203644501279, Test accuracy 93.52254746835443, Cost 50.97543263435364 s\n",
      "Model saved in epoch 860\n",
      "Epoch 861, Train loss 0.0005315930172807976, Test loss 0.47551099871155583, Train accuracy 99.98201726342711, Test accuracy 93.92800632911393, Cost 50.97281742095947 s\n",
      "Epoch 862, Train loss 0.00035926763618786636, Test loss 0.48293068976719167, Train accuracy 99.99000959079284, Test accuracy 93.86867088607595, Cost 51.01840424537659 s\n",
      "Epoch 863, Train loss 0.0005116174085607802, Test loss 0.4914790639017202, Train accuracy 99.97402493606138, Test accuracy 93.76977848101266, Cost 51.01830196380615 s\n",
      "Epoch 864, Train loss 0.00023391336566076573, Test loss 0.47782556472133986, Train accuracy 99.99400575447571, Test accuracy 93.88844936708861, Cost 51.034558057785034 s\n",
      "Epoch 865, Train loss 0.00012728152189009378, Test loss 0.48172851288809054, Train accuracy 99.99800191815856, Test accuracy 93.85878164556962, Cost 51.02852439880371 s\n",
      "Model saved in epoch 865\n",
      "Epoch 866, Train loss 0.00020934778923226106, Test loss 0.48154083625236643, Train accuracy 99.99200767263427, Test accuracy 93.89833860759494, Cost 51.02392864227295 s\n",
      "Epoch 867, Train loss 0.0006328077038721026, Test loss 0.5162901976440526, Train accuracy 99.98001918158567, Test accuracy 93.71044303797468, Cost 50.97825336456299 s\n",
      "Epoch 868, Train loss 0.0008903302285777259, Test loss 0.49815707946125465, Train accuracy 99.96803069053709, Test accuracy 93.82911392405063, Cost 50.959636926651 s\n",
      "Epoch 869, Train loss 0.0005072929792337687, Test loss 0.5188158137511604, Train accuracy 99.98401534526855, Test accuracy 93.63132911392405, Cost 51.07714080810547 s\n",
      "Epoch 870, Train loss 0.0006453005926152477, Test loss 0.49658268812713746, Train accuracy 99.9880115089514, Test accuracy 93.57199367088607, Cost 51.07357573509216 s\n",
      "Model saved in epoch 870\n",
      "Epoch 871, Train loss 0.00020326503402081552, Test loss 0.5010103916254225, Train accuracy 99.99480498721228, Test accuracy 93.60166139240506, Cost 51.06921148300171 s\n",
      "Epoch 872, Train loss 0.0012464598801215107, Test loss 0.5117646672680408, Train accuracy 99.97002877237851, Test accuracy 93.59177215189874, Cost 50.93749475479126 s\n",
      "Epoch 873, Train loss 0.0012275728223957237, Test loss 0.5187772303065167, Train accuracy 99.95004795396419, Test accuracy 93.53243670886076, Cost 50.95983934402466 s\n",
      "Epoch 874, Train loss 0.0005267936174552261, Test loss 0.5509418168965774, Train accuracy 99.9880115089514, Test accuracy 93.29509493670886, Cost 50.721128702163696 s\n",
      "Epoch 875, Train loss 0.0005663568512118555, Test loss 0.5089631791733489, Train accuracy 99.98001918158567, Test accuracy 93.71044303797468, Cost 50.79478454589844 s\n",
      "Model saved in epoch 875\n",
      "Epoch 876, Train loss 0.000646978825548621, Test loss 0.5101634626147113, Train accuracy 99.98201726342711, Test accuracy 93.50276898734177, Cost 50.96385955810547 s\n",
      "Epoch 877, Train loss 0.0012166678570875876, Test loss 0.5183250160911416, Train accuracy 99.9560421994885, Test accuracy 93.4434335443038, Cost 50.95159864425659 s\n",
      "Epoch 878, Train loss 0.0006709735381078496, Test loss 0.498697095185141, Train accuracy 99.97802109974424, Test accuracy 93.82911392405063, Cost 50.964622497558594 s\n",
      "Epoch 879, Train loss 0.0005781861934860652, Test loss 0.5252920491031453, Train accuracy 99.97802109974424, Test accuracy 93.53243670886076, Cost 50.96694874763489 s\n",
      "Epoch 880, Train loss 0.0011237552862967135, Test loss 0.5046633506500269, Train accuracy 99.96003836317135, Test accuracy 93.79944620253164, Cost 50.96919512748718 s\n",
      "Model saved in epoch 880\n",
      "Epoch 881, Train loss 0.0011658618251952294, Test loss 0.5442911361025858, Train accuracy 99.95404411764706, Test accuracy 93.52254746835443, Cost 51.007073640823364 s\n",
      "Epoch 882, Train loss 0.0014211258292002923, Test loss 0.5373637177333047, Train accuracy 99.94005754475704, Test accuracy 93.11708860759494, Cost 51.02290105819702 s\n",
      "Epoch 883, Train loss 0.0014981142435873528, Test loss 0.5397029986864403, Train accuracy 99.95004795396419, Test accuracy 93.47310126582279, Cost 50.97350835800171 s\n",
      "Epoch 884, Train loss 0.0017139002075378137, Test loss 0.4999946488798419, Train accuracy 99.9380594629156, Test accuracy 93.43354430379746, Cost 51.008002042770386 s\n",
      "Epoch 885, Train loss 0.0008485748425044976, Test loss 0.468663454621653, Train accuracy 99.97002877237851, Test accuracy 93.75, Cost 50.986905574798584 s\n",
      "Model saved in epoch 885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 886, Train loss 0.001265107531563474, Test loss 0.5233007602487938, Train accuracy 99.96003836317135, Test accuracy 93.43354430379746, Cost 50.97059941291809 s\n",
      "Epoch 887, Train loss 0.0007536556137036844, Test loss 0.49666050265106976, Train accuracy 99.96403452685422, Test accuracy 93.3445411392405, Cost 50.96107339859009 s\n",
      "Epoch 888, Train loss 0.0009939885672235712, Test loss 0.49825747641204277, Train accuracy 99.96003836317135, Test accuracy 93.49287974683544, Cost 51.01236295700073 s\n",
      "Epoch 889, Train loss 0.00106209660221528, Test loss 0.504385834253287, Train accuracy 99.96403452685422, Test accuracy 93.60166139240506, Cost 51.01159882545471 s\n",
      "Epoch 890, Train loss 0.0006263739263869845, Test loss 0.49827139881215515, Train accuracy 99.98201726342711, Test accuracy 93.69066455696202, Cost 50.921021938323975 s\n",
      "Model saved in epoch 890\n",
      "Epoch 891, Train loss 0.0008214135549748686, Test loss 0.48860778272906435, Train accuracy 99.96803069053709, Test accuracy 93.48299050632912, Cost 50.91479420661926 s\n",
      "Epoch 892, Train loss 0.0007839054697089693, Test loss 0.4891325136340117, Train accuracy 99.97802109974424, Test accuracy 93.73022151898734, Cost 50.89806818962097 s\n",
      "Epoch 893, Train loss 0.0011853134298392973, Test loss 0.4874468033638182, Train accuracy 99.95404411764706, Test accuracy 93.6807753164557, Cost 51.06732177734375 s\n",
      "Epoch 894, Train loss 0.001020902540737559, Test loss 0.49321399987498415, Train accuracy 99.96203644501279, Test accuracy 93.62143987341773, Cost 51.06384634971619 s\n",
      "Epoch 895, Train loss 0.0009039610724127781, Test loss 0.49451472713977473, Train accuracy 99.96403452685422, Test accuracy 93.41376582278481, Cost 51.04754900932312 s\n",
      "Model saved in epoch 895\n",
      "Epoch 896, Train loss 0.00048599177695278506, Test loss 0.5121190058468263, Train accuracy 99.98601342710998, Test accuracy 93.43354430379746, Cost 51.048649311065674 s\n",
      "Epoch 897, Train loss 0.0004960006662810318, Test loss 0.5098865927444606, Train accuracy 99.98401534526855, Test accuracy 93.64121835443038, Cost 51.061662435531616 s\n",
      "Epoch 898, Train loss 0.000421877597821321, Test loss 0.49606697242471237, Train accuracy 99.9880115089514, Test accuracy 93.79944620253164, Cost 51.059791803359985 s\n",
      "Epoch 899, Train loss 0.0010974290967903676, Test loss 0.49021919925190227, Train accuracy 99.96403452685422, Test accuracy 93.67088607594937, Cost 51.02798938751221 s\n",
      "Epoch 900, Train loss 0.0007364941036596322, Test loss 0.5072633340200291, Train accuracy 99.97602301790282, Test accuracy 93.75988924050633, Cost 51.04340386390686 s\n",
      "Model saved in epoch 900\n",
      "Epoch 901, Train loss 0.0007362974066959605, Test loss 0.5441035085086581, Train accuracy 99.97202685421995, Test accuracy 93.45332278481013, Cost 51.064366817474365 s\n",
      "Epoch 902, Train loss 0.0006878910016891316, Test loss 0.49720950424671173, Train accuracy 99.97402493606138, Test accuracy 93.56210443037975, Cost 51.03514099121094 s\n",
      "Epoch 903, Train loss 0.00039120903136328713, Test loss 0.49797946846560587, Train accuracy 99.98601342710998, Test accuracy 93.63132911392405, Cost 51.00834131240845 s\n",
      "Epoch 904, Train loss 0.0005199744601161342, Test loss 0.5068993359992776, Train accuracy 99.98201726342711, Test accuracy 93.59177215189874, Cost 50.95188546180725 s\n",
      "Epoch 905, Train loss 0.0004010180494940759, Test loss 0.49319689796317984, Train accuracy 99.9880115089514, Test accuracy 93.73022151898734, Cost 50.97157692909241 s\n",
      "Model saved in epoch 905\n",
      "Epoch 906, Train loss 0.00028909645242050305, Test loss 0.5069976365075836, Train accuracy 99.99400575447571, Test accuracy 93.57199367088607, Cost 50.91582155227661 s\n",
      "Epoch 907, Train loss 0.0001677158279878192, Test loss 0.48351785333096226, Train accuracy 99.99800191815856, Test accuracy 93.75, Cost 50.72789645195007 s\n",
      "Epoch 908, Train loss 0.00010082388810150207, Test loss 0.4796132272274434, Train accuracy 100.0, Test accuracy 93.76977848101266, Cost 50.92396879196167 s\n",
      "Epoch 909, Train loss 0.00012508863920090616, Test loss 0.47703979268104213, Train accuracy 99.99800191815856, Test accuracy 93.8488924050633, Cost 50.83984708786011 s\n",
      "Epoch 910, Train loss 0.0007483175832028603, Test loss 0.502707873718648, Train accuracy 99.97402493606138, Test accuracy 93.42365506329114, Cost 50.993996143341064 s\n",
      "Model saved in epoch 910\n",
      "Epoch 911, Train loss 0.000806861845805467, Test loss 0.4967041926199122, Train accuracy 99.98201726342711, Test accuracy 93.49287974683544, Cost 51.01158380508423 s\n",
      "Epoch 912, Train loss 0.0003252658884472403, Test loss 0.48879524178897277, Train accuracy 99.99000959079284, Test accuracy 93.5126582278481, Cost 51.014647245407104 s\n",
      "Epoch 913, Train loss 0.0003921183285271286, Test loss 0.48516926046790954, Train accuracy 99.9880115089514, Test accuracy 93.50276898734177, Cost 51.034127712249756 s\n",
      "Epoch 914, Train loss 0.0005106412877428048, Test loss 0.4809644557064093, Train accuracy 99.98201726342711, Test accuracy 93.82911392405063, Cost 51.021233320236206 s\n",
      "Epoch 915, Train loss 0.00037233488736558074, Test loss 0.48435541779934604, Train accuracy 99.98481457800511, Test accuracy 93.92800632911393, Cost 51.004645586013794 s\n",
      "Model saved in epoch 915\n",
      "Epoch 916, Train loss 0.0006400822921392473, Test loss 0.5057365814860486, Train accuracy 99.97602301790282, Test accuracy 93.72033227848101, Cost 51.016371726989746 s\n",
      "Epoch 917, Train loss 0.0002677339254995537, Test loss 0.4947622087843056, Train accuracy 99.99400575447571, Test accuracy 93.80933544303798, Cost 50.95050573348999 s\n",
      "Epoch 918, Train loss 0.0004916442346394374, Test loss 0.5157541866897594, Train accuracy 99.98001918158567, Test accuracy 93.83900316455696, Cost 50.97730016708374 s\n",
      "Epoch 919, Train loss 0.0005064660177039901, Test loss 0.5143950125556204, Train accuracy 99.9880115089514, Test accuracy 93.88844936708861, Cost 50.96151566505432 s\n",
      "Epoch 920, Train loss 0.0006625172694904623, Test loss 0.5027625285371949, Train accuracy 99.97682225063939, Test accuracy 93.83900316455696, Cost 50.96249032020569 s\n",
      "Model saved in epoch 920\n",
      "Epoch 921, Train loss 0.0017987289040193185, Test loss 0.5082196301863163, Train accuracy 99.9440537084399, Test accuracy 93.48299050632912, Cost 50.97171378135681 s\n",
      "Epoch 922, Train loss 0.0017345883838634068, Test loss 0.5108378310275229, Train accuracy 99.95204603580562, Test accuracy 93.50276898734177, Cost 50.95355439186096 s\n",
      "Epoch 923, Train loss 0.0010860292149809747, Test loss 0.506744478393016, Train accuracy 99.9588395140665, Test accuracy 93.59177215189874, Cost 50.961665630340576 s\n",
      "Epoch 924, Train loss 0.001204298498946238, Test loss 0.5050380472329599, Train accuracy 99.96403452685422, Test accuracy 93.53243670886076, Cost 50.71540975570679 s\n",
      "Epoch 925, Train loss 0.0012528007017582837, Test loss 0.5058626861464751, Train accuracy 99.96803069053709, Test accuracy 93.59177215189874, Cost 50.853142976760864 s\n",
      "Model saved in epoch 925\n",
      "Epoch 926, Train loss 0.0006067025761587277, Test loss 0.4948391593650832, Train accuracy 99.97802109974424, Test accuracy 93.64121835443038, Cost 50.91857886314392 s\n",
      "Epoch 927, Train loss 0.0012188737785146647, Test loss 0.5196872289422192, Train accuracy 99.96003836317135, Test accuracy 93.12697784810126, Cost 50.94358205795288 s\n",
      "Epoch 928, Train loss 0.0012157062549543562, Test loss 0.5106710308714758, Train accuracy 99.95004795396419, Test accuracy 93.3742088607595, Cost 50.971091747283936 s\n",
      "Epoch 929, Train loss 0.0007990550177194685, Test loss 0.5004128928331635, Train accuracy 99.97802109974424, Test accuracy 93.67088607594937, Cost 50.97926425933838 s\n",
      "Epoch 930, Train loss 0.00044730193060594066, Test loss 0.5144322598470917, Train accuracy 99.98601342710998, Test accuracy 93.6807753164557, Cost 50.96152377128601 s\n",
      "Model saved in epoch 930\n",
      "Epoch 931, Train loss 0.0003129826414081077, Test loss 0.4949192454731917, Train accuracy 99.9880115089514, Test accuracy 93.80933544303798, Cost 50.96797251701355 s\n",
      "Epoch 932, Train loss 0.0010157810481812705, Test loss 0.5054993286162992, Train accuracy 99.97202685421995, Test accuracy 93.6511075949367, Cost 50.94543695449829 s\n",
      "Epoch 933, Train loss 0.0009757127559637507, Test loss 0.49668693900862826, Train accuracy 99.96203644501279, Test accuracy 93.83900316455696, Cost 50.956286907196045 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 934, Train loss 0.0007110539188971861, Test loss 0.5202383372602584, Train accuracy 99.97802109974424, Test accuracy 93.76977848101266, Cost 50.95953154563904 s\n",
      "Epoch 935, Train loss 0.0007641631011207285, Test loss 0.5298253211039531, Train accuracy 99.97602301790282, Test accuracy 93.6807753164557, Cost 50.963507652282715 s\n",
      "Model saved in epoch 935\n",
      "Epoch 936, Train loss 0.0009866031219854647, Test loss 0.5136760527951808, Train accuracy 99.96803069053709, Test accuracy 93.6807753164557, Cost 50.980671644210815 s\n",
      "Epoch 937, Train loss 0.00043692602459997524, Test loss 0.5246492567696149, Train accuracy 99.99000959079284, Test accuracy 93.5126582278481, Cost 50.881274700164795 s\n",
      "Epoch 938, Train loss 0.0011171948498772016, Test loss 0.5351774926427044, Train accuracy 99.97002877237851, Test accuracy 93.53243670886076, Cost 50.89263081550598 s\n",
      "Epoch 939, Train loss 0.0004004473226092343, Test loss 0.5101871950716912, Train accuracy 99.9880115089514, Test accuracy 93.75, Cost 50.85189437866211 s\n",
      "Epoch 940, Train loss 0.0005928980894125022, Test loss 0.518331674269483, Train accuracy 99.98001918158567, Test accuracy 93.56210443037975, Cost 50.8592529296875 s\n",
      "Model saved in epoch 940\n",
      "Epoch 941, Train loss 0.0004857703022239234, Test loss 0.5116248657054538, Train accuracy 99.98201726342711, Test accuracy 93.92800632911393, Cost 50.64088535308838 s\n",
      "Epoch 942, Train loss 0.0008371903770645669, Test loss 0.5099877676914765, Train accuracy 99.97202685421995, Test accuracy 93.66099683544304, Cost 50.917683362960815 s\n",
      "Epoch 943, Train loss 0.0006633623409341414, Test loss 0.511122949067739, Train accuracy 99.97402493606138, Test accuracy 93.89833860759494, Cost 51.02593469619751 s\n",
      "Epoch 944, Train loss 0.0013743708422935207, Test loss 0.5155303045824359, Train accuracy 99.96003836317135, Test accuracy 93.72033227848101, Cost 51.03356099128723 s\n",
      "Epoch 945, Train loss 0.0005865280998104131, Test loss 0.510751063900092, Train accuracy 99.97202685421995, Test accuracy 93.77966772151899, Cost 51.050307512283325 s\n",
      "Model saved in epoch 945\n",
      "Epoch 946, Train loss 0.0005012485634912027, Test loss 0.5029812243920339, Train accuracy 99.98601342710998, Test accuracy 93.60166139240506, Cost 51.085405588150024 s\n",
      "Epoch 947, Train loss 0.0005909142279060171, Test loss 0.5188292158366758, Train accuracy 99.97802109974424, Test accuracy 93.6807753164557, Cost 51.076570987701416 s\n",
      "Epoch 948, Train loss 0.0005424220746088876, Test loss 0.534590927624627, Train accuracy 99.98201726342711, Test accuracy 93.59177215189874, Cost 51.06558609008789 s\n",
      "Epoch 949, Train loss 0.000748920922350378, Test loss 0.5100374707504164, Train accuracy 99.96803069053709, Test accuracy 93.78955696202532, Cost 51.02614378929138 s\n",
      "Epoch 950, Train loss 0.0010882945717863189, Test loss 0.508463823248314, Train accuracy 99.96603260869566, Test accuracy 93.75, Cost 51.019187450408936 s\n",
      "Model saved in epoch 950\n",
      "Epoch 951, Train loss 0.0010908027420411374, Test loss 0.5110564801511885, Train accuracy 99.97002877237851, Test accuracy 93.63132911392405, Cost 51.081334829330444 s\n",
      "Epoch 952, Train loss 0.0014977697295692845, Test loss 0.5195976828661146, Train accuracy 99.9560421994885, Test accuracy 93.60166139240506, Cost 51.04723000526428 s\n",
      "Epoch 953, Train loss 0.0007128063643295347, Test loss 0.5223936976369801, Train accuracy 99.97802109974424, Test accuracy 93.77966772151899, Cost 51.0539333820343 s\n",
      "Epoch 954, Train loss 0.00041170988215316373, Test loss 0.508205493888523, Train accuracy 99.9880115089514, Test accuracy 93.74011075949367, Cost 51.0604453086853 s\n",
      "Epoch 955, Train loss 0.0001501801517888299, Test loss 0.5036348856608325, Train accuracy 99.99800191815856, Test accuracy 93.8488924050633, Cost 51.03148365020752 s\n",
      "Model saved in epoch 955\n",
      "Epoch 956, Train loss 0.00033791520291928505, Test loss 0.5002014093761202, Train accuracy 99.99200767263427, Test accuracy 93.71044303797468, Cost 51.02229619026184 s\n",
      "Epoch 957, Train loss 0.0004873961696503925, Test loss 0.5170465326761897, Train accuracy 99.98201726342711, Test accuracy 93.53243670886076, Cost 50.92286562919617 s\n",
      "Epoch 958, Train loss 0.00080278663923865, Test loss 0.4969718868408022, Train accuracy 99.97602301790282, Test accuracy 93.75988924050633, Cost 50.83220934867859 s\n",
      "Epoch 959, Train loss 0.0018301219209705044, Test loss 0.5103629746391803, Train accuracy 99.95404411764706, Test accuracy 93.59177215189874, Cost 50.845417976379395 s\n",
      "Epoch 960, Train loss 0.0010388315184112784, Test loss 0.4937475628302067, Train accuracy 99.96803069053709, Test accuracy 93.86867088607595, Cost 51.03425073623657 s\n",
      "Model saved in epoch 960\n",
      "Epoch 961, Train loss 0.0008184303097481381, Test loss 0.5048864402725727, Train accuracy 99.98001918158567, Test accuracy 93.70055379746836, Cost 51.05187463760376 s\n",
      "Epoch 962, Train loss 0.0007838904770830799, Test loss 0.493927005819882, Train accuracy 99.97802109974424, Test accuracy 93.8192246835443, Cost 51.03795623779297 s\n",
      "Epoch 963, Train loss 0.000305228377022107, Test loss 0.4908937870795968, Train accuracy 99.99200767263427, Test accuracy 93.75988924050633, Cost 50.971189975738525 s\n",
      "Epoch 964, Train loss 0.0003326318847472733, Test loss 0.4899312555318392, Train accuracy 99.9880115089514, Test accuracy 93.99723101265823, Cost 51.02932167053223 s\n",
      "Epoch 965, Train loss 0.0010162377555614495, Test loss 0.5150969818800311, Train accuracy 99.96603260869566, Test accuracy 93.71044303797468, Cost 51.04471135139465 s\n",
      "Model saved in epoch 965\n",
      "Epoch 966, Train loss 0.0008569085022865366, Test loss 0.486919202877185, Train accuracy 99.97602301790282, Test accuracy 93.72033227848101, Cost 51.03889989852905 s\n",
      "Epoch 967, Train loss 0.0006408893025784072, Test loss 0.4898281099298332, Train accuracy 99.97402493606138, Test accuracy 93.92800632911393, Cost 50.99989128112793 s\n",
      "Epoch 968, Train loss 0.0005899100368681291, Test loss 0.4948703125590765, Train accuracy 99.98001918158567, Test accuracy 93.87856012658227, Cost 50.95021843910217 s\n",
      "Epoch 969, Train loss 0.0005305458268300199, Test loss 0.4957827454362112, Train accuracy 99.97802109974424, Test accuracy 93.93789556962025, Cost 51.02035713195801 s\n",
      "Epoch 970, Train loss 0.0002798918648387701, Test loss 0.4893953766013625, Train accuracy 99.99000959079284, Test accuracy 93.83900316455696, Cost 51.032793283462524 s\n",
      "Model saved in epoch 970\n",
      "Epoch 971, Train loss 0.0005919709469443732, Test loss 0.504035498522505, Train accuracy 99.98401534526855, Test accuracy 93.83900316455696, Cost 51.00787806510925 s\n",
      "Epoch 972, Train loss 0.00023473902081152116, Test loss 0.48971008957375456, Train accuracy 99.99400575447571, Test accuracy 93.99723101265823, Cost 51.010995864868164 s\n",
      "Epoch 973, Train loss 0.0006732514104995876, Test loss 0.48304548571947253, Train accuracy 99.98201726342711, Test accuracy 93.66099683544304, Cost 51.01583385467529 s\n",
      "Epoch 974, Train loss 0.0005610717794725087, Test loss 0.47977998390605175, Train accuracy 99.98201726342711, Test accuracy 94.03678797468355, Cost 50.82553267478943 s\n",
      "Epoch 975, Train loss 0.00042402078353871026, Test loss 0.47897029036208044, Train accuracy 99.98401534526855, Test accuracy 94.11590189873418, Cost 50.93266987800598 s\n",
      "Model saved in epoch 975\n",
      "Epoch 976, Train loss 0.00061220549504396, Test loss 0.5038936557366124, Train accuracy 99.98001918158567, Test accuracy 93.70055379746836, Cost 50.895928621292114 s\n",
      "Epoch 977, Train loss 0.001003824491414912, Test loss 0.5016236755100987, Train accuracy 99.96403452685422, Test accuracy 93.83900316455696, Cost 51.08536434173584 s\n",
      "Epoch 978, Train loss 0.0007557713434902297, Test loss 0.5048116769028616, Train accuracy 99.98001918158567, Test accuracy 93.72033227848101, Cost 51.02676177024841 s\n",
      "Epoch 979, Train loss 0.0027514246685605478, Test loss 0.496094998962517, Train accuracy 99.92207480818415, Test accuracy 93.59177215189874, Cost 51.03860020637512 s\n",
      "Epoch 980, Train loss 0.0007418095006752959, Test loss 0.49161669960882093, Train accuracy 99.96803069053709, Test accuracy 93.83900316455696, Cost 51.01716947555542 s\n",
      "Model saved in epoch 980\n",
      "Epoch 981, Train loss 0.0008742763011570689, Test loss 0.49826207615529433, Train accuracy 99.96803069053709, Test accuracy 93.66099683544304, Cost 50.95925545692444 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 982, Train loss 0.0007640040580239594, Test loss 0.4954411679808098, Train accuracy 99.98001918158567, Test accuracy 93.46321202531645, Cost 50.993666887283325 s\n",
      "Epoch 983, Train loss 0.0006831836979635998, Test loss 0.48890628156405463, Train accuracy 99.98201726342711, Test accuracy 93.62143987341773, Cost 51.02284502983093 s\n",
      "Epoch 984, Train loss 0.0012741571967300547, Test loss 0.5134918690670894, Train accuracy 99.95684143222506, Test accuracy 93.53243670886076, Cost 51.024476051330566 s\n",
      "Epoch 985, Train loss 0.001760507435611697, Test loss 0.4942550711050818, Train accuracy 99.9320652173913, Test accuracy 93.48299050632912, Cost 51.022512912750244 s\n",
      "Model saved in epoch 985\n",
      "Epoch 986, Train loss 0.0009263674845491358, Test loss 0.48027043138878256, Train accuracy 99.97602301790282, Test accuracy 93.94778481012658, Cost 51.03384780883789 s\n",
      "Epoch 987, Train loss 0.0013723219616360108, Test loss 0.49443425653101525, Train accuracy 99.96003836317135, Test accuracy 93.77966772151899, Cost 51.026588678359985 s\n",
      "Epoch 988, Train loss 0.0002920941688799162, Test loss 0.49273890610548515, Train accuracy 99.99600383631713, Test accuracy 93.69066455696202, Cost 51.06075954437256 s\n",
      "Epoch 989, Train loss 0.0003389746286218877, Test loss 0.500025783913045, Train accuracy 99.99000959079284, Test accuracy 93.89833860759494, Cost 51.02538442611694 s\n",
      "Epoch 990, Train loss 0.0009822413607923548, Test loss 0.5106127205528791, Train accuracy 99.97402493606138, Test accuracy 93.67088607594937, Cost 51.0484254360199 s\n",
      "Model saved in epoch 990\n",
      "Epoch 991, Train loss 0.0005464838560623256, Test loss 0.49599141523807866, Train accuracy 99.98001918158567, Test accuracy 93.6511075949367, Cost 50.796135902404785 s\n",
      "Epoch 992, Train loss 0.0003755778383515404, Test loss 0.5099619376367028, Train accuracy 99.9880115089514, Test accuracy 93.72033227848101, Cost 50.92836093902588 s\n",
      "Epoch 993, Train loss 0.0004335482442125385, Test loss 0.5160024330208574, Train accuracy 99.9880115089514, Test accuracy 93.73022151898734, Cost 51.01524019241333 s\n",
      "Epoch 994, Train loss 0.00033798846730747354, Test loss 0.4872057851922663, Train accuracy 99.99000959079284, Test accuracy 93.80933544303798, Cost 51.07839918136597 s\n",
      "Epoch 995, Train loss 0.00020259105736952207, Test loss 0.48758688625655594, Train accuracy 99.99400575447571, Test accuracy 93.88844936708861, Cost 51.06486654281616 s\n",
      "Model saved in epoch 995\n",
      "Epoch 996, Train loss 0.0002960894460065664, Test loss 0.48602515605242946, Train accuracy 99.99600383631713, Test accuracy 93.87856012658227, Cost 51.032264709472656 s\n",
      "Epoch 997, Train loss 0.000250991496885157, Test loss 0.48805288055652307, Train accuracy 99.99200767263427, Test accuracy 93.80933544303798, Cost 67.47691011428833 s\n",
      "Epoch 998, Train loss 0.0001629087530721167, Test loss 0.49047338462705853, Train accuracy 99.99800191815856, Test accuracy 93.92800632911393, Cost 71.80308318138123 s\n",
      "Epoch 999, Train loss 0.0004567358488078726, Test loss 0.5001372299805472, Train accuracy 99.99200767263427, Test accuracy 93.66099683544304, Cost 72.26104807853699 s\n",
      "Epoch 1000, Train loss 0.0002119767752720319, Test loss 0.4979280229610733, Train accuracy 99.99400575447571, Test accuracy 93.89833860759494, Cost 72.31145596504211 s\n",
      "Model saved in epoch 1000\n",
      "Epoch 1001, Train loss 0.00022258054686315784, Test loss 0.49160684626313705, Train accuracy 99.99400575447571, Test accuracy 93.86867088607595, Cost 72.25958275794983 s\n",
      "Epoch 1002, Train loss 0.0007881163782879507, Test loss 0.5083742418055293, Train accuracy 99.97602301790282, Test accuracy 93.62143987341773, Cost 72.20140027999878 s\n",
      "Epoch 1003, Train loss 0.0007921103584306426, Test loss 0.4932217578156085, Train accuracy 99.97802109974424, Test accuracy 93.8488924050633, Cost 72.33077931404114 s\n",
      "Epoch 1004, Train loss 0.00023199695485026694, Test loss 0.49523951867713206, Train accuracy 99.99000959079284, Test accuracy 93.66099683544304, Cost 72.3305823802948 s\n",
      "Epoch 1005, Train loss 0.0003995124849968598, Test loss 0.49521819879359835, Train accuracy 99.9880115089514, Test accuracy 93.8192246835443, Cost 72.26797795295715 s\n",
      "Model saved in epoch 1005\n",
      "Epoch 1006, Train loss 0.00022708824957736948, Test loss 0.4855328910995888, Train accuracy 99.99200767263427, Test accuracy 93.76977848101266, Cost 71.45342993736267 s\n",
      "Epoch 1007, Train loss 0.0004023426663773071, Test loss 0.4932688297821751, Train accuracy 99.98601342710998, Test accuracy 93.73022151898734, Cost 71.85775780677795 s\n",
      "Epoch 1008, Train loss 0.0003325727109524612, Test loss 0.5045014736301536, Train accuracy 99.9880115089514, Test accuracy 93.70055379746836, Cost 72.23113894462585 s\n",
      "Epoch 1009, Train loss 0.00037038586908439417, Test loss 0.4989429221877569, Train accuracy 99.98401534526855, Test accuracy 93.6511075949367, Cost 72.34134793281555 s\n",
      "Epoch 1010, Train loss 0.00022895655588969202, Test loss 0.48455255346584925, Train accuracy 99.99400575447571, Test accuracy 94.06645569620254, Cost 72.35673093795776 s\n",
      "Model saved in epoch 1010\n",
      "Epoch 1011, Train loss 0.00010831364466520795, Test loss 0.48139637331419355, Train accuracy 99.99800191815856, Test accuracy 94.11590189873418, Cost 71.5334038734436 s\n",
      "Epoch 1012, Train loss 0.00031313639800522724, Test loss 0.4907023976498012, Train accuracy 99.99000959079284, Test accuracy 93.90822784810126, Cost 71.24049687385559 s\n",
      "Epoch 1013, Train loss 0.0001812028956806525, Test loss 0.4972951555553871, Train accuracy 99.99600383631713, Test accuracy 93.79944620253164, Cost 72.38866758346558 s\n",
      "Epoch 1014, Train loss 0.0004352281291026009, Test loss 0.49928245617996286, Train accuracy 99.98401534526855, Test accuracy 93.71044303797468, Cost 72.40516376495361 s\n",
      "Epoch 1015, Train loss 0.00020724994919923528, Test loss 0.49274416852600966, Train accuracy 99.99400575447571, Test accuracy 93.8488924050633, Cost 72.39179515838623 s\n",
      "Model saved in epoch 1015\n",
      "Epoch 1016, Train loss 0.00031400269186570776, Test loss 0.4978880507847931, Train accuracy 99.99200767263427, Test accuracy 94.02689873417721, Cost 72.35706758499146 s\n",
      "Epoch 1017, Train loss 0.0003447266724647322, Test loss 0.4976835304611846, Train accuracy 99.99000959079284, Test accuracy 94.00712025316456, Cost 71.1651656627655 s\n",
      "Epoch 1018, Train loss 0.0004222421617464993, Test loss 0.48406775507934485, Train accuracy 99.98601342710998, Test accuracy 93.97745253164557, Cost 71.79451632499695 s\n",
      "Epoch 1019, Train loss 0.0002529972968674305, Test loss 0.5034196200202915, Train accuracy 99.99000959079284, Test accuracy 93.93789556962025, Cost 70.71942901611328 s\n",
      "Epoch 1020, Train loss 0.00046380053803595937, Test loss 0.49118498863675925, Train accuracy 99.98201726342711, Test accuracy 93.88844936708861, Cost 70.73180103302002 s\n",
      "Model saved in epoch 1020\n",
      "Epoch 1021, Train loss 0.0007939636736537928, Test loss 0.5157494220552565, Train accuracy 99.98001918158567, Test accuracy 93.6807753164557, Cost 72.19909572601318 s\n",
      "Epoch 1022, Train loss 0.0007927415756664994, Test loss 0.5157432299154469, Train accuracy 99.96803069053709, Test accuracy 93.45332278481013, Cost 72.44198250770569 s\n",
      "Epoch 1023, Train loss 0.0007049395220650932, Test loss 0.4799579405284758, Train accuracy 99.97402493606138, Test accuracy 93.8192246835443, Cost 72.28727674484253 s\n",
      "Epoch 1024, Train loss 0.0005166274858342447, Test loss 0.4808986771238756, Train accuracy 99.98401534526855, Test accuracy 93.8488924050633, Cost 71.46558880805969 s\n",
      "Epoch 1025, Train loss 0.00035135224483406126, Test loss 0.49023484327842165, Train accuracy 99.99000959079284, Test accuracy 93.79944620253164, Cost 71.26187705993652 s\n",
      "Model saved in epoch 1025\n",
      "Epoch 1026, Train loss 0.000462624174075973, Test loss 0.47442508036200004, Train accuracy 99.98201726342711, Test accuracy 94.04667721518987, Cost 72.01495933532715 s\n",
      "Epoch 1027, Train loss 0.00021600065316812567, Test loss 0.4852843700047535, Train accuracy 99.99400575447571, Test accuracy 94.03678797468355, Cost 72.05968189239502 s\n",
      "Epoch 1028, Train loss 0.0004206772105471687, Test loss 0.5023476172097122, Train accuracy 99.98601342710998, Test accuracy 93.88844936708861, Cost 72.06720280647278 s\n",
      "Epoch 1029, Train loss 0.0002451730694038161, Test loss 0.49167994751677485, Train accuracy 99.99400575447571, Test accuracy 93.82911392405063, Cost 72.06598567962646 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1030, Train loss 0.00019207612291398656, Test loss 0.49172728268217436, Train accuracy 99.99400575447571, Test accuracy 94.10601265822785, Cost 72.30442690849304 s\n",
      "Model saved in epoch 1030\n",
      "Epoch 1031, Train loss 0.0003168671698067224, Test loss 0.4947518784599968, Train accuracy 99.99400575447571, Test accuracy 93.93789556962025, Cost 71.66226315498352 s\n",
      "Epoch 1032, Train loss 0.0003454687274337698, Test loss 0.5054328794343562, Train accuracy 99.98601342710998, Test accuracy 93.8488924050633, Cost 71.02491545677185 s\n",
      "Epoch 1033, Train loss 0.0006022090515932399, Test loss 0.505157553602623, Train accuracy 99.97882033248082, Test accuracy 93.88844936708861, Cost 72.37399077415466 s\n",
      "Epoch 1034, Train loss 0.0007505939765162007, Test loss 0.5087633694321672, Train accuracy 99.97202685421995, Test accuracy 93.96756329113924, Cost 72.4253716468811 s\n",
      "Epoch 1035, Train loss 0.0005329403919423221, Test loss 0.5162055033813172, Train accuracy 99.98201726342711, Test accuracy 93.83900316455696, Cost 72.3756685256958 s\n",
      "Model saved in epoch 1035\n",
      "Epoch 1036, Train loss 0.0003935415042084114, Test loss 0.5256580471568093, Train accuracy 99.98401534526855, Test accuracy 93.66099683544304, Cost 72.40624022483826 s\n",
      "Epoch 1037, Train loss 0.0007151150857527829, Test loss 0.5122659513549997, Train accuracy 99.98401534526855, Test accuracy 93.8192246835443, Cost 72.34191942214966 s\n",
      "Epoch 1038, Train loss 0.0001955009738000151, Test loss 0.5029533516521318, Train accuracy 99.99400575447571, Test accuracy 93.99723101265823, Cost 72.41770648956299 s\n",
      "Epoch 1039, Train loss 0.0004147349781366026, Test loss 0.5017395136830739, Train accuracy 99.99000959079284, Test accuracy 93.96756329113924, Cost 72.45829129219055 s\n",
      "Epoch 1040, Train loss 0.0006261837087435043, Test loss 0.5041517660587649, Train accuracy 99.98601342710998, Test accuracy 93.80933544303798, Cost 72.45278859138489 s\n",
      "Model saved in epoch 1040\n",
      "Epoch 1041, Train loss 0.0004535856283600233, Test loss 0.5006795517062839, Train accuracy 99.9880115089514, Test accuracy 93.90822784810126, Cost 72.4502272605896 s\n",
      "Epoch 1042, Train loss 0.0003689616948504369, Test loss 0.5074134016338783, Train accuracy 99.98401534526855, Test accuracy 93.9873417721519, Cost 72.34889125823975 s\n",
      "Epoch 1043, Train loss 0.00048270129196280743, Test loss 0.5085349210266825, Train accuracy 99.98401534526855, Test accuracy 93.75, Cost 72.41814279556274 s\n",
      "Epoch 1044, Train loss 0.00028505478550261177, Test loss 0.5116511743657196, Train accuracy 99.99000959079284, Test accuracy 93.72033227848101, Cost 71.23457431793213 s\n",
      "Epoch 1045, Train loss 0.00028694409070054736, Test loss 0.5019214422076563, Train accuracy 99.9880115089514, Test accuracy 94.10601265822785, Cost 72.40320324897766 s\n",
      "Model saved in epoch 1045\n",
      "Epoch 1046, Train loss 0.0004408476841661413, Test loss 0.5219817016320892, Train accuracy 99.99000959079284, Test accuracy 93.72033227848101, Cost 71.59364891052246 s\n",
      "Epoch 1047, Train loss 0.00044145605636475906, Test loss 0.5193433021254177, Train accuracy 99.98201726342711, Test accuracy 93.6807753164557, Cost 71.40552973747253 s\n",
      "Epoch 1048, Train loss 0.0002645836120231971, Test loss 0.5158391996652265, Train accuracy 99.99200767263427, Test accuracy 93.83900316455696, Cost 71.22896146774292 s\n",
      "Epoch 1049, Train loss 0.0002526801586226626, Test loss 0.5188632253793222, Train accuracy 99.99200767263427, Test accuracy 93.78955696202532, Cost 70.89727449417114 s\n",
      "Epoch 1050, Train loss 0.0007182195816932804, Test loss 0.5274049605749831, Train accuracy 99.98401534526855, Test accuracy 93.74011075949367, Cost 70.63609552383423 s\n",
      "Model saved in epoch 1050\n",
      "Epoch 1051, Train loss 0.00037056691048202426, Test loss 0.5206442265948162, Train accuracy 99.99000959079284, Test accuracy 93.77966772151899, Cost 72.13299703598022 s\n",
      "Epoch 1052, Train loss 0.0003140314684319243, Test loss 0.5047432213455816, Train accuracy 99.99000959079284, Test accuracy 93.89833860759494, Cost 71.19105768203735 s\n",
      "Epoch 1053, Train loss 0.00010776719710528125, Test loss 0.5030402765621113, Train accuracy 99.99800191815856, Test accuracy 93.87856012658227, Cost 72.4975380897522 s\n",
      "Epoch 1054, Train loss 0.00012754588274481942, Test loss 0.5008946990099135, Train accuracy 99.99400575447571, Test accuracy 94.01700949367088, Cost 72.46615695953369 s\n",
      "Epoch 1055, Train loss 9.576569654289838e-05, Test loss 0.5041965030228035, Train accuracy 99.99800191815856, Test accuracy 93.95767405063292, Cost 72.39476227760315 s\n",
      "Model saved in epoch 1055\n",
      "Epoch 1056, Train loss 0.00012436015108158215, Test loss 0.500614708737482, Train accuracy 99.99400575447571, Test accuracy 93.85878164556962, Cost 72.39956569671631 s\n",
      "Epoch 1057, Train loss 0.00015127995819448557, Test loss 0.4941070724891711, Train accuracy 99.99600383631713, Test accuracy 93.9873417721519, Cost 72.42567992210388 s\n",
      "Epoch 1058, Train loss 0.0004840334932487007, Test loss 0.507112717703928, Train accuracy 99.98481457800511, Test accuracy 93.56210443037975, Cost 72.45686769485474 s\n",
      "Epoch 1059, Train loss 0.0006382923405484241, Test loss 0.505351635568504, Train accuracy 99.97802109974424, Test accuracy 93.60166139240506, Cost 72.4676022529602 s\n",
      "Epoch 1060, Train loss 0.00046234431339217154, Test loss 0.5271267134554779, Train accuracy 99.9880115089514, Test accuracy 93.62143987341773, Cost 72.08314609527588 s\n",
      "Model saved in epoch 1060\n",
      "Epoch 1061, Train loss 0.0006282437753997831, Test loss 0.527019385861445, Train accuracy 99.97402493606138, Test accuracy 93.72033227848101, Cost 72.09839534759521 s\n",
      "Epoch 1062, Train loss 0.00044548332819039147, Test loss 0.5030322399320482, Train accuracy 99.98601342710998, Test accuracy 93.79944620253164, Cost 70.86345934867859 s\n",
      "Epoch 1063, Train loss 0.00039822164262082524, Test loss 0.5022050360146957, Train accuracy 99.98601342710998, Test accuracy 93.92800632911393, Cost 70.70071363449097 s\n",
      "Epoch 1064, Train loss 0.00019273019987823035, Test loss 0.4933225001338162, Train accuracy 99.99600383631713, Test accuracy 93.76977848101266, Cost 71.32306909561157 s\n",
      "Epoch 1065, Train loss 0.0001908470875891324, Test loss 0.5072129257494891, Train accuracy 99.99200767263427, Test accuracy 93.82911392405063, Cost 71.42162656784058 s\n",
      "Model saved in epoch 1065\n",
      "Epoch 1066, Train loss 0.00017373098206976007, Test loss 0.5050926394289053, Train accuracy 99.99200767263427, Test accuracy 93.75, Cost 72.27307391166687 s\n",
      "Epoch 1067, Train loss 0.00016683188199843662, Test loss 0.4940614997397495, Train accuracy 99.99400575447571, Test accuracy 93.8192246835443, Cost 71.08443188667297 s\n",
      "Epoch 1068, Train loss 0.0004169546386104039, Test loss 0.4923991687312911, Train accuracy 99.98201726342711, Test accuracy 93.85878164556962, Cost 72.10716462135315 s\n",
      "Epoch 1069, Train loss 0.00030123568130857364, Test loss 0.5114944547037535, Train accuracy 99.99200767263427, Test accuracy 93.8488924050633, Cost 72.41493391990662 s\n",
      "Epoch 1070, Train loss 0.0002070538106884122, Test loss 0.5085725951232488, Train accuracy 99.99400575447571, Test accuracy 93.89833860759494, Cost 71.50976085662842 s\n",
      "Model saved in epoch 1070\n",
      "Epoch 1071, Train loss 0.00025205910580578217, Test loss 0.508860545350781, Train accuracy 99.99200767263427, Test accuracy 94.11590189873418, Cost 71.09173774719238 s\n",
      "Epoch 1072, Train loss 0.00014546080592026993, Test loss 0.5061140581965446, Train accuracy 99.99600383631713, Test accuracy 93.90822784810126, Cost 71.7964415550232 s\n",
      "Epoch 1073, Train loss 0.00028869881346231855, Test loss 0.5178467323885688, Train accuracy 99.99400575447571, Test accuracy 93.99723101265823, Cost 71.39964962005615 s\n",
      "Epoch 1074, Train loss 0.0002314562995412953, Test loss 0.5195169953417175, Train accuracy 99.99400575447571, Test accuracy 93.77966772151899, Cost 70.4990565776825 s\n",
      "Epoch 1075, Train loss 0.0002542116936290274, Test loss 0.5067765142391377, Train accuracy 99.99400575447571, Test accuracy 93.86867088607595, Cost 70.97004723548889 s\n",
      "Model saved in epoch 1075\n",
      "Epoch 1076, Train loss 0.0001098361419636971, Test loss 0.5150728591635257, Train accuracy 99.99800191815856, Test accuracy 93.69066455696202, Cost 71.14629316329956 s\n",
      "Epoch 1077, Train loss 0.00024735503146160594, Test loss 0.5160132945055449, Train accuracy 99.9880115089514, Test accuracy 93.5818829113924, Cost 71.46665930747986 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1078, Train loss 0.00011663630584577882, Test loss 0.5103429939739311, Train accuracy 99.99800191815856, Test accuracy 93.69066455696202, Cost 71.47343111038208 s\n",
      "Epoch 1079, Train loss 0.00020315857180648958, Test loss 0.5152902367371547, Train accuracy 99.99200767263427, Test accuracy 93.8192246835443, Cost 71.63883519172668 s\n",
      "Epoch 1080, Train loss 0.0001600537525629882, Test loss 0.5139830269485335, Train accuracy 99.99400575447571, Test accuracy 93.73022151898734, Cost 70.62062335014343 s\n",
      "Model saved in epoch 1080\n",
      "Epoch 1081, Train loss 0.00021444825300492924, Test loss 0.5366518952518324, Train accuracy 99.9880115089514, Test accuracy 93.57199367088607, Cost 70.6754035949707 s\n",
      "Epoch 1082, Train loss 9.501410069902213e-05, Test loss 0.515860577833049, Train accuracy 99.99800191815856, Test accuracy 93.75, Cost 72.20159316062927 s\n",
      "Epoch 1083, Train loss 0.00010321961684787423, Test loss 0.51641672755344, Train accuracy 99.99400575447571, Test accuracy 93.85878164556962, Cost 72.4489574432373 s\n",
      "Epoch 1084, Train loss 7.912405928033586e-05, Test loss 0.5089675557292714, Train accuracy 100.0, Test accuracy 93.92800632911393, Cost 72.48230838775635 s\n",
      "Epoch 1085, Train loss 0.00034502538322878567, Test loss 0.5224683114056345, Train accuracy 99.99000959079284, Test accuracy 93.83900316455696, Cost 72.45424675941467 s\n",
      "Model saved in epoch 1085\n",
      "Epoch 1086, Train loss 0.00033220889297197904, Test loss 0.527221190778515, Train accuracy 99.99000959079284, Test accuracy 93.62143987341773, Cost 72.42246723175049 s\n",
      "Epoch 1087, Train loss 0.00018533948356537123, Test loss 0.5167319412472882, Train accuracy 99.99600383631713, Test accuracy 93.75, Cost 71.03375720977783 s\n",
      "Epoch 1088, Train loss 0.00021781232834744665, Test loss 0.5134207576136046, Train accuracy 99.99200767263427, Test accuracy 93.87856012658227, Cost 72.03691911697388 s\n",
      "Epoch 1089, Train loss 0.0001752381507619366, Test loss 0.5116491290398791, Train accuracy 99.99600383631713, Test accuracy 93.8192246835443, Cost 71.65956377983093 s\n",
      "Epoch 1090, Train loss 0.00018039159919129873, Test loss 0.5187470800703085, Train accuracy 99.99600383631713, Test accuracy 93.73022151898734, Cost 72.43105030059814 s\n",
      "Model saved in epoch 1090\n",
      "Epoch 1091, Train loss 0.00023640091253467036, Test loss 0.5243135026738613, Train accuracy 99.99200767263427, Test accuracy 93.77966772151899, Cost 72.46515250205994 s\n",
      "Epoch 1092, Train loss 0.00042144188208755116, Test loss 0.5250069021801406, Train accuracy 99.98481457800511, Test accuracy 93.90822784810126, Cost 72.41311883926392 s\n",
      "Epoch 1093, Train loss 0.0008204783660398903, Test loss 0.5131381963250004, Train accuracy 99.97602301790282, Test accuracy 93.9873417721519, Cost 72.4553689956665 s\n",
      "Epoch 1094, Train loss 0.00014085946818482353, Test loss 0.5100548207005368, Train accuracy 99.99400575447571, Test accuracy 93.79944620253164, Cost 72.49360513687134 s\n",
      "Epoch 1095, Train loss 0.0004358820228053705, Test loss 0.5385839221409604, Train accuracy 99.99000959079284, Test accuracy 93.69066455696202, Cost 72.47662687301636 s\n",
      "Model saved in epoch 1095\n",
      "Epoch 1096, Train loss 9.82670038654926e-05, Test loss 0.5292725700743591, Train accuracy 99.99800191815856, Test accuracy 93.71044303797468, Cost 71.79661393165588 s\n",
      "Epoch 1097, Train loss 0.00019036837863652923, Test loss 0.5447476510948772, Train accuracy 99.99800191815856, Test accuracy 93.6511075949367, Cost 72.37733125686646 s\n",
      "Epoch 1098, Train loss 0.0005625854616534548, Test loss 0.522831030189991, Train accuracy 99.98201726342711, Test accuracy 93.82911392405063, Cost 72.4909520149231 s\n",
      "Epoch 1099, Train loss 0.000447816162202512, Test loss 0.5212515253998056, Train accuracy 99.9880115089514, Test accuracy 93.90822784810126, Cost 72.444491147995 s\n",
      "Epoch 1100, Train loss 8.37827734821486e-05, Test loss 0.5177834434788439, Train accuracy 99.99800191815856, Test accuracy 93.99723101265823, Cost 72.41689109802246 s\n",
      "Model saved in epoch 1100\n",
      "Epoch 1101, Train loss 0.000317316610546656, Test loss 0.517607522821879, Train accuracy 99.9880115089514, Test accuracy 93.94778481012658, Cost 70.50489711761475 s\n",
      "Epoch 1102, Train loss 0.00016810849971744292, Test loss 0.515434667468071, Train accuracy 99.99600383631713, Test accuracy 93.93789556962025, Cost 70.37780570983887 s\n",
      "Epoch 1103, Train loss 0.00015495412953302936, Test loss 0.5245646999889537, Train accuracy 99.99600383631713, Test accuracy 93.92800632911393, Cost 71.13632035255432 s\n",
      "Epoch 1104, Train loss 0.0001333121258081936, Test loss 0.5324831302926133, Train accuracy 99.99600383631713, Test accuracy 93.93789556962025, Cost 69.70146560668945 s\n",
      "Epoch 1105, Train loss 6.936633367354512e-05, Test loss 0.5249524658805207, Train accuracy 99.99800191815856, Test accuracy 94.02689873417721, Cost 72.433518409729 s\n",
      "Model saved in epoch 1105\n",
      "Epoch 1106, Train loss 0.0002631392850420087, Test loss 0.5320456232639807, Train accuracy 99.99400575447571, Test accuracy 93.72033227848101, Cost 72.394939661026 s\n",
      "Epoch 1107, Train loss 0.0002233229177621068, Test loss 0.546295705664007, Train accuracy 99.99800191815856, Test accuracy 93.75, Cost 71.0097873210907 s\n",
      "Epoch 1108, Train loss 0.00017332821042844338, Test loss 0.5338700276009644, Train accuracy 99.99800191815856, Test accuracy 93.83900316455696, Cost 71.54652309417725 s\n",
      "Epoch 1109, Train loss 0.00016000301654566616, Test loss 0.5241840823164469, Train accuracy 99.99600383631713, Test accuracy 93.77966772151899, Cost 72.04708003997803 s\n",
      "Epoch 1110, Train loss 0.00014818489749678594, Test loss 0.5149719804713998, Train accuracy 99.99400575447571, Test accuracy 94.08623417721519, Cost 71.10831570625305 s\n",
      "Model saved in epoch 1110\n",
      "Epoch 1111, Train loss 0.00014537807631315677, Test loss 0.5312080440830581, Train accuracy 99.99000959079284, Test accuracy 93.8192246835443, Cost 71.00953078269958 s\n",
      "Epoch 1112, Train loss 0.00012251659785248467, Test loss 0.5285666219041317, Train accuracy 99.99800191815856, Test accuracy 93.88844936708861, Cost 70.22357940673828 s\n",
      "Epoch 1113, Train loss 0.0001098659964005828, Test loss 0.52925921127766, Train accuracy 99.99200767263427, Test accuracy 94.02689873417721, Cost 72.4563045501709 s\n",
      "Epoch 1114, Train loss 0.00016675291781560446, Test loss 0.5129950495460366, Train accuracy 99.99600383631713, Test accuracy 94.07634493670886, Cost 72.4127733707428 s\n",
      "Epoch 1115, Train loss 0.0005122554082249325, Test loss 0.5500262807818908, Train accuracy 99.98201726342711, Test accuracy 93.67088607594937, Cost 72.48292756080627 s\n",
      "Model saved in epoch 1115\n",
      "Epoch 1116, Train loss 0.00016647545919738896, Test loss 0.527498642383497, Train accuracy 99.99600383631713, Test accuracy 94.01700949367088, Cost 71.20516681671143 s\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5000 # param\n",
    "epoch_start = 0\n",
    "# path = 'adam_rotate_center_crop1.pt'\n",
    "# path = 'block_3.pt'\n",
    "path = 'batch_128_lr_0.1_no_crop_decay_avg_4.pt'\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "test_accuracy_history = []\n",
    "train_accuracy_history = []\n",
    "\n",
    "Loss = torch.nn.CrossEntropyLoss()\n",
    "lr = 0.1 # param\n",
    "lr_min=0.001\n",
    "# optimizer = torch.optim.SGD(model1.parameters(),lr=lr,momentum=0.9,weight_decay=5e-4) # changable optimizer\n",
    "# optimizer = torch.optim.SGD(model1.parameters(),lr=lr,momentum=0.9) # changable optimizer\n",
    "# optimizer = torch.optim.Adam(model1.parameters(),lr=lr, betas=(0.9,0.999), eps=1e-08, amsgrad=False) # changable optimizer\n",
    "momentum = 0.9\n",
    "nesterov = True\n",
    "optimizer = torch.optim.SGD(model1.parameters(),lr=lr,momentum=momentum,nesterov=nesterov)\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "if os.path.exists(path):\n",
    "  checkpoint = torch.load(path)\n",
    "  print('Read model from checkpoint')\n",
    "  model1.cuda().load_state_dict(checkpoint['model_state_dict'])\n",
    "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "  epoch_start = checkpoint['epoch']\n",
    "  Loss = checkpoint['Loss']\n",
    "  train_loss_history = checkpoint['train_loss_history']\n",
    "  test_loss_history = checkpoint['test_loss_history']\n",
    "  test_accuracy_history = checkpoint['test_accuracy_history']\n",
    "  train_accuracy_history = checkpoint['train_accuracy_history']\n",
    "  print('Restart from epoch',epoch_start)\n",
    "    \n",
    "\n",
    "for epoch in range(epoch_start+1, num_epochs + 1):\n",
    "  timestart = time.time()\n",
    "\n",
    "  train_loss = 0.0\n",
    "  test_loss = 0.0\n",
    "  test_accuracy = 0.0\n",
    "  train_accuracy = 0.0\n",
    "\n",
    "  for i, data in enumerate(trainDataLoader):\n",
    "    images, labels = data\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    optimizer.zero_grad()\n",
    "    predicted_output = model1.cuda()(images)\n",
    "    fit = Loss(predicted_output,labels)\n",
    "    fit.backward()\n",
    "    adjust_learning_rate(optimizer=optimizer,current_epoch=epoch,max_epoch=num_epochs,lr_min=lr_min,lr_max=lr,warmup=True)\n",
    "    optimizer.step()\n",
    "    train_loss += fit.item()\n",
    "    train_accuracy += (torch.eq(torch.max(predicted_output,1)[1],labels).sum()/len(labels)*100).data.cpu().numpy()\n",
    "\n",
    "  for i, data in enumerate(testDataLoader):\n",
    "    with torch.no_grad():\n",
    "      images, labels = data\n",
    "      images = images.cuda()\n",
    "      labels = labels.cuda()\n",
    "      predicted_output = model1.cuda()(images)\n",
    "      fit = Loss(predicted_output,labels)\n",
    "      test_loss += fit.item()\n",
    "      test_accuracy += (torch.eq(torch.max(predicted_output,1)[1],labels).sum()/len(labels)*100).data.cpu().numpy()\n",
    "\n",
    "\n",
    "  train_loss = train_loss/len(trainDataLoader)\n",
    "  test_loss = test_loss/len(testDataLoader)\n",
    "  test_accu = test_accuracy/len(testDataLoader)\n",
    "  train_accu = train_accuracy/len(trainDataLoader)\n",
    "  train_loss_history.append(train_loss)\n",
    "  test_loss_history.append(test_loss)\n",
    "  test_accuracy_history.append(test_accu)\n",
    "  train_accuracy_history.append(train_accu)\n",
    "  print('Epoch %s, Train loss %s, Test loss %s, Train accuracy %s, Test accuracy %s, Cost %s s'%(epoch,\n",
    "                                                                                                   train_loss,test_loss,\n",
    "                                                                                                   train_accu,test_accu,\n",
    "                                                                                                   time.time()-timestart))\n",
    "  \n",
    "  if epoch % 5 == 0 and epoch != 0:\n",
    "    torch.save({'epoch':epoch,\n",
    "          'model_state_dict':model1.cuda().state_dict(),\n",
    "          'optimizer_state_dict':optimizer.state_dict(),\n",
    "          'Loss':Loss,\n",
    "          'train_loss_history':train_loss_history,\n",
    "          'test_loss_history':test_loss_history,\n",
    "          'test_accuracy_history':test_accuracy_history,\n",
    "          'train_accuracy_history':train_accuracy_history},path)\n",
    "    print('Model saved in epoch %s'%(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RUy08Iyn7tUl",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 611\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(num_epochs),train_loss_history,'-',linewidth=3,label='Train error')\n",
    "plt.plot(range(num_epochs),test_loss_history,'-',linewidth=3,label='Test error')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(num_epochs),train_accuracy_history,'-',linewidth=3,label='Test accuracy')\n",
    "plt.plot(range(num_epochs),test_accuracy_history,'-',linewidth=3,label='Test accuracy')\n",
    "# plt.plot(range(num_epochs),test_accuracy_history,'-',linewidth=3,label='Test accuracy')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVQJgMts7vcg"
   },
   "outputs": [],
   "source": [
    "print('Accuracy:',sum(test_accuracy_history[-5:])/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LaMUB4p_Ucip"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "“ResNet.ipynb”的副本",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0130588af6254c76a2c8c382288cfcea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4aa5668c8eaa49f88148d499240b6ea5",
      "placeholder": "​",
      "style": "IPY_MODEL_a66b114e4595419f84ac44a676a1ca61",
      "value": " 170499072/? [00:03&lt;00:00, 56047078.45it/s]"
     }
    },
    "1121692d91114d58b3db79e41b0a24c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d40f4bf0c0e48709cdec5f80069ed2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "321ea7fa0b4d4c9dab9ed5231954e54c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3983cfe844f847899487b2745a203a9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8148f05b38d94ec19351ac920b70acba",
       "IPY_MODEL_af7b660f147d4d1d8796d3419673c9b7",
       "IPY_MODEL_0130588af6254c76a2c8c382288cfcea"
      ],
      "layout": "IPY_MODEL_1121692d91114d58b3db79e41b0a24c9"
     }
    },
    "4aa5668c8eaa49f88148d499240b6ea5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8148f05b38d94ec19351ac920b70acba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_accf52fe298b4716af9d9c351e7326dc",
      "placeholder": "​",
      "style": "IPY_MODEL_fb3e769eb8324af3b77041879c9b54cf",
      "value": ""
     }
    },
    "a66b114e4595419f84ac44a676a1ca61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "accf52fe298b4716af9d9c351e7326dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af7b660f147d4d1d8796d3419673c9b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_321ea7fa0b4d4c9dab9ed5231954e54c",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d40f4bf0c0e48709cdec5f80069ed2f",
      "value": 170498071
     }
    },
    "fb3e769eb8324af3b77041879c9b54cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
