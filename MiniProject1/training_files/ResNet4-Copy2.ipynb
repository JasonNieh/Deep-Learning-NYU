{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import math\n",
    "import torchvision\n",
    "from torchvision import transforms as transforms\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from math import cos,pi\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(17)\n",
    "\n",
    "# class HaS(object): \n",
    "# #     def __init__(self):\n",
    "        \n",
    "#     def __call__(self, img):\n",
    "#         # get width and height of the image\n",
    "#         img_= np.array(img).copy()\n",
    "#         s = img_.shape\n",
    "#         wd = s[0]\n",
    "#         ht = s[1]\n",
    "\n",
    "#         # possible grid size, 0 means no hiding\n",
    "#         grid_size=3\n",
    "\n",
    "#         # hiding probability\n",
    "#         hide_prob = 0.1\n",
    " \n",
    "#         # randomly choose one grid size\n",
    "# #         grid_size= grid_sizes[random.randint(0,len(grid_sizes)-1)]\n",
    "\n",
    "#         # hide the patches\n",
    "#         if(grid_size>0):\n",
    "#              for x in range(0,wd,grid_size):\n",
    "#                  for y in range(0,ht,grid_size):\n",
    "#                      x_end = min(wd, x+grid_size)  \n",
    "#                      y_end = min(ht, y+grid_size)\n",
    "#                      if(random.random() <=  hide_prob):\n",
    "#                            img_[x:x_end,y:y_end,:]=0\n",
    "\n",
    "#         return img_\n",
    "    \n",
    "# torch.manual_seed(17)\n",
    "\n",
    "        \n",
    "# class HideEdge(object): \n",
    "#     def __init__(self,hide_size):\n",
    "#         self.hide_size=hide_size\n",
    "        \n",
    "#     def __call__(self, img):\n",
    "#         # get width and height of the image\n",
    "#         img_= np.array(img).copy()\n",
    "#         s = img_.shape\n",
    "#         wd = s[0]\n",
    "#         ht = s[1]\n",
    "\n",
    "#         hide_size=self.hide_size\n",
    "        \n",
    "# #         img_[:,:,:] = img()\n",
    "   \n",
    "#         x_end = wd - hide_size \n",
    "#         y_end = ht - hide_size\n",
    "\n",
    "#         img_[x_end:,y_end:,:]=0\n",
    "# #         img_[x_end:,:hide_size,:]=0\n",
    "# #         img_[:hide_size,y_end:,:]=0\n",
    "#         img_[:hide_size,:hide_size,:]=0\n",
    "# #         img_[x_end:,:,:]=0\n",
    "# #         img_[:,y_end:,:]=0\n",
    "# #         img_[:hide_size,:,:]=0\n",
    "# #         img_[:,:hide_size,:]=0\n",
    "# #         print(img_[x_end,y_end,:])\n",
    "# #         print(img_[hide_size,hide_size,:])\n",
    "# #         print(x_end,y_end,hide_size)\n",
    "        \n",
    "# #         mean = img_[hide_size:x_end-1,hide_size:y_end,:].mean()\n",
    "# #         std = img_[hide_size:x_end-1,hide_size:y_end,:].std()\n",
    "# #         print(mean, std)\n",
    "# #         img_[hide_size:x_end-1,hide_size:y_end,:] = (img_[hide_size:x_end-1,hide_size:y_end,:] - mean) / std\n",
    "# #         print(img_[hide_size:x_end-1,hide_size:y_end,:])\n",
    "        \n",
    "#         return img_\n",
    "\n",
    "   \n",
    "# class Hide_after_Norm(object): \n",
    "#     def __init__(self,hide_size):\n",
    "#         self.hide_size=hide_size\n",
    "        \n",
    "#     def __call__(self, img_):\n",
    "#         # get width and height of the image\n",
    "# #         img_= np.array(img).copy()\n",
    "#         s = img_.shape\n",
    "#         wd = s[1]\n",
    "#         ht = s[2]\n",
    "\n",
    "#         hide_size=self.hide_size\n",
    "        \n",
    "# #         img_[:,:,:] = img()\n",
    "   \n",
    "#         x_end = wd - hide_size \n",
    "#         y_end = ht - hide_size\n",
    "        \n",
    "#         x_end = wd - hide_size \n",
    "#         y_end = ht - hide_size\n",
    "\n",
    "#         img_[:,x_end:,y_end:]=0\n",
    "# #         img_[x_end:,:hide_size,:]=0\n",
    "# #         img_[:hide_size,y_end:,:]=0\n",
    "#         img_[:,:hide_size,:hide_size]=0\n",
    "# #         print(img_[x_end,y_end,:])\n",
    "# #         print(img_[hide_size,hide_size,:])\n",
    "# #         print(x_end,y_end,hide_size)\n",
    "        \n",
    "# #         mean = img_[hide_size:x_end-1,hide_size:y_end,:].mean()\n",
    "# #         std = img_[hide_size:x_end-1,hide_size:y_end,:].std()\n",
    "# #         print(mean, std)\n",
    "# #         img_[hide_size:x_end-1,hide_size:y_end,:] = (img_[hide_size:x_end-1,hide_size:y_end,:] - mean) / std\n",
    "# #         print(img_[hide_size:x_end-1,hide_size:y_end,:])\n",
    "        \n",
    "#         return img_\n",
    "    \n",
    "    \n",
    "\n",
    "# # torch.cuda.manual_seed(17) # for GPU\n",
    "# aug_train = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(), # 水平翻转\n",
    "# #     torchvision.transforms.CenterCrop(26),\n",
    "# #     HideEdge(),\n",
    "#     torchvision.transforms.RandomRotation(15),\n",
    "# #     torchvision.transforms.CenterCrop(28),\n",
    "#     # transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5), # color aug\n",
    "# #     transforms.RandomCrop(32, padding=4), # 裁剪\n",
    "#     # transforms.RandomResizedCrop((32,32),scale=(0.1,1),ratio=(0.5,2))\n",
    "# #     hide_patch(),\n",
    "# #     HaS(),\n",
    "# #     HideEdge(2),\n",
    "#     transforms.ToTensor(),\n",
    "# #     Norm(2),\n",
    "#     transforms.Normalize((0.4649, 0.4553, 0.4214), (0.2271, 0.2234, 0.2208)),# normalization\n",
    "#     Hide_after_Norm(2)\n",
    "#     ])\n",
    "\n",
    "# aug_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4649, 0.4553, 0.4214), (0.2271, 0.2234, 0.2208)), # normalization\n",
    "#     Hide_after_Norm(2)\n",
    "#     ])\n",
    "\n",
    "# trainingdata = torchvision.datasets.CIFAR10('./CIFAR10',train=True,download=True,transform=aug_train)\n",
    "# # testdata = torchvision.datasets.CIFAR10('./CIFAR10',train=False,download=True,transform=transforms.ToTensor())\n",
    "# # print(len(trainingdata),len(testdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(17)\n",
    "torch.cuda.manual_seed_all(17)\n",
    "\n",
    "aug_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32,padding=4,padding_mode='reflect'),\n",
    "    transforms.RandomHorizontalFlip(), # 水平翻转\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4244, 0.4146, 0.3836), (0.2539, 0.2491, 0.2420)) # normalization\n",
    "    ])\n",
    "\n",
    "aug_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4244, 0.4146, 0.3836), (0.2539, 0.2491, 0.2420)) # normalization\n",
    "    ])\n",
    "\n",
    "trainingdata = torchvision.datasets.CIFAR10('./CIFAR10',train=True,download=True,transform=aug_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def load_data(is_train,aug,batch_size):\n",
    "    dataset = torchvision.datasets.CIFAR10('./CIFAR10',train=is_train,download=True,transform=aug)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset,batch_size=batch_size,shuffle=is_train)\n",
    "    return dataloader\n",
    "\n",
    "batch_size = 256 # param\n",
    "trainDataLoader = load_data(is_train=True,aug=aug_train,batch_size=batch_size)\n",
    "testDataLoader = load_data(is_train=False,aug=aug_test,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32]) 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "image,label = trainingdata[0]\n",
    "print(image.shape, label)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.imshow(image.numpy().transpose(1,2,0))\n",
    "plt.title(str(classes[label]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if in_planes == 64:\n",
    "            self.conv1 = nn.Conv2d(\n",
    "                in_planes, planes, kernel_size=4, stride=stride, padding=1, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(planes)\n",
    "            self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "            self.bn2 = nn.BatchNorm2d(planes)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(\n",
    "                in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(planes)\n",
    "            self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "            self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes == 64:\n",
    "             self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,\n",
    "                          kernel_size=2, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "                )\n",
    "        elif stride != 1 or in_planes != planes:\n",
    "            if in_planes == 128:\n",
    "                self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "                )\n",
    "            else:\n",
    "                self.shortcut = nn.Sequential(\n",
    "                    nn.Conv2d(in_planes, planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "#         self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(256, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(x.shape)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "#         print(out.shape)\n",
    "        out = self.layer1(out)\n",
    "#         print(out.shape)\n",
    "        out = self.layer2(out)\n",
    "#         print(out.shape)\n",
    "        out = self.layer3(out)\n",
    "#         print(out.shape)\n",
    "#         out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "#         print(out.shape)\n",
    "        out = out.view(out.size(0), -1)\n",
    "#         print(out.shape)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu') # weight initialization\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)\n",
    "            elif isinstance(m,nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "            elif isinstance(m,nn.Linear):\n",
    "                nn.init.normal_(m.weight,std=1e-3)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)\n",
    "\n",
    "def project1_model():\n",
    "#     return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "    return ResNet(BasicBlock, [3, 3, 3])\n",
    "\n",
    "# model1 = nn.Sequential(project1_model(), nn.AdaptiveAvgPool2d((1,1)), nn.Flatten(), nn.Linear(512, 10)).cuda()\n",
    "model1 = project1_model().cuda()\n",
    "model1.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4545226\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    # torch.numel() returns number of elements in a tensor\n",
    "\n",
    "print(count_parameters(model1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = torch.rand(size=(1, 3, 32, 32)).cuda()\n",
    "# for layer in model1:\n",
    "#   X = layer(X)\n",
    "#   print(layer.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, current_epoch,max_epoch,lr_min=0,lr_max=0.1,warmup=True):\n",
    "    warmup_epoch = 10 if warmup else 0\n",
    "    if current_epoch < warmup_epoch:\n",
    "        lr = lr_max * current_epoch / warmup_epoch\n",
    "    else:\n",
    "        lr = lr_min + (lr_max-lr_min)*(1 + cos(pi * (current_epoch - warmup_epoch) / (max_epoch - warmup_epoch))) / 2\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read model from checkpoint\n",
      "Restart from epoch 450\n",
      "Epoch 451, Train loss 1.294202626232103e-05, Test loss 0.5879738301038742, Train accuracy 100.0, Test accuracy 93.212890625, Cost 51.85767602920532 s\n",
      "Epoch 452, Train loss 1.6815608518000116e-05, Test loss 0.587981679290533, Train accuracy 100.0, Test accuracy 93.212890625, Cost 51.80841398239136 s\n",
      "Epoch 453, Train loss 2.2950677922663622e-05, Test loss 0.5877248786389828, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.828272104263306 s\n",
      "Epoch 454, Train loss 2.34861231057127e-05, Test loss 0.5875589177012444, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.827545404434204 s\n",
      "Epoch 455, Train loss 2.285434791420384e-05, Test loss 0.5875181779265404, Train accuracy 99.99800701530613, Test accuracy 93.22265625, Cost 51.83003306388855 s\n",
      "Model saved in epoch 455\n",
      "Epoch 456, Train loss 1.7920432601177172e-05, Test loss 0.5874275006353855, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.86870002746582 s\n",
      "Epoch 457, Train loss 1.8196925230966474e-05, Test loss 0.5875852972269058, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.89442157745361 s\n",
      "Epoch 458, Train loss 1.9848167395827672e-05, Test loss 0.587609151750803, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.888667345047 s\n",
      "Epoch 459, Train loss 1.715663821032249e-05, Test loss 0.5874550938606262, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.87279462814331 s\n",
      "Epoch 460, Train loss 2.4439417901740107e-05, Test loss 0.5874931551516056, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.896305561065674 s\n",
      "Model saved in epoch 460\n",
      "Epoch 461, Train loss 2.2272041158283182e-05, Test loss 0.5871521413326264, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.870415449142456 s\n",
      "Epoch 462, Train loss 1.0277940602852556e-05, Test loss 0.5871627919375897, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.85448122024536 s\n",
      "Epoch 463, Train loss 3.0632199482086e-05, Test loss 0.58714859187603, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.73505687713623 s\n",
      "Epoch 464, Train loss 1.306543438337652e-05, Test loss 0.5871662981808186, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.669029235839844 s\n",
      "Epoch 465, Train loss 1.1634535627285885e-05, Test loss 0.5871864944696427, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.695024251937866 s\n",
      "Model saved in epoch 465\n",
      "Epoch 466, Train loss 9.579182290525002e-06, Test loss 0.5872076831758022, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.8519868850708 s\n",
      "Epoch 467, Train loss 1.0278624584830188e-05, Test loss 0.587212722748518, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.85383987426758 s\n",
      "Epoch 468, Train loss 1.573860277314982e-05, Test loss 0.5871189966797828, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.880876779556274 s\n",
      "Epoch 469, Train loss 1.6126576556426846e-05, Test loss 0.5871295772492886, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.86285996437073 s\n",
      "Epoch 470, Train loss 2.0272464882297373e-05, Test loss 0.5870895326137543, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.86295676231384 s\n",
      "Model saved in epoch 470\n",
      "Epoch 471, Train loss 3.341589842351848e-05, Test loss 0.587057101726532, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.84175086021423 s\n",
      "Epoch 472, Train loss 1.8853502014076648e-05, Test loss 0.5870332002639771, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.8500554561615 s\n",
      "Epoch 473, Train loss 1.8499376723932713e-05, Test loss 0.5870424516499042, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.72628378868103 s\n",
      "Epoch 474, Train loss 1.5952441254221854e-05, Test loss 0.587044657766819, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.744187116622925 s\n",
      "Epoch 475, Train loss 1.5396548842736287e-05, Test loss 0.5870319522917271, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.735026359558105 s\n",
      "Model saved in epoch 475\n",
      "Epoch 476, Train loss 2.1917092692235388e-05, Test loss 0.5870126359164715, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.7090699672699 s\n",
      "Epoch 477, Train loss 1.2136656823336543e-05, Test loss 0.5870303489267826, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.69527244567871 s\n",
      "Epoch 478, Train loss 6.802178687388099e-05, Test loss 0.5870441749691964, Train accuracy 99.99800701530613, Test accuracy 93.22265625, Cost 51.69308352470398 s\n",
      "Epoch 479, Train loss 2.3233282036887096e-05, Test loss 0.5870759710669518, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.7969868183136 s\n",
      "Epoch 480, Train loss 2.6474212986203192e-05, Test loss 0.5870661340653897, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.4984929561615 s\n",
      "Model saved in epoch 480\n",
      "Epoch 481, Train loss 2.3719301266465565e-05, Test loss 0.5870543740689754, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.63131523132324 s\n",
      "Epoch 482, Train loss 1.4566048748480746e-05, Test loss 0.5870470598340034, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.62545585632324 s\n",
      "Epoch 483, Train loss 4.491684566702083e-05, Test loss 0.5871109023690224, Train accuracy 99.99800701530613, Test accuracy 93.22265625, Cost 51.70920968055725 s\n",
      "Epoch 484, Train loss 1.9136749491069076e-05, Test loss 0.5871184557676316, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.66234755516052 s\n",
      "Epoch 485, Train loss 1.60361655677629e-05, Test loss 0.5871268734335899, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.70310640335083 s\n",
      "Model saved in epoch 485\n",
      "Epoch 486, Train loss 1.3878979490140971e-05, Test loss 0.5871386438608169, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.69042944908142 s\n",
      "Epoch 487, Train loss 1.6096568939609166e-05, Test loss 0.5871295608580113, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.67168688774109 s\n",
      "Epoch 488, Train loss 2.5162818425658652e-05, Test loss 0.5871118709445, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.661532402038574 s\n",
      "Epoch 489, Train loss 1.3580221770407592e-05, Test loss 0.5871033079922199, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.68547177314758 s\n",
      "Epoch 490, Train loss 2.576108956868863e-05, Test loss 0.5870616912841797, Train accuracy 99.99800701530613, Test accuracy 93.22265625, Cost 51.70303678512573 s\n",
      "Model saved in epoch 490\n",
      "Epoch 491, Train loss 8.939273247908751e-06, Test loss 0.5870636232197285, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.684032917022705 s\n",
      "Epoch 492, Train loss 1.5802413484422573e-05, Test loss 0.587071468681097, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.68533635139465 s\n",
      "Epoch 493, Train loss 4.10313438397263e-05, Test loss 0.5870492063462734, Train accuracy 99.99800701530613, Test accuracy 93.22265625, Cost 51.68074417114258 s\n",
      "Epoch 494, Train loss 2.0696124854852402e-05, Test loss 0.5870488502085209, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.67536783218384 s\n",
      "Epoch 495, Train loss 1.5652488194244452e-05, Test loss 0.5870492577552795, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.664223432540894 s\n",
      "Model saved in epoch 495\n",
      "Epoch 496, Train loss 1.5714294719239948e-05, Test loss 0.5870490871369839, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.657447814941406 s\n",
      "Epoch 497, Train loss 1.0459069706912656e-05, Test loss 0.5870487824082374, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.499289989471436 s\n",
      "Epoch 498, Train loss 1.4975444654318872e-05, Test loss 0.5870511457324028, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.55522632598877 s\n",
      "Epoch 499, Train loss 2.8395465227148975e-05, Test loss 0.5870319381356239, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.860374212265015 s\n",
      "Epoch 500, Train loss 1.7257149307092315e-05, Test loss 0.5870319157838821, Train accuracy 100.0, Test accuracy 93.22265625, Cost 51.877625465393066 s\n",
      "Model saved in epoch 500\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500 # param\n",
    "epoch_start = 0\n",
    "path = 'batch_256_lr_0.1-0.0003_no_crop_kernel_4.pt'\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "train_accuracy_history = []\n",
    "test_accuracy_history = []\n",
    "\n",
    "Loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "lr = 0.1\n",
    "lr_min=0.0003\n",
    "momentum = 0.9\n",
    "nesterov = True\n",
    "optimizer = torch.optim.SGD(model1.parameters(),lr=lr,momentum=momentum,nesterov=nesterov)\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists(path):\n",
    "    checkpoint = torch.load(path)\n",
    "    print('Read model from checkpoint')\n",
    "    model1.cuda().load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch_start = checkpoint['epoch']\n",
    "    Loss = checkpoint['Loss']\n",
    "    train_loss_history = checkpoint['train_loss_history']\n",
    "    test_loss_history = checkpoint['test_loss_history']\n",
    "    train_accuracy_history = checkpoint['train_accuracy_history']\n",
    "    test_accuracy_history = checkpoint['test_accuracy_history']\n",
    "    print('Restart from epoch',epoch_start)\n",
    "    \n",
    "\n",
    "for epoch in range(epoch_start+1, num_epochs+1):\n",
    "    timestart = time.time()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    train_accuracy = 0.0\n",
    "    test_accuracy = 0.0\n",
    "\n",
    "    for i, data in enumerate(trainDataLoader):\n",
    "        images, labels = data\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        predicted_output = model1.cuda()(images)\n",
    "        fit = Loss(predicted_output,labels)\n",
    "        fit.backward()\n",
    "        adjust_learning_rate(optimizer=optimizer,current_epoch=epoch,max_epoch=num_epochs,lr_min=lr_min,lr_max=lr,warmup=True)\n",
    "        optimizer.step()\n",
    "        train_loss += fit.item()\n",
    "        train_accuracy += (torch.eq(torch.max(predicted_output,1)[1],labels).sum()/len(labels)*100).data.cpu().numpy()\n",
    "\n",
    "    for i, data in enumerate(testDataLoader):\n",
    "        with torch.no_grad():\n",
    "            images, labels = data\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            predicted_output = model1.cuda()(images)\n",
    "            fit = Loss(predicted_output,labels)\n",
    "            test_loss += fit.item()\n",
    "            test_accuracy += (torch.eq(torch.max(predicted_output,1)[1],labels).sum()/len(labels)*100).data.cpu().numpy()\n",
    "\n",
    "\n",
    "    train_loss = train_loss/len(trainDataLoader)\n",
    "    test_loss = test_loss/len(testDataLoader)\n",
    "    train_accu = train_accuracy/len(trainDataLoader)\n",
    "    test_accu = test_accuracy/len(testDataLoader)\n",
    "    train_loss_history.append(train_loss)\n",
    "    test_loss_history.append(test_loss)\n",
    "    train_accuracy_history.append(train_accu)\n",
    "    test_accuracy_history.append(test_accu)\n",
    "    print('Epoch %s, Train loss %s, Test loss %s, Train accuracy %s, Test accuracy %s, Cost %s s'%(epoch,\n",
    "                                                                                                   train_loss,test_loss,\n",
    "                                                                                                   train_accu,test_accu,\n",
    "                                                                                                   time.time()-timestart))\n",
    "\n",
    "    if epoch % 5 == 0 and epoch != 0:\n",
    "        torch.save({'epoch':epoch,\n",
    "          'model_state_dict':model1.cuda().state_dict(),\n",
    "          'optimizer_state_dict':optimizer.state_dict(),\n",
    "          'Loss':Loss,\n",
    "          'train_loss_history':train_loss_history,\n",
    "          'test_loss_history':test_loss_history,\n",
    "          'train_accuracy_history':train_accuracy_history,\n",
    "          'test_accuracy_history':test_accuracy_history},path)\n",
    "        print('Model saved in epoch %s'%(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 553 \n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(num_epochs),train_loss_history,'-',linewidth=3,label='Train error')\n",
    "plt.plot(range(num_epochs),test_loss_history,'-',linewidth=3,label='Test error')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(num_epochs),train_accuracy_history,'-',linewidth=3,label='Train accuracy')\n",
    "plt.plot(range(num_epochs),test_accuracy_history,'-',linewidth=3,label='Test accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy:',sum(test_accuracy_history[-5:])/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
