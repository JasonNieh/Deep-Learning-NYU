{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import math\n",
    "import torchvision\n",
    "from torchvision import transforms as transforms\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(17)\n",
    "torch.cuda.manual_seed_all(17)\n",
    "\n",
    "aug_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32,padding=4,padding_mode='reflect'),\n",
    "    transforms.RandomHorizontalFlip(), # 水平翻转\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4244, 0.4146, 0.3836), (0.2539, 0.2491, 0.2420)) # normalization\n",
    "    ])\n",
    "\n",
    "aug_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4244, 0.4146, 0.3836), (0.2539, 0.2491, 0.2420)) # normalization\n",
    "    ])\n",
    "\n",
    "trainingdata = torchvision.datasets.CIFAR10('./CIFAR10',train=True,download=True,transform=aug_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def load_data(is_train,aug,batch_size):\n",
    "    dataset = torchvision.datasets.CIFAR10('./CIFAR10',train=is_train,download=True,transform=aug)\n",
    "#   mean, std = get_mean_and_std(dataset)\n",
    "#   print(mean, std)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset,batch_size=batch_size,shuffle=is_train)\n",
    "    return dataloader\n",
    "\n",
    "batch_size = 256 # param\n",
    "trainDataLoader = load_data(is_train=True,aug=aug_train,batch_size=batch_size)\n",
    "testDataLoader = load_data(is_train=False,aug=aug_test,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32]) 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "image,label = trainingdata[0]\n",
    "print(image.shape, label)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.imshow(image.numpy().transpose(1,2,0))\n",
    "plt.title(str(classes[label]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "#         self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(x.shape)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "#         print(out.shape)\n",
    "        out = self.layer1(out)\n",
    "#         print(out.shape)\n",
    "        out = self.layer2(out)\n",
    "#         print(out.shape)\n",
    "        out = self.layer3(out)\n",
    "#         print(out.shape)\n",
    "#         out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "#         print(out.shape)\n",
    "        out = out.view(out.size(0), -1)\n",
    "#         print(out.shape)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu') # weight initialization\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)\n",
    "            elif isinstance(m,nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "            elif isinstance(m,nn.Linear):\n",
    "                nn.init.normal_(m.weight,std=1e-3)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)\n",
    "\n",
    "def project1_model():\n",
    "#     return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "    return ResNet(BasicBlock, [3, 3, 3])\n",
    "\n",
    "# model1 = nn.Sequential(project1_model(), nn.AdaptiveAvgPool2d((1,1)), nn.Flatten(), nn.Linear(512, 10)).cuda()\n",
    "model1 = project1_model().cuda()\n",
    "model1.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4335434\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    # torch.numel() returns number of elements in a tensor\n",
    "\n",
    "print(count_parameters(model1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read model from checkpoint\n",
      "Restart from epoch 500\n",
      "Epoch 501, Train loss 0.03374898353382489, Test loss 0.31314371302723887, Test accuracy 92.3828125, Cost 52.57499432563782 s\n",
      "Epoch 502, Train loss 0.038501406050458244, Test loss 0.3010561387985945, Test accuracy 92.451171875, Cost 52.57318925857544 s\n",
      "Epoch 503, Train loss 0.042486081935693414, Test loss 0.2982605967670679, Test accuracy 92.451171875, Cost 52.59165644645691 s\n",
      "Epoch 504, Train loss 0.03752754098374625, Test loss 0.29687433019280435, Test accuracy 92.314453125, Cost 52.616886377334595 s\n",
      "Epoch 505, Train loss 0.030602500983038728, Test loss 0.2992273334413767, Test accuracy 92.353515625, Cost 52.56173753738403 s\n",
      "Model saved in epoch 505\n",
      "Epoch 506, Train loss 0.028567936076611584, Test loss 0.3175880003720522, Test accuracy 92.4609375, Cost 52.54379630088806 s\n",
      "Epoch 507, Train loss 0.047139092980484874, Test loss 0.304410195723176, Test accuracy 92.05078125, Cost 52.61023688316345 s\n",
      "Epoch 508, Train loss 0.04632918947680416, Test loss 0.30292076580226424, Test accuracy 92.32421875, Cost 52.66575241088867 s\n",
      "Epoch 509, Train loss 0.037956638356708754, Test loss 0.27851060703396796, Test accuracy 92.55859375, Cost 52.682963132858276 s\n",
      "Epoch 510, Train loss 0.03259158970274943, Test loss 0.3050616394728422, Test accuracy 92.744140625, Cost 52.695847272872925 s\n",
      "Model saved in epoch 510\n",
      "Epoch 511, Train loss 0.03539369244850716, Test loss 0.3223802298307419, Test accuracy 92.12890625, Cost 52.70727062225342 s\n",
      "Epoch 512, Train loss 0.02980575378632591, Test loss 0.3292391192167997, Test accuracy 91.89453125, Cost 52.68262028694153 s\n",
      "Epoch 513, Train loss 0.04560367601486493, Test loss 0.3266511674970388, Test accuracy 91.708984375, Cost 52.654404401779175 s\n",
      "Epoch 514, Train loss 0.04735293746355693, Test loss 0.2933781947940588, Test accuracy 92.75390625, Cost 52.6515748500824 s\n",
      "Epoch 515, Train loss 0.031195781336222986, Test loss 0.30819036327302457, Test accuracy 92.51953125, Cost 52.65089511871338 s\n",
      "Model saved in epoch 515\n",
      "Epoch 516, Train loss 0.03847064915331727, Test loss 0.33192510046064855, Test accuracy 91.767578125, Cost 52.7059805393219 s\n",
      "Epoch 517, Train loss 0.04004700051867688, Test loss 0.3160004045814276, Test accuracy 91.9140625, Cost 52.7675096988678 s\n",
      "Epoch 518, Train loss 0.0372028517375263, Test loss 0.3501264162361622, Test accuracy 91.640625, Cost 52.765681982040405 s\n",
      "Epoch 519, Train loss 0.037104240642404376, Test loss 0.3507076557725668, Test accuracy 91.8359375, Cost 52.75909233093262 s\n",
      "Epoch 520, Train loss 0.040443004819336444, Test loss 0.3274857021868229, Test accuracy 92.1875, Cost 52.75645899772644 s\n",
      "Model saved in epoch 520\n",
      "Epoch 521, Train loss 0.04039342204888104, Test loss 0.2980873048305511, Test accuracy 92.626953125, Cost 52.71154046058655 s\n",
      "Epoch 522, Train loss 0.04450165955777451, Test loss 0.3041606767103076, Test accuracy 92.5390625, Cost 52.72078514099121 s\n",
      "Epoch 523, Train loss 0.03930212596279322, Test loss 0.32262802459299567, Test accuracy 91.884765625, Cost 52.7143771648407 s\n",
      "Epoch 524, Train loss 0.0423965481756141, Test loss 0.31813740693032744, Test accuracy 91.787109375, Cost 52.720606565475464 s\n",
      "Epoch 525, Train loss 0.03839944399018981, Test loss 0.316361677646637, Test accuracy 91.89453125, Cost 52.71692609786987 s\n",
      "Model saved in epoch 525\n",
      "Epoch 526, Train loss 0.03628217776743125, Test loss 0.33661709241569043, Test accuracy 92.08984375, Cost 52.779850006103516 s\n",
      "Epoch 527, Train loss 0.032134303770845335, Test loss 0.3295800969004631, Test accuracy 92.607421875, Cost 52.74234056472778 s\n",
      "Epoch 528, Train loss 0.030538217207340866, Test loss 0.31431404277682307, Test accuracy 92.197265625, Cost 52.74100399017334 s\n",
      "Epoch 529, Train loss 0.041548893929516176, Test loss 0.34721860736608506, Test accuracy 91.7578125, Cost 52.69631910324097 s\n",
      "Epoch 530, Train loss 0.043927514768794786, Test loss 0.34892433434724807, Test accuracy 91.25, Cost 52.70497918128967 s\n",
      "Model saved in epoch 530\n",
      "Epoch 531, Train loss 0.04360898281922754, Test loss 0.3197110753506422, Test accuracy 91.865234375, Cost 52.67286014556885 s\n",
      "Epoch 532, Train loss 0.03870965190212793, Test loss 0.324338436126709, Test accuracy 92.1875, Cost 52.666757106781006 s\n",
      "Epoch 533, Train loss 0.03494161793163845, Test loss 0.32715824581682684, Test accuracy 92.34375, Cost 52.666080951690674 s\n",
      "Epoch 534, Train loss 0.0381612975711041, Test loss 0.32846913002431394, Test accuracy 91.728515625, Cost 52.658708572387695 s\n",
      "Epoch 535, Train loss 0.035541418685615826, Test loss 0.31152224987745286, Test accuracy 92.2265625, Cost 52.661221981048584 s\n",
      "Model saved in epoch 535\n",
      "Epoch 536, Train loss 0.04227776213416031, Test loss 0.31407034359872343, Test accuracy 91.943359375, Cost 52.63973355293274 s\n",
      "Epoch 537, Train loss 0.03615121484011868, Test loss 0.31675706543028354, Test accuracy 92.20703125, Cost 52.679933309555054 s\n",
      "Epoch 538, Train loss 0.03301441261772903, Test loss 0.3124894306063652, Test accuracy 92.421875, Cost 52.719966411590576 s\n",
      "Epoch 539, Train loss 0.034575926389412155, Test loss 0.29780437983572483, Test accuracy 92.314453125, Cost 52.741968631744385 s\n",
      "Epoch 540, Train loss 0.04215929139053867, Test loss 0.293945026025176, Test accuracy 92.021484375, Cost 52.729480266571045 s\n",
      "Model saved in epoch 540\n",
      "Epoch 541, Train loss 0.03940365462069761, Test loss 0.2952691182494164, Test accuracy 92.51953125, Cost 52.74110221862793 s\n",
      "Epoch 542, Train loss 0.02957582746499351, Test loss 0.32106318771839143, Test accuracy 92.236328125, Cost 52.75041103363037 s\n",
      "Epoch 543, Train loss 0.04750585056157136, Test loss 0.30858061611652376, Test accuracy 92.412109375, Cost 52.755425214767456 s\n",
      "Epoch 544, Train loss 0.04066887460601497, Test loss 0.3214920911937952, Test accuracy 92.28515625, Cost 52.75587844848633 s\n",
      "Epoch 545, Train loss 0.030638315541460653, Test loss 0.3141328863799572, Test accuracy 92.353515625, Cost 52.749316453933716 s\n",
      "Model saved in epoch 545\n",
      "Epoch 546, Train loss 0.033100538955982396, Test loss 0.3087463241070509, Test accuracy 92.3046875, Cost 52.72649884223938 s\n",
      "Epoch 547, Train loss 0.033855377073988925, Test loss 0.3542288146913052, Test accuracy 91.728515625, Cost 52.74966907501221 s\n",
      "Epoch 548, Train loss 0.05123246899254772, Test loss 0.3285180699080229, Test accuracy 91.845703125, Cost 52.73936986923218 s\n",
      "Epoch 549, Train loss 0.045558223538860985, Test loss 0.3239637676626444, Test accuracy 91.787109375, Cost 52.772350788116455 s\n",
      "Epoch 550, Train loss 0.04246508581943962, Test loss 0.307752276211977, Test accuracy 91.982421875, Cost 52.80249500274658 s\n",
      "Model saved in epoch 550\n",
      "Epoch 551, Train loss 0.035901532057026515, Test loss 0.31933286152780055, Test accuracy 91.904296875, Cost 52.750773668289185 s\n",
      "Epoch 552, Train loss 0.045286214843924553, Test loss 0.29181452207267283, Test accuracy 92.314453125, Cost 52.745800495147705 s\n",
      "Epoch 553, Train loss 0.04010229088290005, Test loss 0.30261859856545925, Test accuracy 92.158203125, Cost 52.75233483314514 s\n",
      "Epoch 554, Train loss 0.030880350992558713, Test loss 0.2892704952508211, Test accuracy 92.65625, Cost 52.735538482666016 s\n",
      "Epoch 555, Train loss 0.030783869368879467, Test loss 0.30955622233450414, Test accuracy 92.3828125, Cost 52.75474309921265 s\n",
      "Model saved in epoch 555\n",
      "Epoch 556, Train loss 0.038947823089167326, Test loss 0.3066717963665724, Test accuracy 92.685546875, Cost 52.7134325504303 s\n",
      "Epoch 557, Train loss 0.03801543246574548, Test loss 0.3228067524731159, Test accuracy 91.8359375, Cost 52.71714901924133 s\n",
      "Epoch 558, Train loss 0.03864332540816038, Test loss 0.29833592735230924, Test accuracy 92.51953125, Cost 52.72362780570984 s\n",
      "Epoch 559, Train loss 0.03289486268269164, Test loss 0.32444961108267306, Test accuracy 92.294921875, Cost 52.72867822647095 s\n",
      "Epoch 560, Train loss 0.034564296063986054, Test loss 0.2973023738712072, Test accuracy 92.412109375, Cost 52.72378635406494 s\n",
      "Model saved in epoch 560\n",
      "Epoch 561, Train loss 0.036791113008060775, Test loss 0.3453078676015139, Test accuracy 91.748046875, Cost 52.72461724281311 s\n",
      "Epoch 562, Train loss 0.03626353480872147, Test loss 0.3234851997345686, Test accuracy 92.48046875, Cost 52.71547508239746 s\n",
      "Epoch 563, Train loss 0.04124926494040089, Test loss 0.3317609362304211, Test accuracy 92.1484375, Cost 52.72799038887024 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 564, Train loss 0.044311247618716895, Test loss 0.2980454910546541, Test accuracy 92.236328125, Cost 52.739235162734985 s\n",
      "Epoch 565, Train loss 0.044685145721257646, Test loss 0.30677397139370444, Test accuracy 92.177734375, Cost 52.74429249763489 s\n",
      "Model saved in epoch 565\n",
      "Epoch 566, Train loss 0.032117963566596866, Test loss 0.3084982126951218, Test accuracy 92.5, Cost 52.7007999420166 s\n",
      "Epoch 567, Train loss 0.03264513639828228, Test loss 0.2919411674141884, Test accuracy 92.568359375, Cost 52.71148991584778 s\n",
      "Epoch 568, Train loss 0.03455022396757362, Test loss 0.30115782991051676, Test accuracy 92.666015625, Cost 52.702903509140015 s\n",
      "Epoch 569, Train loss 0.0414473473721621, Test loss 0.32252622991800306, Test accuracy 92.099609375, Cost 52.71967911720276 s\n",
      "Epoch 570, Train loss 0.03799566894304007, Test loss 0.303499935567379, Test accuracy 92.490234375, Cost 52.72026085853577 s\n",
      "Model saved in epoch 570\n",
      "Epoch 571, Train loss 0.0374819342598167, Test loss 0.3572248887270689, Test accuracy 91.66015625, Cost 52.7568883895874 s\n",
      "Epoch 572, Train loss 0.039325413313143105, Test loss 0.339507132396102, Test accuracy 92.177734375, Cost 52.73372745513916 s\n",
      "Epoch 573, Train loss 0.037424227355846336, Test loss 0.33830107413232324, Test accuracy 91.884765625, Cost 52.73464107513428 s\n",
      "Epoch 574, Train loss 0.03978046933569166, Test loss 0.32055082619190217, Test accuracy 91.953125, Cost 52.79029870033264 s\n",
      "Epoch 575, Train loss 0.04778566046104747, Test loss 0.28844809122383597, Test accuracy 92.2265625, Cost 52.75672650337219 s\n",
      "Model saved in epoch 575\n",
      "Epoch 576, Train loss 0.032690826423314154, Test loss 0.3178141459822655, Test accuracy 92.40234375, Cost 52.69071650505066 s\n",
      "Epoch 577, Train loss 0.034560560160886725, Test loss 0.29582703560590745, Test accuracy 92.9296875, Cost 52.6189751625061 s\n",
      "Epoch 578, Train loss 0.03136480041085837, Test loss 0.3077116720378399, Test accuracy 92.4609375, Cost 52.6642587184906 s\n",
      "Epoch 579, Train loss 0.04112372935359956, Test loss 0.3148938905447721, Test accuracy 92.294921875, Cost 52.673229455947876 s\n",
      "Epoch 580, Train loss 0.04756412912654329, Test loss 0.3130974620580673, Test accuracy 92.20703125, Cost 52.64669108390808 s\n",
      "Model saved in epoch 580\n",
      "Epoch 581, Train loss 0.038240285739967864, Test loss 0.30809335224330425, Test accuracy 92.24609375, Cost 52.658586740493774 s\n",
      "Epoch 582, Train loss 0.031879961139009316, Test loss 0.3068241305649281, Test accuracy 92.2265625, Cost 52.93079614639282 s\n",
      "Epoch 583, Train loss 0.032491074452100664, Test loss 0.3193966828286648, Test accuracy 92.373046875, Cost 52.72068667411804 s\n",
      "Epoch 584, Train loss 0.02885191858750863, Test loss 0.3092710018157959, Test accuracy 92.5390625, Cost 52.708056926727295 s\n",
      "Epoch 585, Train loss 0.04247801488607514, Test loss 0.3194736234843731, Test accuracy 92.333984375, Cost 52.697786808013916 s\n",
      "Model saved in epoch 585\n",
      "Epoch 586, Train loss 0.03755647470053209, Test loss 0.31790693774819373, Test accuracy 92.431640625, Cost 52.55888915061951 s\n",
      "Epoch 587, Train loss 0.0361594761465201, Test loss 0.33671860024333, Test accuracy 91.884765625, Cost 52.68918323516846 s\n",
      "Epoch 588, Train loss 0.04304437390148488, Test loss 0.2927671816200018, Test accuracy 92.470703125, Cost 74.95038032531738 s\n",
      "Epoch 589, Train loss 0.038328178566690456, Test loss 0.30461837761104105, Test accuracy 92.255859375, Cost 75.12322115898132 s\n",
      "Epoch 590, Train loss 0.03362629980523595, Test loss 0.3056860826909542, Test accuracy 92.314453125, Cost 75.08833193778992 s\n",
      "Model saved in epoch 590\n",
      "Epoch 591, Train loss 0.03647735653378602, Test loss 0.2900651045143604, Test accuracy 92.548828125, Cost 75.31936192512512 s\n",
      "Epoch 592, Train loss 0.034502722337195764, Test loss 0.3498174849897623, Test accuracy 91.85546875, Cost 75.31145668029785 s\n",
      "Epoch 593, Train loss 0.04534102602842815, Test loss 0.3187079008668661, Test accuracy 92.158203125, Cost 75.2986056804657 s\n",
      "Epoch 594, Train loss 0.03957211956077693, Test loss 0.29284420795738697, Test accuracy 92.685546875, Cost 75.30147671699524 s\n",
      "Epoch 595, Train loss 0.02472630286665291, Test loss 0.3109742071479559, Test accuracy 92.470703125, Cost 75.41824531555176 s\n",
      "Model saved in epoch 595\n",
      "Epoch 596, Train loss 0.03431829909927079, Test loss 0.3131946623325348, Test accuracy 92.060546875, Cost 75.22853779792786 s\n",
      "Epoch 597, Train loss 0.03636756297010852, Test loss 0.29569685980677607, Test accuracy 92.822265625, Cost 75.20655846595764 s\n",
      "Epoch 598, Train loss 0.044202661854500065, Test loss 0.30860547721385956, Test accuracy 92.060546875, Cost 75.24086427688599 s\n",
      "Epoch 599, Train loss 0.03748712999917263, Test loss 0.2881720755249262, Test accuracy 92.3828125, Cost 75.35302400588989 s\n",
      "Epoch 600, Train loss 0.03706876160244325, Test loss 0.29607377722859385, Test accuracy 92.626953125, Cost 75.37225127220154 s\n",
      "Model saved in epoch 600\n",
      "Epoch 601, Train loss 0.0342306311180511, Test loss 0.3355833478271961, Test accuracy 91.69921875, Cost 75.36719989776611 s\n",
      "Epoch 602, Train loss 0.03576447634140448, Test loss 0.3052192825824022, Test accuracy 92.177734375, Cost 75.40483236312866 s\n",
      "Epoch 603, Train loss 0.04656380532803584, Test loss 0.2915789745748043, Test accuracy 92.71484375, Cost 75.25670671463013 s\n",
      "Epoch 604, Train loss 0.03866027937536793, Test loss 0.31540482118725777, Test accuracy 92.67578125, Cost 75.30943012237549 s\n",
      "Epoch 605, Train loss 0.03618942853063345, Test loss 0.31209896206855775, Test accuracy 92.275390625, Cost 75.42787432670593 s\n",
      "Model saved in epoch 605\n",
      "Epoch 606, Train loss 0.03241732339992435, Test loss 0.3022240839898586, Test accuracy 92.919921875, Cost 75.21066904067993 s\n",
      "Epoch 607, Train loss 0.030501913614285996, Test loss 0.3120701093226671, Test accuracy 91.982421875, Cost 75.19178700447083 s\n",
      "Epoch 608, Train loss 0.03552084129864388, Test loss 0.3155100965872407, Test accuracy 91.923828125, Cost 75.30475926399231 s\n",
      "Epoch 609, Train loss 0.0435564577275393, Test loss 0.3079724695533514, Test accuracy 92.12890625, Cost 75.48084259033203 s\n",
      "Epoch 610, Train loss 0.038569382543922684, Test loss 0.31639728099107745, Test accuracy 92.392578125, Cost 75.6123218536377 s\n",
      "Model saved in epoch 610\n",
      "Epoch 611, Train loss 0.04469134085526576, Test loss 0.32015553675591946, Test accuracy 92.2265625, Cost 75.30106210708618 s\n",
      "Epoch 612, Train loss 0.0471376225195483, Test loss 0.3106681391596794, Test accuracy 92.1484375, Cost 75.30844855308533 s\n",
      "Epoch 613, Train loss 0.032064552832280796, Test loss 0.29818529859185217, Test accuracy 92.65625, Cost 75.36761617660522 s\n",
      "Epoch 614, Train loss 0.031108922111250614, Test loss 0.30960020497441293, Test accuracy 92.4609375, Cost 75.2332980632782 s\n",
      "Epoch 615, Train loss 0.029299407598695586, Test loss 0.31841840092092755, Test accuracy 92.626953125, Cost 75.35398077964783 s\n",
      "Model saved in epoch 615\n",
      "Epoch 616, Train loss 0.031396195665477036, Test loss 0.3164319206029177, Test accuracy 92.4609375, Cost 75.36782836914062 s\n",
      "Epoch 617, Train loss 0.03969385502954983, Test loss 0.332678297534585, Test accuracy 91.8359375, Cost 75.42089438438416 s\n",
      "Epoch 618, Train loss 0.03573618637521428, Test loss 0.2904856991022825, Test accuracy 92.451171875, Cost 75.17007207870483 s\n",
      "Epoch 619, Train loss 0.039484879933297634, Test loss 0.3022034000605345, Test accuracy 92.490234375, Cost 75.20458579063416 s\n",
      "Epoch 620, Train loss 0.035744091424596856, Test loss 0.3189736925065517, Test accuracy 92.12890625, Cost 75.2514066696167 s\n",
      "Model saved in epoch 620\n",
      "Epoch 621, Train loss 0.046241311545303206, Test loss 0.3148279547691345, Test accuracy 92.2265625, Cost 75.30121088027954 s\n",
      "Epoch 622, Train loss 0.0294965494433608, Test loss 0.32114085033535955, Test accuracy 92.412109375, Cost 75.21917223930359 s\n",
      "Epoch 623, Train loss 0.035029230511044056, Test loss 0.30546804182231424, Test accuracy 92.34375, Cost 75.27667236328125 s\n",
      "Epoch 624, Train loss 0.03682930158850338, Test loss 0.32284373231232166, Test accuracy 91.474609375, Cost 75.24597692489624 s\n",
      "Epoch 625, Train loss 0.039900225544424385, Test loss 0.3360923036932945, Test accuracy 91.630859375, Cost 75.30479025840759 s\n",
      "Model saved in epoch 625\n",
      "Epoch 626, Train loss 0.03660717349005293, Test loss 0.32958442643284797, Test accuracy 92.51953125, Cost 75.31170701980591 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 627, Train loss 0.03549055248612956, Test loss 0.34715038128197195, Test accuracy 91.66015625, Cost 75.27736926078796 s\n",
      "Epoch 628, Train loss 0.030293308329122255, Test loss 0.306088050827384, Test accuracy 92.265625, Cost 75.26872134208679 s\n",
      "Epoch 629, Train loss 0.03945276928514394, Test loss 0.32875496074557303, Test accuracy 92.099609375, Cost 75.11673903465271 s\n",
      "Epoch 630, Train loss 0.03398229707536116, Test loss 0.3279669348150492, Test accuracy 92.353515625, Cost 75.33920001983643 s\n",
      "Model saved in epoch 630\n",
      "Epoch 631, Train loss 0.03269588829455327, Test loss 0.2948714304715395, Test accuracy 92.705078125, Cost 75.45752477645874 s\n",
      "Epoch 632, Train loss 0.03582675476102348, Test loss 0.3268939547240734, Test accuracy 91.904296875, Cost 75.51274156570435 s\n",
      "Epoch 633, Train loss 0.036557741952603875, Test loss 0.2964804593473673, Test accuracy 92.431640625, Cost 75.26331782341003 s\n",
      "Epoch 634, Train loss 0.03627953207481424, Test loss 0.30287802703678607, Test accuracy 92.67578125, Cost 75.32971405982971 s\n",
      "Epoch 635, Train loss 0.04114240732956297, Test loss 0.30393429175019265, Test accuracy 92.24609375, Cost 75.1490695476532 s\n",
      "Model saved in epoch 635\n",
      "Epoch 636, Train loss 0.04972653183135755, Test loss 0.27757495194673537, Test accuracy 92.646484375, Cost 75.09931778907776 s\n",
      "Epoch 637, Train loss 0.04059948995519353, Test loss 0.2933529824018478, Test accuracy 92.421875, Cost 75.24845314025879 s\n",
      "Epoch 638, Train loss 0.037342166734802326, Test loss 0.274065025895834, Test accuracy 92.939453125, Cost 75.07953572273254 s\n",
      "Epoch 639, Train loss 0.030473318568677927, Test loss 0.31812182664871214, Test accuracy 92.24609375, Cost 75.25880169868469 s\n",
      "Epoch 640, Train loss 0.03903022498291518, Test loss 0.34107866175472734, Test accuracy 91.669921875, Cost 75.28091669082642 s\n",
      "Model saved in epoch 640\n",
      "Epoch 641, Train loss 0.03321970479410826, Test loss 0.32074565887451173, Test accuracy 92.314453125, Cost 75.2748441696167 s\n",
      "Epoch 642, Train loss 0.031808846922382256, Test loss 0.31683447733521464, Test accuracy 92.5390625, Cost 75.28035950660706 s\n",
      "Epoch 643, Train loss 0.040285922002465446, Test loss 0.32341803461313245, Test accuracy 92.01171875, Cost 75.31109237670898 s\n",
      "Epoch 644, Train loss 0.03829573586164993, Test loss 0.3226663190871477, Test accuracy 92.353515625, Cost 75.24117374420166 s\n",
      "Epoch 645, Train loss 0.03859162181188181, Test loss 0.33865063115954397, Test accuracy 92.041015625, Cost 75.3849093914032 s\n",
      "Model saved in epoch 645\n",
      "Epoch 646, Train loss 0.02787641667741902, Test loss 0.3011246740818024, Test accuracy 92.55859375, Cost 75.29401302337646 s\n",
      "Epoch 647, Train loss 0.030839971207291345, Test loss 0.3247351124882698, Test accuracy 92.01171875, Cost 75.32884693145752 s\n",
      "Epoch 648, Train loss 0.04355055316617446, Test loss 0.30655055716633794, Test accuracy 92.24609375, Cost 75.22746300697327 s\n",
      "Epoch 649, Train loss 0.036295411680654, Test loss 0.32714349068701265, Test accuracy 91.943359375, Cost 75.24849796295166 s\n",
      "Epoch 650, Train loss 0.035672946932858655, Test loss 0.3180426977574825, Test accuracy 92.548828125, Cost 75.26844644546509 s\n",
      "Model saved in epoch 650\n",
      "Epoch 651, Train loss 0.031942596870512534, Test loss 0.2863906633108854, Test accuracy 93.046875, Cost 75.43043351173401 s\n",
      "Epoch 652, Train loss 0.0379572455790274, Test loss 0.3218121450394392, Test accuracy 92.24609375, Cost 75.38547825813293 s\n",
      "Epoch 653, Train loss 0.04126625558437438, Test loss 0.3015761662274599, Test accuracy 92.197265625, Cost 75.60077238082886 s\n",
      "Epoch 654, Train loss 0.037653122807624846, Test loss 0.31783306412398815, Test accuracy 91.796875, Cost 75.62661862373352 s\n",
      "Epoch 655, Train loss 0.034631432647037566, Test loss 0.2880664259195328, Test accuracy 92.3828125, Cost 75.38097476959229 s\n",
      "Model saved in epoch 655\n",
      "Epoch 656, Train loss 0.03834994160570204, Test loss 0.3158051647245884, Test accuracy 92.08984375, Cost 75.138108253479 s\n",
      "Epoch 657, Train loss 0.03643244245013564, Test loss 0.31788143143057823, Test accuracy 92.3828125, Cost 75.17344188690186 s\n",
      "Epoch 658, Train loss 0.03476128738839179, Test loss 0.2841434732079506, Test accuracy 92.32421875, Cost 75.17621970176697 s\n",
      "Epoch 659, Train loss 0.041020353234430054, Test loss 0.33016914278268816, Test accuracy 91.796875, Cost 75.1557867527008 s\n",
      "Epoch 660, Train loss 0.03787241110160035, Test loss 0.2804119486361742, Test accuracy 92.83203125, Cost 75.1902322769165 s\n",
      "Model saved in epoch 660\n",
      "Epoch 661, Train loss 0.030582095313418125, Test loss 0.3147440318018198, Test accuracy 92.568359375, Cost 75.17689609527588 s\n",
      "Epoch 662, Train loss 0.0407481499310887, Test loss 0.2939999416470528, Test accuracy 92.607421875, Cost 75.2452802658081 s\n",
      "Epoch 663, Train loss 0.03834148852050076, Test loss 0.27896549478173255, Test accuracy 92.880859375, Cost 75.28342056274414 s\n",
      "Epoch 664, Train loss 0.0330204211641103, Test loss 0.28089261837303636, Test accuracy 92.6171875, Cost 75.24582839012146 s\n",
      "Epoch 665, Train loss 0.03864159532680119, Test loss 0.32146736457943914, Test accuracy 92.158203125, Cost 75.14615082740784 s\n",
      "Model saved in epoch 665\n",
      "Epoch 666, Train loss 0.035780006226114165, Test loss 0.29711625836789607, Test accuracy 92.529296875, Cost 75.12787461280823 s\n",
      "Epoch 667, Train loss 0.03913919617212853, Test loss 0.30777683965861796, Test accuracy 92.20703125, Cost 75.20802712440491 s\n",
      "Epoch 668, Train loss 0.033995189297735234, Test loss 0.3075412016361952, Test accuracy 92.36328125, Cost 75.18085789680481 s\n",
      "Epoch 669, Train loss 0.045168926335909236, Test loss 0.27425699941813947, Test accuracy 92.744140625, Cost 75.17326474189758 s\n",
      "Epoch 670, Train loss 0.03938857188961488, Test loss 0.29603204913437364, Test accuracy 92.36328125, Cost 75.1321451663971 s\n",
      "Model saved in epoch 670\n",
      "Epoch 671, Train loss 0.03051843753616725, Test loss 0.2872949935495853, Test accuracy 93.18359375, Cost 75.20903706550598 s\n",
      "Epoch 672, Train loss 0.03179463123004617, Test loss 0.2912121437489986, Test accuracy 92.587890625, Cost 75.24772000312805 s\n",
      "Epoch 673, Train loss 0.03247384549289638, Test loss 0.3063177477568388, Test accuracy 92.529296875, Cost 75.37461447715759 s\n",
      "Epoch 674, Train loss 0.038118597039268634, Test loss 0.2706560742110014, Test accuracy 92.607421875, Cost 75.42069268226624 s\n",
      "Epoch 675, Train loss 0.03494969276920417, Test loss 0.2839505229145288, Test accuracy 92.63671875, Cost 75.70353817939758 s\n",
      "Model saved in epoch 675\n",
      "Epoch 676, Train loss 0.04200187656667312, Test loss 0.32600496485829356, Test accuracy 92.314453125, Cost 75.47053527832031 s\n",
      "Epoch 677, Train loss 0.03498532355772521, Test loss 0.2936224929988384, Test accuracy 92.900390625, Cost 75.43633031845093 s\n",
      "Epoch 678, Train loss 0.0378879249186198, Test loss 0.29601614233106377, Test accuracy 92.431640625, Cost 75.45945692062378 s\n",
      "Epoch 679, Train loss 0.029199519050925285, Test loss 0.32653074376285074, Test accuracy 91.943359375, Cost 75.51350593566895 s\n",
      "Epoch 680, Train loss 0.03681597448600342, Test loss 0.3143189910799265, Test accuracy 91.865234375, Cost 75.46461391448975 s\n",
      "Model saved in epoch 680\n",
      "Epoch 681, Train loss 0.03820874879364761, Test loss 0.30695463083684443, Test accuracy 92.5, Cost 75.34291958808899 s\n",
      "Epoch 682, Train loss 0.043999516291125695, Test loss 0.30030020140111446, Test accuracy 92.529296875, Cost 75.14509439468384 s\n",
      "Epoch 683, Train loss 0.034416002763093125, Test loss 0.29764159880578517, Test accuracy 92.392578125, Cost 75.36975383758545 s\n",
      "Epoch 684, Train loss 0.03580990710476299, Test loss 0.3100685697048903, Test accuracy 92.28515625, Cost 75.34499883651733 s\n",
      "Epoch 685, Train loss 0.036644415447621474, Test loss 0.3091937333345413, Test accuracy 92.12890625, Cost 75.26855731010437 s\n",
      "Model saved in epoch 685\n",
      "Epoch 686, Train loss 0.03820183154252567, Test loss 0.3427777860313654, Test accuracy 91.5234375, Cost 75.45103621482849 s\n",
      "Epoch 687, Train loss 0.03590573382098228, Test loss 0.2917118929326534, Test accuracy 92.36328125, Cost 75.29284024238586 s\n",
      "Epoch 688, Train loss 0.03143980987702629, Test loss 0.3184957608580589, Test accuracy 91.884765625, Cost 75.3360698223114 s\n",
      "Epoch 689, Train loss 0.029791180923467084, Test loss 0.35798392705619336, Test accuracy 91.796875, Cost 75.29678177833557 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 690, Train loss 0.03730291668420695, Test loss 0.3225305858999491, Test accuracy 91.9921875, Cost 75.27215456962585 s\n",
      "Model saved in epoch 690\n",
      "Epoch 691, Train loss 0.042548939143782674, Test loss 0.294383106008172, Test accuracy 92.529296875, Cost 75.54316735267639 s\n",
      "Epoch 692, Train loss 0.035486952755695245, Test loss 0.31421588733792305, Test accuracy 92.080078125, Cost 75.38816332817078 s\n",
      "Epoch 693, Train loss 0.03552386840586835, Test loss 0.3137892082333565, Test accuracy 92.275390625, Cost 75.2848391532898 s\n",
      "Epoch 694, Train loss 0.034420290194470814, Test loss 0.29365326799452307, Test accuracy 92.55859375, Cost 75.37705063819885 s\n",
      "Epoch 695, Train loss 0.0337124996538255, Test loss 0.30138207525014876, Test accuracy 92.67578125, Cost 75.3152666091919 s\n",
      "Model saved in epoch 695\n",
      "Epoch 696, Train loss 0.036766986227214186, Test loss 0.30650751292705536, Test accuracy 92.6171875, Cost 75.33427095413208 s\n",
      "Epoch 697, Train loss 0.03939464536961168, Test loss 0.3005165632814169, Test accuracy 92.75390625, Cost 75.52980899810791 s\n",
      "Epoch 698, Train loss 0.02506225931633986, Test loss 0.3003809489309788, Test accuracy 92.8125, Cost 75.48345851898193 s\n",
      "Epoch 699, Train loss 0.03378426838590174, Test loss 0.31205249987542627, Test accuracy 92.34375, Cost 75.33580613136292 s\n",
      "Epoch 700, Train loss 0.02782894883361854, Test loss 0.29437902197241783, Test accuracy 92.9296875, Cost 75.35821914672852 s\n",
      "Model saved in epoch 700\n",
      "Epoch 701, Train loss 0.0360837956553097, Test loss 0.3015927944332361, Test accuracy 92.099609375, Cost 75.38070058822632 s\n",
      "Epoch 702, Train loss 0.036817560312148105, Test loss 0.31653890684247016, Test accuracy 92.1484375, Cost 75.35681748390198 s\n",
      "Epoch 703, Train loss 0.03477558134627357, Test loss 0.32074139900505544, Test accuracy 92.373046875, Cost 75.26172614097595 s\n",
      "Epoch 704, Train loss 0.04923913093302779, Test loss 0.2880655717104673, Test accuracy 92.216796875, Cost 75.27144932746887 s\n",
      "Epoch 705, Train loss 0.04334257779006219, Test loss 0.30636732615530493, Test accuracy 92.294921875, Cost 75.306565284729 s\n",
      "Model saved in epoch 705\n",
      "Epoch 706, Train loss 0.03070358752881234, Test loss 0.29897334426641464, Test accuracy 92.87109375, Cost 75.296550989151 s\n",
      "Epoch 707, Train loss 0.0309330099143506, Test loss 0.3122498098760843, Test accuracy 92.5, Cost 75.34036421775818 s\n",
      "Epoch 708, Train loss 0.03302595585736693, Test loss 0.313220738992095, Test accuracy 92.275390625, Cost 75.27830123901367 s\n",
      "Epoch 709, Train loss 0.0374508094855071, Test loss 0.2999801985919476, Test accuracy 92.36328125, Cost 75.38613653182983 s\n",
      "Epoch 710, Train loss 0.03464725329445637, Test loss 0.3105984222143888, Test accuracy 92.734375, Cost 75.3840024471283 s\n",
      "Model saved in epoch 710\n",
      "Epoch 711, Train loss 0.03253324233632231, Test loss 0.33660054169595244, Test accuracy 92.28515625, Cost 75.39170479774475 s\n",
      "Epoch 712, Train loss 0.03779562364798039, Test loss 0.32816467359662055, Test accuracy 92.24609375, Cost 75.31876349449158 s\n",
      "Epoch 713, Train loss 0.04489394697379701, Test loss 0.33235885538160803, Test accuracy 91.884765625, Cost 75.38701367378235 s\n",
      "Epoch 714, Train loss 0.03760484824128145, Test loss 0.3070343445986509, Test accuracy 92.509765625, Cost 75.27411317825317 s\n",
      "Epoch 715, Train loss 0.03902064548444231, Test loss 0.29943062253296376, Test accuracy 92.392578125, Cost 75.32470273971558 s\n",
      "Model saved in epoch 715\n",
      "Epoch 716, Train loss 0.03682132466335078, Test loss 0.2939055532217026, Test accuracy 92.67578125, Cost 75.25438833236694 s\n",
      "Epoch 717, Train loss 0.03511075530087157, Test loss 0.3060898518189788, Test accuracy 92.294921875, Cost 75.21985721588135 s\n",
      "Epoch 718, Train loss 0.03145676361853067, Test loss 0.29938109777867794, Test accuracy 92.75390625, Cost 75.32576179504395 s\n",
      "Epoch 719, Train loss 0.03114977538851755, Test loss 0.3431214727461338, Test accuracy 92.158203125, Cost 75.65448117256165 s\n",
      "Epoch 720, Train loss 0.04697180463343251, Test loss 0.31438578478991985, Test accuracy 92.3046875, Cost 75.5058023929596 s\n",
      "Model saved in epoch 720\n",
      "Epoch 721, Train loss 0.037009297943750054, Test loss 0.3145146656781435, Test accuracy 92.51953125, Cost 75.23849081993103 s\n",
      "Epoch 722, Train loss 0.03271297353547903, Test loss 0.30934640653431417, Test accuracy 92.490234375, Cost 75.16197633743286 s\n",
      "Epoch 723, Train loss 0.03137970878742635, Test loss 0.3150075625628233, Test accuracy 92.5, Cost 75.26687145233154 s\n",
      "Epoch 724, Train loss 0.03271860565885673, Test loss 0.3203248344361782, Test accuracy 92.216796875, Cost 75.12076663970947 s\n",
      "Epoch 725, Train loss 0.03603033618098695, Test loss 0.31063396856188774, Test accuracy 92.451171875, Cost 75.23660063743591 s\n",
      "Model saved in epoch 725\n",
      "Epoch 726, Train loss 0.03886683292838992, Test loss 0.3183080706745386, Test accuracy 92.392578125, Cost 75.31188607215881 s\n",
      "Epoch 727, Train loss 0.04319371330095645, Test loss 0.3288159500807524, Test accuracy 91.58203125, Cost 75.26702380180359 s\n",
      "Epoch 728, Train loss 0.03583414507412105, Test loss 0.283122431859374, Test accuracy 92.734375, Cost 75.422931432724 s\n",
      "Epoch 729, Train loss 0.02515969635343787, Test loss 0.2910729479044676, Test accuracy 92.998046875, Cost 75.22599220275879 s\n",
      "Epoch 730, Train loss 0.03121101959342403, Test loss 0.3135362781584263, Test accuracy 92.32421875, Cost 75.36322140693665 s\n",
      "Model saved in epoch 730\n",
      "Epoch 731, Train loss 0.03906111092287667, Test loss 0.30729130394756793, Test accuracy 92.412109375, Cost 75.33547854423523 s\n",
      "Epoch 732, Train loss 0.03823411866205231, Test loss 0.28666398748755456, Test accuracy 92.353515625, Cost 75.35647964477539 s\n",
      "Epoch 733, Train loss 0.03585118450680558, Test loss 0.28590399995446203, Test accuracy 93.046875, Cost 75.24404716491699 s\n",
      "Epoch 734, Train loss 0.04203517413318005, Test loss 0.2990135096013546, Test accuracy 92.40234375, Cost 75.26337051391602 s\n",
      "Epoch 735, Train loss 0.03584268079994588, Test loss 0.3021737426519394, Test accuracy 92.28515625, Cost 75.29669737815857 s\n",
      "Model saved in epoch 735\n",
      "Epoch 736, Train loss 0.03705842594844194, Test loss 0.29380827136337756, Test accuracy 92.744140625, Cost 75.3778338432312 s\n",
      "Epoch 737, Train loss 0.03036099659250479, Test loss 0.3519981227815151, Test accuracy 91.5234375, Cost 75.27383518218994 s\n",
      "Epoch 738, Train loss 0.03829975170558508, Test loss 0.32776247411966325, Test accuracy 92.392578125, Cost 75.30282759666443 s\n",
      "Epoch 739, Train loss 0.03872911510656455, Test loss 0.3240533322095871, Test accuracy 92.197265625, Cost 75.22431468963623 s\n",
      "Epoch 740, Train loss 0.03855167260412507, Test loss 0.30224196799099445, Test accuracy 92.36328125, Cost 75.33309030532837 s\n",
      "Model saved in epoch 740\n",
      "Epoch 741, Train loss 0.0316487479270721, Test loss 0.2790064312517643, Test accuracy 92.7734375, Cost 75.5275411605835 s\n",
      "Epoch 742, Train loss 0.03335761767812073, Test loss 0.32569759972393514, Test accuracy 92.20703125, Cost 75.4117968082428 s\n",
      "Epoch 743, Train loss 0.035093683397815545, Test loss 0.296147321164608, Test accuracy 92.51953125, Cost 75.20456218719482 s\n",
      "Epoch 744, Train loss 0.03763544375114903, Test loss 0.2911817241460085, Test accuracy 92.783203125, Cost 75.26297116279602 s\n",
      "Epoch 745, Train loss 0.03429388816169064, Test loss 0.303853864595294, Test accuracy 92.392578125, Cost 75.34308052062988 s\n",
      "Model saved in epoch 745\n",
      "Epoch 746, Train loss 0.038423712027962416, Test loss 0.3068345721811056, Test accuracy 92.275390625, Cost 75.38728165626526 s\n",
      "Epoch 747, Train loss 0.04330681962417249, Test loss 0.2956743586808443, Test accuracy 92.3046875, Cost 75.26948094367981 s\n",
      "Epoch 748, Train loss 0.038458461773448756, Test loss 0.3121100593358278, Test accuracy 92.275390625, Cost 75.2182092666626 s\n",
      "Epoch 749, Train loss 0.04313747917434999, Test loss 0.32775140814483167, Test accuracy 92.24609375, Cost 75.2697525024414 s\n",
      "Epoch 750, Train loss 0.02793250322741057, Test loss 0.3019120629876852, Test accuracy 92.470703125, Cost 75.15210485458374 s\n",
      "Model saved in epoch 750\n",
      "Epoch 751, Train loss 0.02432054354053713, Test loss 0.2957876641303301, Test accuracy 92.900390625, Cost 75.26254892349243 s\n",
      "Epoch 752, Train loss 0.033333900847890396, Test loss 0.31682734154164793, Test accuracy 92.59765625, Cost 75.25662994384766 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 753, Train loss 0.042981423656171074, Test loss 0.2954979345202446, Test accuracy 92.763671875, Cost 75.22745370864868 s\n",
      "Epoch 754, Train loss 0.028608429122107978, Test loss 0.31823594532907007, Test accuracy 91.962890625, Cost 75.45022749900818 s\n",
      "Epoch 755, Train loss 0.04037706996789392, Test loss 0.30496673844754696, Test accuracy 92.509765625, Cost 75.3848009109497 s\n",
      "Model saved in epoch 755\n",
      "Epoch 756, Train loss 0.030767265229714007, Test loss 0.29871479868888856, Test accuracy 92.607421875, Cost 75.39547824859619 s\n",
      "Epoch 757, Train loss 0.033977203642502805, Test loss 0.3319988053292036, Test accuracy 92.001953125, Cost 75.3574104309082 s\n",
      "Epoch 758, Train loss 0.046290521025277524, Test loss 0.3244657203555107, Test accuracy 92.353515625, Cost 75.24161195755005 s\n",
      "Epoch 759, Train loss 0.03552944695206397, Test loss 0.2968258481472731, Test accuracy 92.265625, Cost 75.47114515304565 s\n",
      "Epoch 760, Train loss 0.03649936978733737, Test loss 0.32756319269537926, Test accuracy 92.01171875, Cost 75.35445666313171 s\n",
      "Model saved in epoch 760\n",
      "Epoch 761, Train loss 0.03684758068043358, Test loss 0.30383964739739894, Test accuracy 92.55859375, Cost 75.41095733642578 s\n",
      "Epoch 762, Train loss 0.03360004633028364, Test loss 0.2970798838883638, Test accuracy 92.275390625, Cost 75.38838291168213 s\n",
      "Epoch 763, Train loss 0.031887552910009206, Test loss 0.3118271606042981, Test accuracy 92.626953125, Cost 75.72229838371277 s\n",
      "Epoch 764, Train loss 0.029890766067962562, Test loss 0.2906349278986454, Test accuracy 92.734375, Cost 75.41951251029968 s\n",
      "Epoch 765, Train loss 0.03924489363182184, Test loss 0.30565091893076896, Test accuracy 92.275390625, Cost 75.31092023849487 s\n",
      "Model saved in epoch 765\n",
      "Epoch 766, Train loss 0.03767964084233556, Test loss 0.3115164216607809, Test accuracy 92.080078125, Cost 75.20590233802795 s\n",
      "Epoch 767, Train loss 0.032166511894260744, Test loss 0.2956932969391346, Test accuracy 92.861328125, Cost 75.36478590965271 s\n",
      "Epoch 768, Train loss 0.02982140368097747, Test loss 0.2882542356848717, Test accuracy 92.744140625, Cost 75.34145998954773 s\n",
      "Epoch 769, Train loss 0.030903715635554826, Test loss 0.3148745257407427, Test accuracy 92.71484375, Cost 75.264488697052 s\n",
      "Epoch 770, Train loss 0.03225202949679628, Test loss 0.2887309372425079, Test accuracy 92.9296875, Cost 75.21106624603271 s\n",
      "Model saved in epoch 770\n",
      "Epoch 771, Train loss 0.0378546180365113, Test loss 0.30381353944540024, Test accuracy 92.705078125, Cost 75.15916442871094 s\n",
      "Epoch 772, Train loss 0.036014701512984325, Test loss 0.3337649632245302, Test accuracy 92.1484375, Cost 75.23655414581299 s\n",
      "Epoch 773, Train loss 0.03943724416633498, Test loss 0.3083323955535889, Test accuracy 92.236328125, Cost 75.24538898468018 s\n",
      "Epoch 774, Train loss 0.036882311865991474, Test loss 0.28026084750890734, Test accuracy 93.02734375, Cost 75.34515929222107 s\n",
      "Epoch 775, Train loss 0.035953020040249944, Test loss 0.30612282231450083, Test accuracy 92.51953125, Cost 75.23612785339355 s\n",
      "Model saved in epoch 775\n",
      "Epoch 776, Train loss 0.03773459559781667, Test loss 0.29975289665162563, Test accuracy 92.705078125, Cost 75.20642709732056 s\n",
      "Epoch 777, Train loss 0.028613751155457327, Test loss 0.2960939437150955, Test accuracy 92.5390625, Cost 75.25545644760132 s\n",
      "Epoch 778, Train loss 0.031546686617990156, Test loss 0.30728919319808484, Test accuracy 92.5, Cost 75.33905529975891 s\n",
      "Epoch 779, Train loss 0.0355279470202323, Test loss 0.281186705455184, Test accuracy 92.314453125, Cost 75.32521104812622 s\n",
      "Epoch 780, Train loss 0.04811635207650917, Test loss 0.2825683679431677, Test accuracy 92.59765625, Cost 75.37738037109375 s\n",
      "Model saved in epoch 780\n",
      "Epoch 781, Train loss 0.03813565251113353, Test loss 0.2663418535143137, Test accuracy 93.056640625, Cost 75.2726104259491 s\n",
      "Epoch 782, Train loss 0.04069495032427414, Test loss 0.2835243232548237, Test accuracy 93.017578125, Cost 75.20895147323608 s\n",
      "Epoch 783, Train loss 0.03101252512626198, Test loss 0.28831691257655623, Test accuracy 93.173828125, Cost 75.25600361824036 s\n",
      "Epoch 784, Train loss 0.036835775140444844, Test loss 0.3319042131304741, Test accuracy 92.158203125, Cost 75.44441604614258 s\n",
      "Epoch 785, Train loss 0.03306458985233413, Test loss 0.30545807518064977, Test accuracy 92.685546875, Cost 75.62848925590515 s\n",
      "Model saved in epoch 785\n",
      "Epoch 786, Train loss 0.025977111977468034, Test loss 0.2793533204123378, Test accuracy 92.96875, Cost 75.41244649887085 s\n",
      "Epoch 787, Train loss 0.03542169480470522, Test loss 0.2993950668722391, Test accuracy 92.705078125, Cost 75.32399940490723 s\n",
      "Epoch 788, Train loss 0.051279232096003026, Test loss 0.2903212904930115, Test accuracy 92.8515625, Cost 75.30625534057617 s\n",
      "Epoch 789, Train loss 0.028014456701217865, Test loss 0.263621617667377, Test accuracy 93.095703125, Cost 75.32996106147766 s\n",
      "Epoch 790, Train loss 0.027974310606642037, Test loss 0.3155008550733328, Test accuracy 92.431640625, Cost 75.41933989524841 s\n",
      "Model saved in epoch 790\n",
      "Epoch 791, Train loss 0.04319579721124349, Test loss 0.28436506632715464, Test accuracy 92.71484375, Cost 75.28114008903503 s\n",
      "Epoch 792, Train loss 0.03235087274070069, Test loss 0.3110607109963894, Test accuracy 92.34375, Cost 75.37448215484619 s\n",
      "Epoch 793, Train loss 0.044087907805449654, Test loss 0.29285171888768674, Test accuracy 92.626953125, Cost 75.3407690525055 s\n",
      "Epoch 794, Train loss 0.02973816526711595, Test loss 0.2746441651135683, Test accuracy 93.388671875, Cost 75.46069192886353 s\n",
      "Epoch 795, Train loss 0.025297855996355718, Test loss 0.293914957344532, Test accuracy 93.076171875, Cost 75.24121403694153 s\n",
      "Model saved in epoch 795\n",
      "Epoch 796, Train loss 0.04745951114336447, Test loss 0.2816985260695219, Test accuracy 92.646484375, Cost 75.39529919624329 s\n",
      "Epoch 797, Train loss 0.03740121669383073, Test loss 0.282464088127017, Test accuracy 92.67578125, Cost 75.31925678253174 s\n",
      "Epoch 798, Train loss 0.03723742639436862, Test loss 0.28940457608550785, Test accuracy 92.646484375, Cost 75.40747785568237 s\n",
      "Epoch 799, Train loss 0.036558943009479164, Test loss 0.3151893489062786, Test accuracy 91.982421875, Cost 75.33517909049988 s\n",
      "Epoch 800, Train loss 0.04488163937729004, Test loss 0.28924536854028704, Test accuracy 92.8125, Cost 75.48585724830627 s\n",
      "Model saved in epoch 800\n",
      "Epoch 801, Train loss 0.0342249870929886, Test loss 0.29470677115023136, Test accuracy 92.6171875, Cost 75.25452971458435 s\n",
      "Epoch 802, Train loss 0.029547273915508116, Test loss 0.3415670141577721, Test accuracy 92.177734375, Cost 75.19888544082642 s\n",
      "Epoch 803, Train loss 0.030653525269780383, Test loss 0.28356686010956766, Test accuracy 92.646484375, Cost 75.29685425758362 s\n",
      "Epoch 804, Train loss 0.032234313035364816, Test loss 0.32045246474444866, Test accuracy 92.51953125, Cost 75.38573336601257 s\n",
      "Epoch 805, Train loss 0.03687567995832663, Test loss 0.3133220888674259, Test accuracy 92.021484375, Cost 75.32017588615417 s\n",
      "Model saved in epoch 805\n",
      "Epoch 806, Train loss 0.04040421579479791, Test loss 0.3469009630382061, Test accuracy 91.669921875, Cost 75.32462978363037 s\n",
      "Epoch 807, Train loss 0.03807884050124534, Test loss 0.3041297491639853, Test accuracy 92.294921875, Cost 75.60392212867737 s\n",
      "Epoch 808, Train loss 0.03272686747130843, Test loss 0.2963203083723783, Test accuracy 92.763671875, Cost 75.44930124282837 s\n",
      "Epoch 809, Train loss 0.03725297031306415, Test loss 0.28053960762917995, Test accuracy 92.705078125, Cost 75.30587530136108 s\n",
      "Epoch 810, Train loss 0.036944909776770035, Test loss 0.28356948047876357, Test accuracy 92.841796875, Cost 75.31296873092651 s\n",
      "Model saved in epoch 810\n",
      "Epoch 811, Train loss 0.03433008491517786, Test loss 0.31147303357720374, Test accuracy 92.685546875, Cost 75.13065648078918 s\n",
      "Epoch 812, Train loss 0.038395813723303834, Test loss 0.29472681805491446, Test accuracy 92.96875, Cost 75.18004417419434 s\n",
      "Epoch 813, Train loss 0.030066884776140203, Test loss 0.29699670560657976, Test accuracy 92.48046875, Cost 75.21114444732666 s\n",
      "Epoch 814, Train loss 0.035008291770913164, Test loss 0.305038445442915, Test accuracy 92.55859375, Cost 75.2440390586853 s\n",
      "Epoch 815, Train loss 0.02771407663014394, Test loss 0.29130158945918083, Test accuracy 93.02734375, Cost 75.20119857788086 s\n",
      "Model saved in epoch 815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 816, Train loss 0.031275725735788594, Test loss 0.3089366026222706, Test accuracy 92.255859375, Cost 75.36726880073547 s\n",
      "Epoch 817, Train loss 0.039251839190873564, Test loss 0.3012573217973113, Test accuracy 92.470703125, Cost 75.27946829795837 s\n",
      "Epoch 818, Train loss 0.0408995861700755, Test loss 0.3059467777609825, Test accuracy 92.5, Cost 75.16335844993591 s\n",
      "Epoch 819, Train loss 0.030933471256391887, Test loss 0.32870140075683596, Test accuracy 92.16796875, Cost 75.364497423172 s\n",
      "Epoch 820, Train loss 0.03557318157506917, Test loss 0.2973128464072943, Test accuracy 92.587890625, Cost 75.28037667274475 s\n",
      "Model saved in epoch 820\n",
      "Epoch 821, Train loss 0.03567914573038567, Test loss 0.2980306684970856, Test accuracy 92.568359375, Cost 75.33055973052979 s\n",
      "Epoch 822, Train loss 0.04256302714157773, Test loss 0.2895066637545824, Test accuracy 92.685546875, Cost 75.13370990753174 s\n",
      "Epoch 823, Train loss 0.039000733114056746, Test loss 0.29708135053515433, Test accuracy 92.32421875, Cost 75.16409540176392 s\n",
      "Epoch 824, Train loss 0.035536639292591383, Test loss 0.2967442784458399, Test accuracy 92.255859375, Cost 75.18563985824585 s\n",
      "Epoch 825, Train loss 0.035251381350871254, Test loss 0.28326247818768024, Test accuracy 92.8515625, Cost 75.28426218032837 s\n",
      "Model saved in epoch 825\n",
      "Epoch 826, Train loss 0.037164504003083826, Test loss 0.30192249417304995, Test accuracy 92.568359375, Cost 75.32803392410278 s\n",
      "Epoch 827, Train loss 0.03747291017646844, Test loss 0.31427353993058205, Test accuracy 92.44140625, Cost 75.28467392921448 s\n",
      "Epoch 828, Train loss 0.0287531909238243, Test loss 0.2841139905154705, Test accuracy 93.203125, Cost 75.50255012512207 s\n",
      "Epoch 829, Train loss 0.030211343546397984, Test loss 0.3054037407040596, Test accuracy 92.40234375, Cost 75.60816311836243 s\n",
      "Epoch 830, Train loss 0.044512152032717606, Test loss 0.2905038181692362, Test accuracy 92.3828125, Cost 75.43115282058716 s\n",
      "Model saved in epoch 830\n",
      "Epoch 831, Train loss 0.030950841472522184, Test loss 0.27252588979899883, Test accuracy 92.9296875, Cost 75.28131556510925 s\n",
      "Epoch 832, Train loss 0.03667552354127853, Test loss 0.2806067459285259, Test accuracy 92.841796875, Cost 75.30972027778625 s\n",
      "Epoch 833, Train loss 0.03271518803049563, Test loss 0.3245552897453308, Test accuracy 91.865234375, Cost 75.42408418655396 s\n",
      "Epoch 834, Train loss 0.038534491301552225, Test loss 0.30807429291307925, Test accuracy 92.216796875, Cost 75.24962067604065 s\n",
      "Epoch 835, Train loss 0.03476624965325606, Test loss 0.3138081539422274, Test accuracy 92.421875, Cost 75.25928711891174 s\n",
      "Model saved in epoch 835\n",
      "Epoch 836, Train loss 0.035372467250658235, Test loss 0.30735682509839535, Test accuracy 92.626953125, Cost 75.28815913200378 s\n",
      "Epoch 837, Train loss 0.03825175753148387, Test loss 0.3191071625798941, Test accuracy 92.177734375, Cost 75.31912612915039 s\n",
      "Epoch 838, Train loss 0.029688525006498153, Test loss 0.28281761668622496, Test accuracy 93.271484375, Cost 75.24288535118103 s\n",
      "Epoch 839, Train loss 0.02521449540817768, Test loss 0.3310977526009083, Test accuracy 92.5390625, Cost 75.27456498146057 s\n",
      "Epoch 840, Train loss 0.02874663629692656, Test loss 0.30744011141359806, Test accuracy 92.51953125, Cost 75.3355884552002 s\n",
      "Model saved in epoch 840\n",
      "Epoch 841, Train loss 0.03695691926689933, Test loss 0.305376098677516, Test accuracy 92.44140625, Cost 75.28203701972961 s\n",
      "Epoch 842, Train loss 0.039149884989827265, Test loss 0.31870433054864405, Test accuracy 92.373046875, Cost 75.31999683380127 s\n",
      "Epoch 843, Train loss 0.03520595546745296, Test loss 0.33931271359324455, Test accuracy 92.060546875, Cost 75.28978085517883 s\n",
      "Epoch 844, Train loss 0.03092338234822893, Test loss 0.3191227976232767, Test accuracy 92.59765625, Cost 75.17825365066528 s\n",
      "Epoch 845, Train loss 0.03554638122845137, Test loss 0.3077224023640156, Test accuracy 92.71484375, Cost 75.16680455207825 s\n",
      "Model saved in epoch 845\n",
      "Epoch 846, Train loss 0.042389798137283295, Test loss 0.3162169363349676, Test accuracy 92.578125, Cost 75.15551781654358 s\n",
      "Epoch 847, Train loss 0.030828905372633313, Test loss 0.29999476335942743, Test accuracy 92.71484375, Cost 75.30069780349731 s\n",
      "Epoch 848, Train loss 0.03480168019554445, Test loss 0.3140799324959517, Test accuracy 92.2265625, Cost 75.28791499137878 s\n",
      "Epoch 849, Train loss 0.037340201568143556, Test loss 0.2913319326937199, Test accuracy 92.802734375, Cost 75.23089289665222 s\n",
      "Epoch 850, Train loss 0.030558261884927596, Test loss 0.31288442723453047, Test accuracy 92.578125, Cost 75.43896007537842 s\n",
      "Model saved in epoch 850\n",
      "Epoch 851, Train loss 0.03220266740702625, Test loss 0.32628341130912303, Test accuracy 92.08984375, Cost 75.55187463760376 s\n",
      "Epoch 852, Train loss 0.031855150076028495, Test loss 0.30073381960392, Test accuracy 92.94921875, Cost 75.291743516922 s\n",
      "Epoch 853, Train loss 0.04031689499257779, Test loss 0.346888829767704, Test accuracy 91.259765625, Cost 75.23900485038757 s\n",
      "Epoch 854, Train loss 0.04151075543617183, Test loss 0.30864525511860846, Test accuracy 92.421875, Cost 75.25589776039124 s\n",
      "Epoch 855, Train loss 0.034823604101524214, Test loss 0.33387160710990427, Test accuracy 91.962890625, Cost 75.37355875968933 s\n",
      "Model saved in epoch 855\n",
      "Epoch 856, Train loss 0.0393207023200598, Test loss 0.3094413548707962, Test accuracy 92.7734375, Cost 75.29263710975647 s\n",
      "Epoch 857, Train loss 0.03357281533488053, Test loss 0.3065756570547819, Test accuracy 92.451171875, Cost 75.35915303230286 s\n",
      "Epoch 858, Train loss 0.031321685958406606, Test loss 0.3033172618597746, Test accuracy 92.841796875, Cost 75.35374903678894 s\n",
      "Epoch 859, Train loss 0.03196877740770198, Test loss 0.2876848362386227, Test accuracy 92.87109375, Cost 75.30096888542175 s\n",
      "Epoch 860, Train loss 0.03696499200423761, Test loss 0.30951867811381817, Test accuracy 92.5, Cost 75.22384595870972 s\n",
      "Model saved in epoch 860\n",
      "Epoch 861, Train loss 0.035125557981830625, Test loss 0.3318473618477583, Test accuracy 92.03125, Cost 75.24913096427917 s\n",
      "Epoch 862, Train loss 0.03936610405561419, Test loss 0.305486387014389, Test accuracy 92.44140625, Cost 75.2133572101593 s\n",
      "Epoch 863, Train loss 0.03272589981765011, Test loss 0.30564990267157555, Test accuracy 92.509765625, Cost 75.24056625366211 s\n",
      "Epoch 864, Train loss 0.03617098289114252, Test loss 0.31233564801514146, Test accuracy 92.03125, Cost 75.28384208679199 s\n",
      "Epoch 865, Train loss 0.03744873906514246, Test loss 0.32069312781095505, Test accuracy 91.513671875, Cost 75.14294576644897 s\n",
      "Model saved in epoch 865\n",
      "Epoch 866, Train loss 0.030160021751986017, Test loss 0.30368872433900834, Test accuracy 92.431640625, Cost 75.25936603546143 s\n",
      "Epoch 867, Train loss 0.033567465542416484, Test loss 0.3035751961171627, Test accuracy 92.24609375, Cost 75.36457109451294 s\n",
      "Epoch 868, Train loss 0.04704531984004591, Test loss 0.27695701979100706, Test accuracy 92.6953125, Cost 75.39340019226074 s\n",
      "Epoch 869, Train loss 0.0298822223807552, Test loss 0.30905520282685756, Test accuracy 92.177734375, Cost 75.29736232757568 s\n",
      "Epoch 870, Train loss 0.026620675974801108, Test loss 0.3116476621478796, Test accuracy 92.626953125, Cost 75.41538667678833 s\n",
      "Model saved in epoch 870\n",
      "Epoch 871, Train loss 0.03395890550003672, Test loss 0.29451715014874935, Test accuracy 92.40234375, Cost 75.2184407711029 s\n",
      "Epoch 872, Train loss 0.03241427960967151, Test loss 0.3080536093562841, Test accuracy 92.607421875, Cost 75.43467330932617 s\n",
      "Epoch 873, Train loss 0.0270974422164727, Test loss 0.29360929764807225, Test accuracy 92.900390625, Cost 75.60676455497742 s\n",
      "Epoch 874, Train loss 0.024729211259946912, Test loss 0.3451726198196411, Test accuracy 92.24609375, Cost 75.30647492408752 s\n",
      "Epoch 875, Train loss 0.03721637175209364, Test loss 0.30507587864995, Test accuracy 92.666015625, Cost 75.3277039527893 s\n",
      "Model saved in epoch 875\n",
      "Epoch 876, Train loss 0.04397362215938617, Test loss 0.3103538352996111, Test accuracy 92.20703125, Cost 75.18235158920288 s\n",
      "Epoch 877, Train loss 0.036081222823241305, Test loss 0.3025409523397684, Test accuracy 92.4609375, Cost 75.35255193710327 s\n",
      "Epoch 878, Train loss 0.035087302118083655, Test loss 0.32905339226126673, Test accuracy 91.6015625, Cost 75.28541398048401 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 879, Train loss 0.03455113691553397, Test loss 0.30863346457481383, Test accuracy 92.4609375, Cost 75.35678267478943 s\n",
      "Epoch 880, Train loss 0.04095643769227424, Test loss 0.3199481338262558, Test accuracy 92.001953125, Cost 75.40053606033325 s\n",
      "Model saved in epoch 880\n",
      "Epoch 881, Train loss 0.04278035783113874, Test loss 0.3103916812688112, Test accuracy 92.24609375, Cost 75.19614052772522 s\n",
      "Epoch 882, Train loss 0.029196445915695965, Test loss 0.2950376706197858, Test accuracy 92.822265625, Cost 75.35129475593567 s\n",
      "Epoch 883, Train loss 0.027026967588593537, Test loss 0.3389972347766161, Test accuracy 92.373046875, Cost 75.3354549407959 s\n",
      "Epoch 884, Train loss 0.0386377761392303, Test loss 0.29978464879095557, Test accuracy 92.7734375, Cost 75.3093614578247 s\n",
      "Epoch 885, Train loss 0.03756159670384867, Test loss 0.29401534162461757, Test accuracy 92.451171875, Cost 75.28239345550537 s\n",
      "Model saved in epoch 885\n",
      "Epoch 886, Train loss 0.04152749156180237, Test loss 0.3015086632221937, Test accuracy 92.490234375, Cost 75.14713740348816 s\n",
      "Epoch 887, Train loss 0.03497017890557039, Test loss 0.31040572039783, Test accuracy 91.884765625, Cost 75.23390603065491 s\n",
      "Epoch 888, Train loss 0.03287551608601851, Test loss 0.3057142088189721, Test accuracy 92.265625, Cost 75.2604513168335 s\n",
      "Epoch 889, Train loss 0.030525063375980422, Test loss 0.29901648312807083, Test accuracy 92.841796875, Cost 75.2563419342041 s\n",
      "Epoch 890, Train loss 0.03689719527028501, Test loss 0.3061752639710903, Test accuracy 92.548828125, Cost 75.21038174629211 s\n",
      "Model saved in epoch 890\n",
      "Epoch 891, Train loss 0.03378689547582549, Test loss 0.30089084804058075, Test accuracy 92.548828125, Cost 75.19663763046265 s\n",
      "Epoch 892, Train loss 0.03262578417090889, Test loss 0.2972186554223299, Test accuracy 92.705078125, Cost 75.37289047241211 s\n",
      "Epoch 893, Train loss 0.031242500342029546, Test loss 0.29432320185005667, Test accuracy 92.59765625, Cost 75.38894629478455 s\n",
      "Epoch 894, Train loss 0.027722398116139278, Test loss 0.29950241148471834, Test accuracy 92.734375, Cost 75.47622442245483 s\n",
      "Epoch 895, Train loss 0.03857744316218839, Test loss 0.3143612194806337, Test accuracy 92.265625, Cost 75.53951334953308 s\n",
      "Model saved in epoch 895\n",
      "Epoch 896, Train loss 0.03310685473190127, Test loss 0.2952965185046196, Test accuracy 92.744140625, Cost 75.16366839408875 s\n",
      "Epoch 897, Train loss 0.037381788318957755, Test loss 0.341406075656414, Test accuracy 91.982421875, Cost 75.27513289451599 s\n",
      "Epoch 898, Train loss 0.03938556366067912, Test loss 0.3080198705196381, Test accuracy 92.626953125, Cost 75.23019766807556 s\n",
      "Epoch 899, Train loss 0.032312735827278574, Test loss 0.32506728135049345, Test accuracy 92.373046875, Cost 75.22885131835938 s\n",
      "Epoch 900, Train loss 0.03295523154416254, Test loss 0.28129050731658933, Test accuracy 93.037109375, Cost 75.25465559959412 s\n",
      "Model saved in epoch 900\n",
      "Epoch 901, Train loss 0.029993629705502976, Test loss 0.2983449807390571, Test accuracy 92.470703125, Cost 75.24555230140686 s\n",
      "Epoch 902, Train loss 0.027822948806938166, Test loss 0.3102939587086439, Test accuracy 92.91015625, Cost 75.26238632202148 s\n",
      "Epoch 903, Train loss 0.024680418810541078, Test loss 0.2936861341819167, Test accuracy 93.046875, Cost 75.23830127716064 s\n",
      "Epoch 904, Train loss 0.03631660235304462, Test loss 0.3403405461460352, Test accuracy 91.5625, Cost 75.31209945678711 s\n",
      "Epoch 905, Train loss 0.042631545512727936, Test loss 0.3057278607040644, Test accuracy 92.197265625, Cost 75.32477164268494 s\n",
      "Model saved in epoch 905\n",
      "Epoch 906, Train loss 0.04207771625939985, Test loss 0.31859162636101246, Test accuracy 92.158203125, Cost 75.21911025047302 s\n",
      "Epoch 907, Train loss 0.03881818273731945, Test loss 0.30173744075000286, Test accuracy 92.6171875, Cost 75.26211166381836 s\n",
      "Epoch 908, Train loss 0.028994189601448575, Test loss 0.3431268561631441, Test accuracy 92.265625, Cost 75.31985664367676 s\n",
      "Epoch 909, Train loss 0.03641568856522897, Test loss 0.33348711878061293, Test accuracy 91.904296875, Cost 75.47874760627747 s\n",
      "Epoch 910, Train loss 0.041199762849327255, Test loss 0.30038287714123724, Test accuracy 92.67578125, Cost 75.31971740722656 s\n",
      "Model saved in epoch 910\n",
      "Epoch 911, Train loss 0.02846176331691748, Test loss 0.29625222478061913, Test accuracy 92.529296875, Cost 75.28674554824829 s\n",
      "Epoch 912, Train loss 0.03176476472361507, Test loss 0.3039426665753126, Test accuracy 92.294921875, Cost 75.15176892280579 s\n",
      "Epoch 913, Train loss 0.04344908657426737, Test loss 0.3202385287731886, Test accuracy 91.97265625, Cost 75.28575849533081 s\n",
      "Epoch 914, Train loss 0.031074902482273778, Test loss 0.3074306767433882, Test accuracy 92.470703125, Cost 75.25957155227661 s\n",
      "Epoch 915, Train loss 0.03301059454441907, Test loss 0.3098524183034897, Test accuracy 92.236328125, Cost 75.2774429321289 s\n",
      "Model saved in epoch 915\n",
      "Epoch 916, Train loss 0.03823930644240154, Test loss 0.30301452092826364, Test accuracy 92.392578125, Cost 75.56231832504272 s\n",
      "Epoch 917, Train loss 0.0340858960300874, Test loss 0.2943310968577862, Test accuracy 92.568359375, Cost 75.41782069206238 s\n",
      "Epoch 918, Train loss 0.030084280508608386, Test loss 0.3341147888451815, Test accuracy 92.255859375, Cost 75.47260332107544 s\n",
      "Epoch 919, Train loss 0.034412515441155325, Test loss 0.3241546437144279, Test accuracy 92.568359375, Cost 75.36282587051392 s\n",
      "Epoch 920, Train loss 0.03606258984655142, Test loss 0.321478970348835, Test accuracy 92.08984375, Cost 75.34028434753418 s\n",
      "Model saved in epoch 920\n",
      "Epoch 921, Train loss 0.03540783268589603, Test loss 0.2956884440034628, Test accuracy 92.998046875, Cost 75.17469668388367 s\n",
      "Epoch 922, Train loss 0.02858108925224491, Test loss 0.31221870630979537, Test accuracy 92.36328125, Cost 75.18781232833862 s\n",
      "Epoch 923, Train loss 0.03715416658384611, Test loss 0.31217027120292185, Test accuracy 92.431640625, Cost 75.2069206237793 s\n",
      "Epoch 924, Train loss 0.029724802762479047, Test loss 0.30134686157107354, Test accuracy 92.626953125, Cost 75.20477294921875 s\n",
      "Epoch 925, Train loss 0.03930370844140345, Test loss 0.31561892088502647, Test accuracy 92.197265625, Cost 75.2442684173584 s\n",
      "Model saved in epoch 925\n",
      "Epoch 926, Train loss 0.034277621827715515, Test loss 0.31135421730577945, Test accuracy 92.3046875, Cost 75.1872148513794 s\n",
      "Epoch 927, Train loss 0.042476904160362115, Test loss 0.2795493397861719, Test accuracy 93.30078125, Cost 75.29796147346497 s\n",
      "Epoch 928, Train loss 0.02577038550492832, Test loss 0.28831027299165723, Test accuracy 92.822265625, Cost 75.38214302062988 s\n",
      "Epoch 929, Train loss 0.0296175948733806, Test loss 0.3096247993409634, Test accuracy 92.509765625, Cost 75.25762367248535 s\n",
      "Epoch 930, Train loss 0.03853865144109087, Test loss 0.3572789322584867, Test accuracy 91.5625, Cost 75.36033701896667 s\n",
      "Model saved in epoch 930\n",
      "Epoch 931, Train loss 0.04001594277821025, Test loss 0.28154326155781745, Test accuracy 92.94921875, Cost 75.21310019493103 s\n",
      "Epoch 932, Train loss 0.022448811373597354, Test loss 0.298928938806057, Test accuracy 92.744140625, Cost 75.21028232574463 s\n",
      "Epoch 933, Train loss 0.037787680751739106, Test loss 0.3145457372069359, Test accuracy 92.333984375, Cost 75.14607095718384 s\n",
      "Epoch 934, Train loss 0.039634013605513135, Test loss 0.3604247037321329, Test accuracy 91.3671875, Cost 75.34042239189148 s\n",
      "Epoch 935, Train loss 0.03780924164385972, Test loss 0.2759089138358831, Test accuracy 93.076171875, Cost 75.15996861457825 s\n",
      "Model saved in epoch 935\n",
      "Epoch 936, Train loss 0.03135725745113985, Test loss 0.31847645826637744, Test accuracy 92.861328125, Cost 75.2740638256073 s\n",
      "Epoch 937, Train loss 0.02810630997837692, Test loss 0.32749241776764393, Test accuracy 92.314453125, Cost 75.40698480606079 s\n",
      "Epoch 938, Train loss 0.041322915463195165, Test loss 0.3125194475054741, Test accuracy 92.568359375, Cost 75.59014129638672 s\n",
      "Epoch 939, Train loss 0.034377093947188436, Test loss 0.3147117383778095, Test accuracy 92.36328125, Cost 75.1626763343811 s\n",
      "Epoch 940, Train loss 0.0389012697399879, Test loss 0.31671098433434963, Test accuracy 92.265625, Cost 75.2174723148346 s\n",
      "Model saved in epoch 940\n",
      "Epoch 941, Train loss 0.03234215423331729, Test loss 0.3058251839131117, Test accuracy 92.7734375, Cost 75.26128339767456 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 942, Train loss 0.032952871439712386, Test loss 0.334079560264945, Test accuracy 92.421875, Cost 75.28151249885559 s\n",
      "Epoch 943, Train loss 0.03234162605937799, Test loss 0.31633838936686515, Test accuracy 92.44140625, Cost 75.29432010650635 s\n",
      "Epoch 944, Train loss 0.03262309087392855, Test loss 0.31881080456078054, Test accuracy 92.71484375, Cost 75.32792139053345 s\n",
      "Epoch 945, Train loss 0.030122127239022176, Test loss 0.31195767447352407, Test accuracy 92.4609375, Cost 75.31935048103333 s\n",
      "Model saved in epoch 945\n",
      "Epoch 946, Train loss 0.03986499772160029, Test loss 0.32645915299654005, Test accuracy 92.265625, Cost 75.39224481582642 s\n",
      "Epoch 947, Train loss 0.04232731910793073, Test loss 0.26666993498802183, Test accuracy 93.076171875, Cost 75.3376317024231 s\n",
      "Epoch 948, Train loss 0.029093880569847415, Test loss 0.29179827831685545, Test accuracy 92.91015625, Cost 75.2648503780365 s\n",
      "Epoch 949, Train loss 0.03226745372391021, Test loss 0.3023687232285738, Test accuracy 92.3046875, Cost 75.27891755104065 s\n",
      "Epoch 950, Train loss 0.03259523829554531, Test loss 0.2960972372442484, Test accuracy 92.880859375, Cost 75.28076481819153 s\n",
      "Model saved in epoch 950\n",
      "Epoch 951, Train loss 0.030447980827932264, Test loss 0.2813607271760702, Test accuracy 92.6953125, Cost 75.1815447807312 s\n",
      "Epoch 952, Train loss 0.039787368877429743, Test loss 0.3150049850344658, Test accuracy 92.041015625, Cost 75.38316941261292 s\n",
      "Epoch 953, Train loss 0.04233393858529019, Test loss 0.3282661192119122, Test accuracy 91.513671875, Cost 75.31920528411865 s\n",
      "Epoch 954, Train loss 0.03942907741293311, Test loss 0.26086010560393336, Test accuracy 93.056640625, Cost 75.3409595489502 s\n",
      "Epoch 955, Train loss 0.03125802754443519, Test loss 0.30919067189097404, Test accuracy 92.32421875, Cost 75.31009840965271 s\n",
      "Model saved in epoch 955\n",
      "Epoch 956, Train loss 0.03336418228585045, Test loss 0.2862205784767866, Test accuracy 92.63671875, Cost 75.45494055747986 s\n",
      "Epoch 957, Train loss 0.031210844941931416, Test loss 0.3024631790816784, Test accuracy 92.32421875, Cost 75.28841137886047 s\n",
      "Epoch 958, Train loss 0.0318726649013709, Test loss 0.3147696305066347, Test accuracy 92.65625, Cost 75.32995319366455 s\n",
      "Epoch 959, Train loss 0.02632904390813973, Test loss 0.277707246132195, Test accuracy 92.978515625, Cost 75.51287508010864 s\n",
      "Epoch 960, Train loss 0.02849994236793445, Test loss 0.30160032846033574, Test accuracy 92.83203125, Cost 75.6487033367157 s\n",
      "Model saved in epoch 960\n",
      "Epoch 961, Train loss 0.03081262056544727, Test loss 0.27739274576306344, Test accuracy 93.134765625, Cost 75.47591423988342 s\n",
      "Epoch 962, Train loss 0.04549151962642007, Test loss 0.32454703338444235, Test accuracy 92.080078125, Cost 75.30745720863342 s\n",
      "Epoch 963, Train loss 0.03784122305675125, Test loss 0.30039518140256405, Test accuracy 92.294921875, Cost 75.44137692451477 s\n",
      "Epoch 964, Train loss 0.03283392718746042, Test loss 0.33374090008437635, Test accuracy 92.44140625, Cost 75.26435995101929 s\n",
      "Epoch 965, Train loss 0.04134983476726528, Test loss 0.34681370109319687, Test accuracy 91.23046875, Cost 75.21830630302429 s\n",
      "Model saved in epoch 965\n",
      "Epoch 966, Train loss 0.03995121371628223, Test loss 0.32492692545056345, Test accuracy 92.275390625, Cost 75.29004168510437 s\n",
      "Epoch 967, Train loss 0.028797750848307446, Test loss 0.2979290444403887, Test accuracy 93.10546875, Cost 75.147953748703 s\n",
      "Epoch 968, Train loss 0.02238550092621079, Test loss 0.3179268307983875, Test accuracy 92.275390625, Cost 75.25038814544678 s\n",
      "Epoch 969, Train loss 0.02952191049983839, Test loss 0.29343746192753317, Test accuracy 92.822265625, Cost 75.30261754989624 s\n",
      "Epoch 970, Train loss 0.0393588970752661, Test loss 0.30387302227318286, Test accuracy 92.48046875, Cost 75.12509751319885 s\n",
      "Model saved in epoch 970\n",
      "Epoch 971, Train loss 0.0325205318275744, Test loss 0.31200106367468833, Test accuracy 92.177734375, Cost 75.3082869052887 s\n",
      "Epoch 972, Train loss 0.041014408844770214, Test loss 0.2865866724401712, Test accuracy 92.451171875, Cost 75.31760859489441 s\n",
      "Epoch 973, Train loss 0.03674746842636746, Test loss 0.30425053648650646, Test accuracy 92.529296875, Cost 75.30061054229736 s\n",
      "Epoch 974, Train loss 0.0249623349399724, Test loss 0.28644385635852815, Test accuracy 92.59765625, Cost 75.322265625 s\n",
      "Epoch 975, Train loss 0.034797722207648416, Test loss 0.3076718557626009, Test accuracy 92.626953125, Cost 75.33426022529602 s\n",
      "Model saved in epoch 975\n",
      "Epoch 976, Train loss 0.03733397495210627, Test loss 0.32809823639690877, Test accuracy 92.158203125, Cost 75.35475778579712 s\n",
      "Epoch 977, Train loss 0.03894515889601744, Test loss 0.3028838917613029, Test accuracy 92.373046875, Cost 75.3866035938263 s\n",
      "Epoch 978, Train loss 0.0373616977404727, Test loss 0.3462844152003527, Test accuracy 91.54296875, Cost 75.22963809967041 s\n",
      "Epoch 979, Train loss 0.036509949818481595, Test loss 0.3197619285434484, Test accuracy 92.5390625, Cost 75.40047574043274 s\n",
      "Epoch 980, Train loss 0.0313671292969957, Test loss 0.3231607425957918, Test accuracy 92.5390625, Cost 75.36129689216614 s\n",
      "Model saved in epoch 980\n",
      "Epoch 981, Train loss 0.0325608942230061, Test loss 0.2958054583519697, Test accuracy 92.568359375, Cost 75.46231937408447 s\n",
      "Epoch 982, Train loss 0.03017159596641491, Test loss 0.30392896942794323, Test accuracy 92.919921875, Cost 75.61819958686829 s\n",
      "Epoch 983, Train loss 0.03217964978860121, Test loss 0.2974729523062706, Test accuracy 93.0859375, Cost 75.25362610816956 s\n",
      "Epoch 984, Train loss 0.028871032713475277, Test loss 0.3264571145176888, Test accuracy 92.509765625, Cost 75.26953458786011 s\n",
      "Epoch 985, Train loss 0.044486569592311065, Test loss 0.2979789175093174, Test accuracy 92.51953125, Cost 75.35367941856384 s\n",
      "Model saved in epoch 985\n",
      "Epoch 986, Train loss 0.03316796962670716, Test loss 0.29270033203065393, Test accuracy 92.255859375, Cost 75.20635557174683 s\n",
      "Epoch 987, Train loss 0.030435499138845017, Test loss 0.2804662674665451, Test accuracy 92.91015625, Cost 75.32033348083496 s\n",
      "Epoch 988, Train loss 0.03848550536631778, Test loss 0.3151832979172468, Test accuracy 92.265625, Cost 75.3751916885376 s\n",
      "Epoch 989, Train loss 0.02542307492754213, Test loss 0.28470629937946795, Test accuracy 93.076171875, Cost 75.30545425415039 s\n",
      "Epoch 990, Train loss 0.02445153440633903, Test loss 0.33489674925804136, Test accuracy 92.3046875, Cost 75.32817912101746 s\n",
      "Model saved in epoch 990\n",
      "Epoch 991, Train loss 0.038807853167800575, Test loss 0.3239800322800875, Test accuracy 92.236328125, Cost 75.10021710395813 s\n",
      "Epoch 992, Train loss 0.03858309319451907, Test loss 0.2964359328150749, Test accuracy 92.734375, Cost 75.15870189666748 s\n",
      "Epoch 993, Train loss 0.0321994802952573, Test loss 0.31079436354339124, Test accuracy 92.451171875, Cost 75.29799103736877 s\n",
      "Epoch 994, Train loss 0.03698124450023229, Test loss 0.2880765534937382, Test accuracy 92.705078125, Cost 75.38949465751648 s\n",
      "Epoch 995, Train loss 0.030573566144864475, Test loss 0.3156068161129951, Test accuracy 92.666015625, Cost 75.29931426048279 s\n",
      "Model saved in epoch 995\n",
      "Epoch 996, Train loss 0.036671551842508573, Test loss 0.3199000656604767, Test accuracy 92.119140625, Cost 75.23752808570862 s\n",
      "Epoch 997, Train loss 0.03421033984430286, Test loss 0.307829375192523, Test accuracy 92.40234375, Cost 75.32672166824341 s\n",
      "Epoch 998, Train loss 0.03813765095119193, Test loss 0.2687021750956774, Test accuracy 92.783203125, Cost 75.45690059661865 s\n",
      "Epoch 999, Train loss 0.029481122826169034, Test loss 0.3212862856686115, Test accuracy 92.32421875, Cost 75.3004720211029 s\n",
      "Epoch 1000, Train loss 0.03380280754728509, Test loss 0.3171429239213467, Test accuracy 92.724609375, Cost 75.38863635063171 s\n",
      "Model saved in epoch 1000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000 # param\n",
    "epoch_start = 0\n",
    "path = 'resnet_aug_weight_decay.pt'\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "test_accuracy_history = []\n",
    "\n",
    "Loss = torch.nn.CrossEntropyLoss()\n",
    "lr = 0.1 # param\n",
    "weight_decay = 1e-4\n",
    "optimizer = torch.optim.SGD(model1.parameters(),lr=lr,momentum=0.9,weight_decay=weight_decay) # changable optimizer\n",
    "\n",
    "if os.path.exists(path):\n",
    "    checkpoint = torch.load(path)\n",
    "    print('Read model from checkpoint')\n",
    "    model1.cuda().load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch_start = checkpoint['epoch']\n",
    "    Loss = checkpoint['Loss']\n",
    "    train_loss_history = checkpoint['train_loss_history']\n",
    "    test_loss_history = checkpoint['test_loss_history']\n",
    "    test_accuracy_history = checkpoint['test_accuracy_history']\n",
    "    print('Restart from epoch',epoch_start)\n",
    "    \n",
    "\n",
    "for epoch in range(epoch_start+1, num_epochs+1):\n",
    "    timestart = time.time()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    test_accuracy = 0.0\n",
    "\n",
    "    for i, data in enumerate(trainDataLoader):\n",
    "        images, labels = data\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        predicted_output = model1.cuda()(images)\n",
    "        fit = Loss(predicted_output,labels)\n",
    "        fit.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += fit.item()\n",
    "\n",
    "    for i, data in enumerate(testDataLoader):\n",
    "        with torch.no_grad():\n",
    "            images, labels = data\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            predicted_output = model1.cuda()(images)\n",
    "            fit = Loss(predicted_output,labels)\n",
    "            test_loss += fit.item()\n",
    "            test_accuracy += (torch.eq(torch.max(predicted_output,1)[1],labels).sum()/len(labels)*100).data.cpu().numpy()\n",
    "\n",
    "\n",
    "    train_loss = train_loss/len(trainDataLoader)\n",
    "    test_loss = test_loss/len(testDataLoader)\n",
    "    test_accu = test_accuracy/len(testDataLoader)\n",
    "    train_loss_history.append(train_loss)\n",
    "    test_loss_history.append(test_loss)\n",
    "    test_accuracy_history.append(test_accu)\n",
    "    print('Epoch %s, Train loss %s, Test loss %s, Test accuracy %s, Cost %s s'%(epoch,train_loss,test_loss,test_accu,time.time()-timestart))\n",
    "\n",
    "    if epoch % 5 == 0 and epoch != 0:\n",
    "        torch.save({'epoch':epoch,\n",
    "              'model_state_dict':model1.cuda().state_dict(),\n",
    "              'optimizer_state_dict':optimizer.state_dict(),\n",
    "              'Loss':Loss,\n",
    "              'train_loss_history':train_loss_history,\n",
    "              'test_loss_history':test_loss_history,\n",
    "              'test_accuracy_history':test_accuracy_history},path)\n",
    "        print('Model saved in epoch %s'%(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x153685d035e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(num_epochs),train_loss_history,'-',linewidth=3,label='Train error')\n",
    "plt.plot(range(num_epochs),test_loss_history,'-',linewidth=3,label='Test error')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(num_epochs),test_accuracy_history,'-',linewidth=3,label='Test accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.470703125 7.529296875\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:',sum(test_accuracy_history[-5:])/5,100-sum(test_accuracy_history[-5:])/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
